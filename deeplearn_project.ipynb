{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install -q d2l\n",
        "\n",
        "from d2l import torch as d2l\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zb_NmuaBOPWK",
        "outputId": "d498ea68-3a3b-4afc-f8b5-1bff873e6435"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.0/95.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\n",
            "mizani 0.13.2 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vFgNNqAnoZO",
        "outputId": "6ce0dabd-6cf6-403e-eae3-0c3c19bc54ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'grs34806-deep-learning-project-data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (21/21), 8.74 MiB | 5.40 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git\n",
        "os.chdir(\"grs34806-deep-learning-project-data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files(seqfile,posfile):\n",
        "# seqfile: file with sequences\n",
        "# posfile: file with positive cases (annotated with function)\n",
        "\n",
        "  with open(seqfile) as seq_handle:\n",
        "    datalist = []\n",
        "    for line in seq_handle:\n",
        "      datalist.append(line.split()[1])\n",
        "\n",
        "  with open(posfile) as pos_handle:\n",
        "    labellist = [0] * len(datalist)\n",
        "    for line in pos_handle:\n",
        "      labellist[int(line[3:]) - 1] = 1\n",
        "\n",
        "  return datalist, labellist"
      ],
      "metadata": {
        "id": "LvSuNBaGnx8J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = read_files('/content/grs34806-deep-learning-project-data/len100_200_n1000.seq', '/content/grs34806-deep-learning-project-data/len100_200_n1000.pos')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "foYGV_Rn8FhM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data = zip(all_data[0], all_data[1]), columns = ['Sequence', 'label'])"
      ],
      "metadata": {
        "id": "NPWKz4TmOfrG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    all_data[0], all_data[1], test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "6hlLrUS12jU1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(batch_size, num_steps, dataset):\n",
        "  mapaa2num = {aa: i for (i, aa)\n",
        "                in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "  seq,lab = dataset\n",
        "  seq = tokenize(seq, mapaa2num)\n",
        "  seq_array = build_seq_array(seq, num_steps)\n",
        "  data_arrays = (seq_array, torch.tensor(lab))\n",
        "  data_iter = d2l.load_array(data_arrays, batch_size)\n",
        "  return data_iter\n",
        "\n",
        "def tokenize(dat, map2num,non_aa_num=20):\n",
        "  seq = []\n",
        "  for count, i in enumerate(dat):\n",
        "    seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "  return seq\n",
        "\n",
        "def build_seq_array(lines, num_steps, non_aa_num=20):\n",
        "  array = torch.tensor([\n",
        "  truncate_pad(l, num_steps, non_aa_num) for l in lines])\n",
        "  return array\n",
        "\n",
        "def truncate_pad(line, num_steps, padding_token):\n",
        "  if len(line) > num_steps:\n",
        "    return line[:num_steps] # Truncate\n",
        "  return line + [padding_token] * (num_steps - len(line)) # Pad\n"
      ],
      "metadata": {
        "id": "98bShXmgSw7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKYvJ81874Ki",
        "outputId": "a73be860-4da9-4e81-89f5-dfdd2d9536cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "# === Deep CNN Model with nn.Sequential ===\n",
        "class DeepProteinCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, out_channels, kernel_size, dropout_rate, num_classes=2):\n",
        "        super(DeepProteinCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab_size - 1)\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(embed_dim, out_channels, kernel_size, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(out_channels, out_channels * 2, kernel_size, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(out_channels * 2, out_channels * 4, kernel_size, padding=\"same\"),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(out_channels * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)             # (batch, seq_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1)            # (batch, embed_dim, seq_len)\n",
        "        x = self.conv_layers(x)          # (batch, out_channels * 4, 1)\n",
        "        x = x.squeeze(-1)                # (batch, out_channels * 4)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# === Training & Evaluation ===\n",
        "def train_model(model, optimizer, criterion, loader):\n",
        "    model.train()\n",
        "    for batch_X, batch_y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(batch_X)\n",
        "        loss = criterion(preds, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in loader:\n",
        "            preds = model(batch_X).argmax(dim=1)\n",
        "            correct += (preds == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# === Grid Search ===\n",
        "param_grid = {\n",
        "    'kernel_size': [5, 8],\n",
        "    'out_channels': [32],\n",
        "    'embed_dim': [20, 50],\n",
        "    'dropout_rate': [0.2, 0.4, 0.6],\n",
        "    'lr': [1e-3, 1e-4, 1e-5]\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "# === Load Your Dataset ===\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "num_steps = 140  # fixed length of sequence\n",
        "\n",
        "train_loader = load_data(batch_size, num_steps, (X_train, y_train))\n",
        "test_loader = load_data(batch_size, num_steps, (X_test, y_test))\n",
        "\n",
        "# === Grid Search Loop ===\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "for params in grid:\n",
        "    model = DeepProteinCNN(\n",
        "        vocab_size=21,\n",
        "        embed_dim=params['embed_dim'],\n",
        "        out_channels=params['out_channels'],\n",
        "        kernel_size=params['kernel_size'],\n",
        "        dropout_rate=params['dropout_rate']\n",
        "    )\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(5):\n",
        "        train_model(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    acc = evaluate_model(model, test_loader)\n",
        "    print(f\"Params: {params}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\nðŸ”¥ Best Params:\")\n",
        "print(best_params)\n",
        "print(f\"âœ… Best Accuracy: {best_acc:.4f}\")"
      ],
      "metadata": {
        "id": "YWoHWeZGTF6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6c39ae-0dac-4e7c-cdb8-8ab694924276"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9636\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5364\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.4788\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9515\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5515\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5212\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9545\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5545\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5182\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9515\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.7000\n",
            "Params: {'dropout_rate': 0.2, 'embed_dim': 50, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.4606\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9545\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5455\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.4818\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9576\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5879\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 20, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5212\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9636\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.6242\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5333\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9576\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5879\n",
            "Params: {'dropout_rate': 0.4, 'embed_dim': 50, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5212\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.8606\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5061\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.4848\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9576\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5242\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 20, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5242\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9576\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 5, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5303\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 5, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.5212\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.001, 'out_channels': 32}, Accuracy: 0.9576\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 8, 'lr': 0.0001, 'out_channels': 32}, Accuracy: 0.5636\n",
            "Params: {'dropout_rate': 0.6, 'embed_dim': 50, 'kernel_size': 8, 'lr': 1e-05, 'out_channels': 32}, Accuracy: 0.4788\n",
            "\n",
            "ðŸ”¥ Best Params:\n",
            "{'dropout_rate': 0.2, 'embed_dim': 20, 'kernel_size': 5, 'lr': 0.001, 'out_channels': 32}\n",
            "âœ… Best Accuracy: 0.9636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNLcJqRb7qVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}