{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bioinformatics Project 2025 - Motif CNN & GO Prediction\n",
        "\n",
        "**Course:** GRS34806 Deep Learning\n",
        "\n",
        "**Authors:** Berkay Helvaci & Maurits Naber\n",
        "\n",
        "**Date:**\n",
        "\n"
      ],
      "metadata": {
        "id": "HuP5FaUF6YLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "YbtfKAzz6ct5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the code last time! also the redundant libraries."
      ],
      "metadata": {
        "id": "amk7R7B2kcma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q\n",
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "Emlqnf_rAIWr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data I/O & Tokenisation"
      ],
      "metadata": {
        "id": "g96CRPCRCbdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. read() --------------------------------------------------------------------\n",
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 2. split_labelled() ----------------------------------------------------------\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    \"\"\"Return two separate sequence lists: positives & negatives.\"\"\"\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "# 3. remove_sequences() -----\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    \"\"\"Randomly keeps half of the list\"\"\"\n",
        "    random.shuffle(datalist)\n",
        "    keep = round(len(datalist) * fraction)\n",
        "    return datalist[:keep]\n",
        "\n",
        "\n",
        "# 4. fuse_sequence_lists() ------------\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    \"\"\"Merge postives and negetaves into one list + label\"\"\"\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 5. generate_train_test() --------\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "# 6. Tokenisation & Padding --------\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "# 7. load_array() & load_data()\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter\n"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "_b5Kq5jEKZwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "9a5774f7-b9ae-4857-fb9b-1cb5c0e282c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training / Evaluation"
      ],
      "metadata": {
        "id": "BhuHUN6TRLun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "YwR8PJG9SYbo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer, device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.columns = [\n",
        "            'epoch',\n",
        "            'train_accuracy',\n",
        "            'train_precision',\n",
        "            'train_recall',\n",
        "            'train_fscore',\n",
        "            'train_loss',\n",
        "            'test_accuracy',\n",
        "            'test_precision',\n",
        "            'test_recall',\n",
        "            'test_fscore',\n",
        "            'test_loss'\n",
        "        ]\n",
        "        self.df = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "\n",
        "    # One training epoch -------------------------------------------------------\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.train(True)\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            # Confusion matrix calculation\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                l = l.item()\n",
        "                if o == 1 and l == 1:\n",
        "                    tpos += 1\n",
        "                elif o == 1 and l == 0:\n",
        "                    fpos += 1\n",
        "                elif o == 0 and l == 0:\n",
        "                    tneg += 1\n",
        "                elif o == 0 and l == 1:\n",
        "                    fneg += 1\n",
        "                else:\n",
        "                    raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "    # Evaluation epoch ---------------------------------------------------------\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter, start=1):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "\n",
        "                # Confusion matrix calculation\n",
        "                for j, l in enumerate(labels):\n",
        "                    o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                    l = l.item()\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _load_into_dict(self, epoch, train_stats, test_stats):\n",
        "        row = [epoch] + list(train_stats) + list(test_stats)\n",
        "        row = pd.DataFrame(row, index=self.columns).T\n",
        "        self.df = pd.concat([self.df, row], axis=0)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_stats = self._train_one_epoch(train_iter)\n",
        "\n",
        "            test_stats = self._test_one_epoch(test_iter)\n",
        "            self._load_into_dict(epoch, train_stats, test_stats)\n",
        "            print(f\"[epoch {epoch:02d}] \"\n",
        "                  f\"train-loss={train_stats[-1]:.4f} | \"\n",
        "                  f\"test-loss={test_stats[-1]:.4f} | \"\n",
        "                  f\"train-acc={train_stats[0]:.4f} | \"\n",
        "                  f\"test-acc={test_stats[0]:.4f} | \"\n",
        "                  f\"P={test_stats[1]:.4f} | R={test_stats[2]:.4f} | F1={test_stats[3]:.4f}\")\n",
        "\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "C0xPrmp3jHjD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, vocab_size: int = 21,\n",
        "                 dropout_rate = 0, conv_channels: int = 128,\n",
        "                 use_bias: bool = False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "UeAeB8Wo79Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "param_grid = {\n",
        "    'dropout_rate': [0, 0.3],\n",
        "    'lr': [0.01, 0.001],\n",
        "    'momentum': [0, 0.5],\n",
        "    'conv_channels': [64, 128]\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "df = None\n",
        "\n",
        "for params in grid:\n",
        "    print(\"Current hyper-parameters:\", params)\n",
        "    model = BerryCNN1D(\n",
        "        vocab_size=21,\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        conv_channels=params['conv_channels']\n",
        "    )\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        momentum=params['momentum']\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "\n",
        "    out_df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    for p in params.keys():\n",
        "        out_df[p] = params[p]\n",
        "\n",
        "    acc = out_df['test_accuracy'].max()\n",
        "\n",
        "    if acc >= best_acc:\n",
        "        best_acc = []\n",
        "        best_acc = acc\n",
        "        best_params = params\n",
        "        print(f\"New best accuracy {best_acc:.4f} with {best_params} \\n\")\n",
        "\n",
        "    if type(df) != pd.DataFrame:\n",
        "        df = out_df\n",
        "    else:\n",
        "        df = pd.concat([df, out_df], axis=0)\n",
        "\n",
        "print(\"Best hyper‑parameters found:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HESI-RwU5o",
        "outputId": "4f82f392-8efa-42a8-ecaf-b523e8d3d7ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4473 | test-loss=0.0441 | train-acc=0.7605 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 01] train-loss=0.0196 | test-loss=0.0093 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0068 | test-loss=0.0045 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0042 | test-loss=0.0030 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0030 | test-loss=0.0021 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0023 | test-loss=0.0017 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0018 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0015 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0013 | test-loss=0.0010 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0011 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1593 | test-loss=0.0078 | train-acc=0.9337 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0044 | test-loss=0.0031 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0021 | test-loss=0.0019 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0013 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0010 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0008 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0006 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0005 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0004 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0004 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7035 | test-loss=0.6826 | train-acc=0.5045 | test-acc=0.5390 | P=0.5675 | R=0.4769 | F1=0.5183\n",
            "[epoch 01] train-loss=0.6851 | test-loss=0.6702 | train-acc=0.5605 | test-acc=0.5750 | P=0.5604 | R=0.8481 | F1=0.6748\n",
            "[epoch 02] train-loss=0.6657 | test-loss=0.6565 | train-acc=0.6310 | test-acc=0.6230 | P=0.8824 | R=0.3173 | F1=0.4668\n",
            "[epoch 03] train-loss=0.6267 | test-loss=0.5976 | train-acc=0.7220 | test-acc=0.7510 | P=0.8538 | R=0.6288 | F1=0.7243\n",
            "[epoch 04] train-loss=0.5370 | test-loss=0.4589 | train-acc=0.8570 | test-acc=0.9550 | P=0.9857 | R=0.9269 | F1=0.9554\n",
            "[epoch 05] train-loss=0.3603 | test-loss=0.2700 | train-acc=0.9895 | test-acc=0.9960 | P=0.9924 | R=1.0000 | F1=0.9962\n",
            "[epoch 06] train-loss=0.2055 | test-loss=0.1541 | train-acc=0.9990 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 07] train-loss=0.1196 | test-loss=0.0940 | train-acc=0.9995 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 08] train-loss=0.0766 | test-loss=0.0642 | train-acc=1.0000 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 09] train-loss=0.0538 | test-loss=0.0474 | train-acc=1.0000 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6966 | test-loss=0.6864 | train-acc=0.5002 | test-acc=0.5140 | P=0.5500 | R=0.3596 | F1=0.4349\n",
            "[epoch 01] train-loss=0.6840 | test-loss=0.6629 | train-acc=0.5590 | test-acc=0.6290 | P=0.5995 | R=0.8635 | F1=0.7076\n",
            "[epoch 02] train-loss=0.5593 | test-loss=0.3560 | train-acc=0.8650 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.1860 | test-loss=0.0907 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0578 | test-loss=0.0404 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0295 | test-loss=0.0244 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0189 | test-loss=0.0172 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0137 | test-loss=0.0131 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0106 | test-loss=0.0105 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0086 | test-loss=0.0088 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6026 | test-loss=0.1952 | train-acc=0.6530 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 01] train-loss=0.1435 | test-loss=0.0372 | train-acc=0.9580 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 02] train-loss=0.0524 | test-loss=0.0110 | train-acc=0.9858 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0369 | test-loss=0.0081 | train-acc=0.9900 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0270 | test-loss=0.0052 | train-acc=0.9915 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0237 | test-loss=0.0077 | train-acc=0.9940 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0216 | test-loss=0.0068 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0211 | test-loss=0.0033 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0207 | test-loss=0.0044 | train-acc=0.9938 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0182 | test-loss=0.0046 | train-acc=0.9948 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4366 | test-loss=0.0229 | train-acc=0.7542 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0356 | test-loss=0.0106 | train-acc=0.9912 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0244 | test-loss=0.0062 | train-acc=0.9948 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0188 | test-loss=0.0068 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0096 | test-loss=0.0046 | train-acc=0.9982 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 05] train-loss=0.0073 | test-loss=0.0025 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0065 | test-loss=0.0026 | train-acc=0.9982 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0044 | test-loss=0.0024 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0050 | test-loss=0.0016 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0053 | test-loss=0.0039 | train-acc=0.9988 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7633 | test-loss=0.6884 | train-acc=0.4968 | test-acc=0.5100 | P=0.5852 | R=0.1981 | F1=0.2960\n",
            "[epoch 01] train-loss=0.7195 | test-loss=0.6728 | train-acc=0.5100 | test-acc=0.5670 | P=0.5589 | R=0.7942 | F1=0.6561\n",
            "[epoch 02] train-loss=0.6985 | test-loss=0.6517 | train-acc=0.5375 | test-acc=0.7220 | P=0.7597 | R=0.6808 | F1=0.7181\n",
            "[epoch 03] train-loss=0.6628 | test-loss=0.5927 | train-acc=0.6132 | test-acc=0.9160 | P=0.8759 | R=0.9769 | F1=0.9236\n",
            "[epoch 04] train-loss=0.5928 | test-loss=0.4925 | train-acc=0.7245 | test-acc=0.9870 | P=0.9756 | R=1.0000 | F1=0.9877\n",
            "[epoch 05] train-loss=0.4836 | test-loss=0.3565 | train-acc=0.8190 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 06] train-loss=0.3605 | test-loss=0.2285 | train-acc=0.8922 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 07] train-loss=0.2747 | test-loss=0.1483 | train-acc=0.9290 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 08] train-loss=0.2093 | test-loss=0.0953 | train-acc=0.9453 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "[epoch 09] train-loss=0.1679 | test-loss=0.0756 | train-acc=0.9557 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7220 | test-loss=0.6688 | train-acc=0.5072 | test-acc=0.5380 | P=0.5298 | R=0.9904 | F1=0.6903\n",
            "[epoch 01] train-loss=0.6366 | test-loss=0.4940 | train-acc=0.6378 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.4142 | test-loss=0.2130 | train-acc=0.8690 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.2519 | test-loss=0.0994 | train-acc=0.9377 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1649 | test-loss=0.0591 | train-acc=0.9583 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.1345 | test-loss=0.0432 | train-acc=0.9627 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.1070 | test-loss=0.0335 | train-acc=0.9710 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0968 | test-loss=0.0292 | train-acc=0.9745 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0782 | test-loss=0.0241 | train-acc=0.9805 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0666 | test-loss=0.0196 | train-acc=0.9845 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.2003 | test-loss=0.0157 | train-acc=0.9205 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0089 | test-loss=0.0054 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0040 | test-loss=0.0031 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0025 | test-loss=0.0021 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0018 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0014 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0012 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0010 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0008 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0007 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1454 | test-loss=0.0066 | train-acc=0.9337 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0038 | test-loss=0.0027 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0019 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0012 | test-loss=0.0012 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0009 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0007 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0006 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0005 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0004 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0004 | test-loss=0.0004 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6912 | test-loss=0.6771 | train-acc=0.5310 | test-acc=0.5470 | P=0.5356 | R=0.9692 | F1=0.6899\n",
            "[epoch 01] train-loss=0.6635 | test-loss=0.6234 | train-acc=0.6522 | test-acc=0.8210 | P=0.7549 | R=0.9712 | F1=0.8495\n",
            "[epoch 02] train-loss=0.5465 | test-loss=0.4256 | train-acc=0.9350 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 03] train-loss=0.3028 | test-loss=0.1943 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1364 | test-loss=0.0934 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0717 | test-loss=0.0548 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0448 | test-loss=0.0367 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0313 | test-loss=0.0270 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0236 | test-loss=0.0211 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0187 | test-loss=0.0171 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6947 | test-loss=0.6558 | train-acc=0.5195 | test-acc=0.5950 | P=0.5626 | R=0.9942 | F1=0.7186\n",
            "[epoch 01] train-loss=0.5590 | test-loss=0.3783 | train-acc=0.8702 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.2137 | test-loss=0.1046 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0662 | test-loss=0.0426 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0316 | test-loss=0.0242 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0195 | test-loss=0.0163 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0137 | test-loss=0.0120 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0104 | test-loss=0.0094 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0083 | test-loss=0.0077 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0069 | test-loss=0.0065 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3869 | test-loss=0.0343 | train-acc=0.8073 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0526 | test-loss=0.0163 | train-acc=0.9875 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0263 | test-loss=0.0068 | train-acc=0.9940 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0151 | test-loss=0.0045 | train-acc=0.9960 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0124 | test-loss=0.0031 | train-acc=0.9968 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0105 | test-loss=0.0026 | train-acc=0.9972 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0105 | test-loss=0.0025 | train-acc=0.9978 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0052 | test-loss=0.0015 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0059 | test-loss=0.0015 | train-acc=0.9982 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0056 | test-loss=0.0010 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3032 | test-loss=0.0183 | train-acc=0.8482 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0233 | test-loss=0.0034 | train-acc=0.9938 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0147 | test-loss=0.0027 | train-acc=0.9970 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0083 | test-loss=0.0017 | train-acc=0.9972 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0050 | test-loss=0.0021 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0054 | test-loss=0.0026 | train-acc=0.9985 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0051 | test-loss=0.0019 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0027 | test-loss=0.0010 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0031 | test-loss=0.0007 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0019 | test-loss=0.0018 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7327 | test-loss=0.6814 | train-acc=0.5052 | test-acc=0.5590 | P=0.6000 | R=0.4558 | F1=0.5180\n",
            "[epoch 01] train-loss=0.6989 | test-loss=0.6509 | train-acc=0.5407 | test-acc=0.7810 | P=0.7980 | R=0.7750 | F1=0.7863\n",
            "[epoch 02] train-loss=0.6485 | test-loss=0.5735 | train-acc=0.6282 | test-acc=0.9860 | P=1.0000 | R=0.9731 | F1=0.9864\n",
            "[epoch 03] train-loss=0.5637 | test-loss=0.4580 | train-acc=0.7628 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.4722 | test-loss=0.3399 | train-acc=0.8355 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.4071 | test-loss=0.2624 | train-acc=0.8462 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.3606 | test-loss=0.2070 | train-acc=0.8512 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 07] train-loss=0.3143 | test-loss=0.1577 | train-acc=0.8690 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.2755 | test-loss=0.1186 | train-acc=0.9050 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.2393 | test-loss=0.0969 | train-acc=0.9335 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7109 | test-loss=0.6522 | train-acc=0.5220 | test-acc=0.7120 | P=0.9056 | R=0.4981 | F1=0.6427\n",
            "[epoch 01] train-loss=0.5907 | test-loss=0.4010 | train-acc=0.6910 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.3565 | test-loss=0.1776 | train-acc=0.8970 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.2197 | test-loss=0.0876 | train-acc=0.9450 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1541 | test-loss=0.0525 | train-acc=0.9603 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.1123 | test-loss=0.0364 | train-acc=0.9680 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 06] train-loss=0.0853 | test-loss=0.0259 | train-acc=0.9780 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0723 | test-loss=0.0249 | train-acc=0.9772 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 08] train-loss=0.0531 | test-loss=0.0208 | train-acc=0.9868 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "[epoch 09] train-loss=0.0448 | test-loss=0.0174 | train-acc=0.9882 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Best hyper‑parameters found: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on reduced datasets"
      ],
      "metadata": {
        "id": "8ZdNGslz0cAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half of positives"
      ],
      "metadata": {
        "id": "301fqHMW1mGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "pos_datalist = remove_sequences(pos_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "id": "sPheYUrF0hl0",
        "outputId": "600a8e4b-3f08-472a-ac94-aa9fd06b2dac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "n58u1CAg0rbb",
        "outputId": "af011a41-be1e-4133-8498-84c10298b858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.2455 | test-loss=0.0126 | train-acc=0.8971 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0077 | test-loss=0.0040 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0034 | test-loss=0.0021 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0021 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0016 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0012 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0010 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0008 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0007 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0006 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('half_pos_len200_500_n5000nr1.csv')"
      ],
      "metadata": {
        "id": "SjVt5LX-1S80"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half of negatives"
      ],
      "metadata": {
        "id": "qaxou8V21paQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "id": "DfBF1M-W1h9I",
        "outputId": "315707a3-2da9-4416-ae91-92e6248f6408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "KcLovPuh1r3s",
        "outputId": "d3a9da20-f064-499e-8011-86da3d7a4f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.5165 | test-loss=0.0688 | train-acc=0.7465 | test-acc=0.9960 | P=0.9941 | R=1.0000 | F1=0.9970\n",
            "[epoch 01] train-loss=0.0241 | test-loss=0.0087 | train-acc=0.9983 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0067 | test-loss=0.0043 | train-acc=0.9993 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0038 | test-loss=0.0029 | train-acc=0.9997 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0025 | test-loss=0.0022 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0019 | test-loss=0.0018 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0015 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0012 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0010 | test-loss=0.0012 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0009 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('half_neg_len200_500_n5000nr1.csv')"
      ],
      "metadata": {
        "id": "B2dtThLk1t0q"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on GO annotations"
      ],
      "metadata": {
        "id": "L6-AIB-L0ToX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0005576.annotprot\")\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n"
      ],
      "metadata": {
        "id": "yDEFWAwbK_s3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "df.to_csv(\"GO_3A0005576_full_set.csv\")"
      ],
      "metadata": {
        "id": "CvegAg3Q0YU8",
        "outputId": "e6e82d0e-c512-4a48-9625-1eca99587509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7c0b4eb25958>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GO_3A0005576_full_set.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-1cb05001b72f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_iter, test_iter)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-1cb05001b72f>\u001b[0m in \u001b[0;36m_train_one_epoch\u001b[0;34m(self, train_iter)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mresult_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0005576.annotprot\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.3)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "# Train model\n",
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "-5S6aw2z7Ysv",
        "outputId": "464237ad-8b2f-4ccf-c41b-7be5ad65551b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4077 | test-loss=0.4206 | train-acc=0.8639 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.3867 | test-loss=0.4189 | train-acc=0.8683 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3713 | test-loss=0.4366 | train-acc=0.8683 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3568 | test-loss=0.4391 | train-acc=0.8689 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3365 | test-loss=0.4043 | train-acc=0.8689 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3186 | test-loss=0.4116 | train-acc=0.8739 | test-acc=0.8489 | P=0.6667 | R=0.0571 | F1=0.1053\n",
            "[epoch 06] train-loss=0.3004 | test-loss=0.4579 | train-acc=0.8778 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2654 | test-loss=0.4689 | train-acc=0.8911 | test-acc=0.8444 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.2379 | test-loss=0.4073 | train-acc=0.9006 | test-acc=0.8467 | P=0.5714 | R=0.0571 | F1=0.1039\n",
            "[epoch 09] train-loss=0.2073 | test-loss=0.4132 | train-acc=0.9172 | test-acc=0.8489 | P=0.6250 | R=0.0714 | F1=0.1282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "go_annotations = [\"GO_3A0005576\", \"GO_3A0005739\", \"GO_3A0007165\", \"GO_3A0043066\", \"GO_3A0055085\"]\n",
        "\n",
        "for go in go_annotations:\n",
        "    datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", f\"{go}.annotprot\")\n",
        "    pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "    neg_datalist = remove_sequences(neg_datalist, 0.3)\n",
        "    datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "    batch_size = 10\n",
        "    num_steps = 1000 # max sequence length\n",
        "\n",
        "    traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "    traindataset = [traindatalist, trainlabellist]\n",
        "    testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "    # Set batch_size and num_steps (maximum sequence length)\n",
        "    train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "    test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "    # Train model\n",
        "    model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "    model.apply(init_weights)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=0.01,\n",
        "        momentum=0.5\n",
        "    )\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "    df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    df.to_csv(f\"{go}.csv\")"
      ],
      "metadata": {
        "id": "ix_1KPPF5gJI",
        "outputId": "f05299ba-8783-444f-d6a3-e6b3f52db45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4231 | test-loss=0.3598 | train-acc=0.8544 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.4010 | test-loss=0.3579 | train-acc=0.8600 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3859 | test-loss=0.3750 | train-acc=0.8600 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3765 | test-loss=0.3477 | train-acc=0.8600 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3599 | test-loss=0.3410 | train-acc=0.8617 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3338 | test-loss=0.3517 | train-acc=0.8661 | test-acc=0.8778 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3054 | test-loss=0.3894 | train-acc=0.8706 | test-acc=0.8733 | P=0.4500 | R=0.1636 | F1=0.2400\n",
            "[epoch 07] train-loss=0.2758 | test-loss=0.3268 | train-acc=0.8828 | test-acc=0.8822 | P=0.6250 | R=0.0909 | F1=0.1587\n",
            "[epoch 08] train-loss=0.2445 | test-loss=0.3242 | train-acc=0.9028 | test-acc=0.8800 | P=1.0000 | R=0.0182 | F1=0.0357\n",
            "[epoch 09] train-loss=0.2069 | test-loss=0.3169 | train-acc=0.9261 | test-acc=0.8778 | P=0.5000 | R=0.0364 | F1=0.0678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.5208 | test-loss=0.5203 | train-acc=0.7966 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.4874 | test-loss=0.4987 | train-acc=0.8024 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4711 | test-loss=0.5204 | train-acc=0.8051 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.4476 | test-loss=0.5048 | train-acc=0.8051 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.4277 | test-loss=0.5595 | train-acc=0.8061 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3928 | test-loss=0.5967 | train-acc=0.8278 | test-acc=0.7844 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3722 | test-loss=0.5335 | train-acc=0.8405 | test-acc=0.7865 | P=0.6667 | R=0.0196 | F1=0.0381\n",
            "[epoch 07] train-loss=0.3291 | test-loss=0.5762 | train-acc=0.8595 | test-acc=0.7865 | P=1.0000 | R=0.0098 | F1=0.0194\n",
            "[epoch 08] train-loss=0.2912 | test-loss=0.5703 | train-acc=0.8748 | test-acc=0.6786 | P=0.2917 | R=0.3431 | F1=0.3153\n",
            "[epoch 09] train-loss=0.2600 | test-loss=0.6002 | train-acc=0.9054 | test-acc=0.7907 | P=0.7143 | R=0.0490 | F1=0.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4951 | test-loss=0.4760 | train-acc=0.8143 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.4715 | test-loss=0.5423 | train-acc=0.8175 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4640 | test-loss=0.4775 | train-acc=0.8223 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.4563 | test-loss=0.4783 | train-acc=0.8218 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.4406 | test-loss=0.5248 | train-acc=0.8223 | test-acc=0.8133 | P=1.0000 | R=0.0114 | F1=0.0225\n",
            "[epoch 05] train-loss=0.4198 | test-loss=0.4709 | train-acc=0.8250 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3915 | test-loss=0.5378 | train-acc=0.8245 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3732 | test-loss=0.4754 | train-acc=0.8347 | test-acc=0.8112 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3400 | test-loss=0.4730 | train-acc=0.8497 | test-acc=0.8112 | P=0.5000 | R=0.0455 | F1=0.0833\n",
            "[epoch 09] train-loss=0.3104 | test-loss=0.4712 | train-acc=0.8647 | test-acc=0.8176 | P=1.0000 | R=0.0341 | F1=0.0659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3082 | test-loss=0.3094 | train-acc=0.9083 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.2960 | test-loss=0.3015 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.2899 | test-loss=0.3280 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.2834 | test-loss=0.3075 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.2720 | test-loss=0.3138 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.2686 | test-loss=0.3051 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.2527 | test-loss=0.3083 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2388 | test-loss=0.3225 | train-acc=0.9141 | test-acc=0.9055 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.2279 | test-loss=0.3022 | train-acc=0.9152 | test-acc=0.9078 | P=1.0000 | R=0.0244 | F1=0.0476\n",
            "[epoch 09] train-loss=0.2081 | test-loss=0.3099 | train-acc=0.9187 | test-acc=0.9078 | P=1.0000 | R=0.0244 | F1=0.0476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3618 | test-loss=0.4198 | train-acc=0.8951 | test-acc=0.9043 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.3356 | test-loss=0.3387 | train-acc=0.8951 | test-acc=0.9043 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3110 | test-loss=0.2855 | train-acc=0.8951 | test-acc=0.9043 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.2862 | test-loss=0.2794 | train-acc=0.8951 | test-acc=0.9043 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.2568 | test-loss=0.2742 | train-acc=0.9019 | test-acc=0.9043 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.2289 | test-loss=0.2708 | train-acc=0.9122 | test-acc=0.9021 | P=0.4615 | R=0.1429 | F1=0.2182\n",
            "[epoch 06] train-loss=0.1995 | test-loss=0.3281 | train-acc=0.9225 | test-acc=0.8884 | P=0.4222 | R=0.4524 | F1=0.4368\n",
            "[epoch 07] train-loss=0.1852 | test-loss=0.2456 | train-acc=0.9333 | test-acc=0.8998 | P=0.4000 | R=0.0952 | F1=0.1538\n",
            "[epoch 08] train-loss=0.1542 | test-loss=0.3047 | train-acc=0.9441 | test-acc=0.9066 | P=1.0000 | R=0.0238 | F1=0.0465\n",
            "[epoch 09] train-loss=0.1401 | test-loss=0.2485 | train-acc=0.9504 | test-acc=0.9043 | P=0.5000 | R=0.2857 | F1=0.3636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label prediction"
      ],
      "metadata": {
        "id": "1w0ZU-T_u2yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)"
      ],
      "metadata": {
        "id": "NpXTnCJ63_6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data multiple labels"
      ],
      "metadata": {
        "id": "i1r1FMrdxNj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled_multiple_pos(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    pos_labellist = []\n",
        "    neg_datalist = []\n",
        "    neg_labellist = []\n",
        "    for i, labels in enumerate(labellist):\n",
        "        is_pos = False\n",
        "        for label in labels:\n",
        "            if label:\n",
        "                is_pos = True\n",
        "        if is_pos:\n",
        "            pos_datalist.append(datalist[i])\n",
        "            pos_labellist.append(labels)\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "            neg_labellist.append(labels)\n",
        "    return pos_datalist, pos_labellist, neg_datalist, neg_labellist\n",
        "\n",
        "\n",
        "def zip_n_shuffle(list1: list, list2: list) -> tuple[list, list]:\n",
        "    assert len(list1) == len(list2)\n",
        "    combined = list(zip(list1, list2))\n",
        "    random.shuffle(combined)\n",
        "    list1, list2 = zip(*combined)\n",
        "    return list(list1), list(list2)\n",
        "\n",
        "\n",
        "def remove_sequences_multiple_pos(datalist: list, labellist, fraction=0.5):\n",
        "    datalist, labellist = zip_n_shuffle(datalist, labellist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i], labellist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal_multiple_pos(reduced_datalist: list, reduced_labellist: list, compared_datalist: list):\n",
        "    reduced_datalist, reduced_labellist = zip_n_shuffle(reduced_datalist, reduced_labellist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    reduced_labellist = reduced_labellist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist) or len(compared_datalist) != len(reduced_labellist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist, reduced_labellist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists_multiple_pos(pos_datalist: list, pos_labellist:list, neg_datalist: list, neg_labellist):\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labellist + neg_labellist\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def calculate_pos_weights(labellist: list):\n",
        "    total_samples = len(labellist)\n",
        "    label_counts = torch.Tensor(labellist).sum(0)\n",
        "    pos_weights = (total_samples - label_counts) / (label_counts + 1e-5)\n",
        "    return pos_weights"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer multiple labels"
      ],
      "metadata": {
        "id": "o0TJEbhQxRLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def dataset_stats(dl, ll):\n",
        "    len_list = []\n",
        "    for s in dl:\n",
        "        len_list.append(len(s))\n",
        "    sns.histplot(len_list)\n",
        "\n",
        "    p = 0\n",
        "    n = 0\n",
        "    for labels in ll:\n",
        "        found_pos = False\n",
        "        for l in labels:\n",
        "            if l:\n",
        "                p += 1\n",
        "                found_pos = True\n",
        "                break\n",
        "        if not found_pos:\n",
        "            n+=1\n",
        "    print(f'{p = }\\n{n = }')\n",
        "\n",
        "\n",
        "class TrainerMultipleClasses:\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.columns = [\n",
        "            'epoch',\n",
        "            'train_accuracy',\n",
        "            'train_precision',\n",
        "            'train_recall',\n",
        "            'train_fscore',\n",
        "            'train_loss',\n",
        "            'test_accuracy',\n",
        "            'test_precision',\n",
        "            'test_recall',\n",
        "            'test_fscore',\n",
        "            'test_loss'\n",
        "        ]\n",
        "        self.df = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.train(True)\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "            labels = labels.type(torch.float32)\n",
        "\n",
        "            loss = loss_fn(input=outputs, target=labels)\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            for b, lab in enumerate(labels):\n",
        "                out = torch.round(torch.sigmoid(outputs[b]))\n",
        "\n",
        "                for j, o in enumerate(out):\n",
        "                    # print(f'{o=}\\t{l=}')\n",
        "                    l = lab[j]\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "                    # print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels\n",
        "                outputs = self.model(inputs).to('cpu')\n",
        "                labels = labels.type(torch.float32)\n",
        "                loss = loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                for b, lab in enumerate(labels):\n",
        "                    out = torch.round(torch.sigmoid(outputs[b]))\n",
        "                    for j, o in enumerate(out):\n",
        "                        l = lab[j]\n",
        "                        if o == 1 and l == 1:\n",
        "                            tpos += 1\n",
        "                        elif o == 1 and l == 0:\n",
        "                            fpos += 1\n",
        "                        elif o == 0 and l == 0:\n",
        "                            tneg += 1\n",
        "                        elif o == 0 and l == 1:\n",
        "                            fneg += 1\n",
        "                        else:\n",
        "                            raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        # print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _load_into_dict(self, epoch, train_stats, test_stats):\n",
        "        row = [epoch] + list(train_stats) + list(test_stats)\n",
        "        row = pd.DataFrame(row, index=self.columns).T\n",
        "        self.df = pd.concat([self.df, row], axis=0)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_stats = self._train_one_epoch(train_iter)\n",
        "\n",
        "            test_stats = self._test_one_epoch(test_iter)\n",
        "            self._load_into_dict(epoch, train_stats, test_stats)\n",
        "            print(f\"[epoch {epoch:02d}] \"\n",
        "                  f\"train-loss={train_stats[-1]:.4f} | \"\n",
        "                  f\"test-loss={test_stats[-1]:.4f} | \"\n",
        "                  f\"train-acc={train_stats[0]:.4f} | \"\n",
        "                  f\"test-acc={test_stats[0]:.4f} | \"\n",
        "                  f\"P={test_stats[1]:.4f} | R={test_stats[2]:.4f} | F1={test_stats[3]:.4f}\")\n",
        "\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model multiple labels"
      ],
      "metadata": {
        "id": "xsJ8Xb1zxVYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, num_classes: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(1),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=64, bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.LazyLinear(out_features=num_classes, bias=use_bias)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load GO data multiple labels"
      ],
      "metadata": {
        "id": "5H-PP8bUxpCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "p_dl, p_ll, n_dl, n_ll = split_labelled_multiple_pos(dl, ll)\n",
        "n_dl, n_ll = remove_sequences_multiple_pos(n_dl, n_ll, 0.1)\n",
        "dl, ll = fuse_sequence_lists_multiple_pos(p_dl, p_ll, n_dl, n_ll)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.6)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "pos_weights = calculate_pos_weights(train_ll)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "8e80adb5-3f9b-4b9e-9199-8d4f9c2a9be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0, 14,  ..., 20, 20, 20],\n",
            "        [10, 19, 14,  ..., 20, 20, 20],\n",
            "        [10,  0,  6,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10, 17,  6,  ..., 20, 20, 20],\n",
            "        [10, 17,  6,  ..., 20, 20, 20],\n",
            "        [10,  3,  8,  ..., 20, 20, 20]]), tensor([[1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "45c03b8a-9efd-4b65-a98b-6355f74bac2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 1454\n",
            "n = 533\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model multiple labels"
      ],
      "metadata": {
        "id": "bcZoEI7-xuop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(num_classes=5, conv_channels=256, use_bias=True)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "522fb760-6dc9-401e-8bb6-f15194d6fe1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=64, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=50, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "04d5e80a-4bb9-490c-8796-3a3b0b878db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "<ipython-input-6-1a27aa51fb67>:112: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=1.1920 | test-loss=1.1838 | train-acc=0.4854 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 01] train-loss=1.1665 | test-loss=1.1852 | train-acc=0.4055 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 02] train-loss=1.1685 | test-loss=1.1838 | train-acc=0.4878 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 03] train-loss=1.1643 | test-loss=1.1831 | train-acc=0.4173 | test-acc=0.5572 | P=0.1547 | R=0.3716 | F1=0.2185\n",
            "[epoch 04] train-loss=1.1660 | test-loss=1.1844 | train-acc=0.5163 | test-acc=0.4196 | P=0.1551 | R=0.5589 | F1=0.2429\n",
            "[epoch 05] train-loss=1.1647 | test-loss=1.1842 | train-acc=0.4210 | test-acc=0.5572 | P=0.1547 | R=0.3716 | F1=0.2185\n",
            "[epoch 06] train-loss=1.1691 | test-loss=1.1840 | train-acc=0.4653 | test-acc=0.4553 | P=0.1849 | R=0.6662 | F1=0.2895\n",
            "[epoch 07] train-loss=1.1669 | test-loss=1.1838 | train-acc=0.5508 | test-acc=0.4181 | P=0.1539 | R=0.5544 | F1=0.2409\n",
            "[epoch 08] train-loss=1.1670 | test-loss=1.1853 | train-acc=0.4257 | test-acc=0.3824 | P=0.1241 | R=0.4471 | F1=0.1943\n",
            "[epoch 09] train-loss=1.1673 | test-loss=1.1857 | train-acc=0.4656 | test-acc=0.4181 | P=0.1539 | R=0.5544 | F1=0.2409\n",
            "[epoch 10] train-loss=1.1700 | test-loss=1.1847 | train-acc=0.4508 | test-acc=0.5572 | P=0.1547 | R=0.3716 | F1=0.2185\n",
            "[epoch 11] train-loss=1.1634 | test-loss=1.1858 | train-acc=0.3804 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 12] train-loss=1.1653 | test-loss=1.1822 | train-acc=0.3626 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 13] train-loss=1.1694 | test-loss=1.1830 | train-acc=0.4753 | test-acc=0.6176 | P=0.2302 | R=0.5529 | F1=0.3250\n",
            "[epoch 14] train-loss=1.1632 | test-loss=1.1831 | train-acc=0.5515 | test-acc=0.3177 | P=0.1777 | R=0.8535 | F1=0.2941\n",
            "[epoch 15] train-loss=1.1620 | test-loss=1.1845 | train-acc=0.4270 | test-acc=0.5940 | P=0.2006 | R=0.4819 | F1=0.2833\n",
            "[epoch 16] train-loss=1.1666 | test-loss=1.1836 | train-acc=0.6908 | test-acc=0.5940 | P=0.2006 | R=0.4819 | F1=0.2833\n",
            "[epoch 17] train-loss=1.1643 | test-loss=1.1831 | train-acc=0.5297 | test-acc=0.5804 | P=0.1836 | R=0.4411 | F1=0.2593\n",
            "[epoch 18] train-loss=1.1634 | test-loss=1.1851 | train-acc=0.3639 | test-acc=0.6823 | P=0.1220 | R=0.1465 | F1=0.1332\n",
            "[epoch 19] train-loss=1.1644 | test-loss=1.1848 | train-acc=0.5763 | test-acc=0.5683 | P=0.1686 | R=0.4048 | F1=0.2380\n",
            "[epoch 20] train-loss=1.1643 | test-loss=1.1829 | train-acc=0.4807 | test-acc=0.4307 | P=0.1644 | R=0.5921 | F1=0.2573\n",
            "[epoch 21] train-loss=1.1654 | test-loss=1.1822 | train-acc=0.5190 | test-acc=0.4800 | P=0.2055 | R=0.7402 | F1=0.3216\n",
            "[epoch 22] train-loss=1.1630 | test-loss=1.1844 | train-acc=0.5545 | test-acc=0.4800 | P=0.2055 | R=0.7402 | F1=0.3216\n",
            "[epoch 23] train-loss=1.1656 | test-loss=1.1834 | train-acc=0.5096 | test-acc=0.4553 | P=0.1849 | R=0.6662 | F1=0.2895\n",
            "[epoch 24] train-loss=1.1675 | test-loss=1.1859 | train-acc=0.4351 | test-acc=0.4196 | P=0.1551 | R=0.5589 | F1=0.2429\n",
            "[epoch 25] train-loss=1.1653 | test-loss=1.1839 | train-acc=0.5086 | test-acc=0.5336 | P=0.1252 | R=0.3006 | F1=0.1767\n",
            "[epoch 26] train-loss=1.1648 | test-loss=1.1820 | train-acc=0.4163 | test-acc=0.4428 | P=0.1744 | R=0.6284 | F1=0.2731\n",
            "[epoch 27] train-loss=1.1659 | test-loss=1.1844 | train-acc=0.5126 | test-acc=0.4196 | P=0.1551 | R=0.5589 | F1=0.2429\n",
            "[epoch 28] train-loss=1.1675 | test-loss=1.1859 | train-acc=0.4012 | test-acc=0.4060 | P=0.1438 | R=0.5181 | F1=0.2251\n",
            "[epoch 29] train-loss=1.1683 | test-loss=1.1836 | train-acc=0.4015 | test-acc=0.4307 | P=0.1644 | R=0.5921 | F1=0.2573\n",
            "[epoch 30] train-loss=1.1654 | test-loss=1.1851 | train-acc=0.3844 | test-acc=0.3177 | P=0.1777 | R=0.8535 | F1=0.2941\n",
            "[epoch 31] train-loss=1.1632 | test-loss=1.1826 | train-acc=0.5549 | test-acc=0.5200 | P=0.1082 | R=0.2598 | F1=0.1528\n",
            "[epoch 32] train-loss=1.1647 | test-loss=1.1854 | train-acc=0.6173 | test-acc=0.5200 | P=0.1082 | R=0.2598 | F1=0.1528\n",
            "[epoch 33] train-loss=1.1635 | test-loss=1.1841 | train-acc=0.4287 | test-acc=0.5572 | P=0.1547 | R=0.3716 | F1=0.2185\n",
            "[epoch 34] train-loss=1.1675 | test-loss=1.1847 | train-acc=0.5622 | test-acc=0.5683 | P=0.1686 | R=0.4048 | F1=0.2380\n",
            "[epoch 35] train-loss=1.1633 | test-loss=1.1830 | train-acc=0.3263 | test-acc=0.4307 | P=0.1644 | R=0.5921 | F1=0.2573\n",
            "[epoch 36] train-loss=1.1660 | test-loss=1.1830 | train-acc=0.4216 | test-acc=0.5447 | P=0.1390 | R=0.3338 | F1=0.1963\n",
            "[epoch 37] train-loss=1.1675 | test-loss=1.1845 | train-acc=0.5421 | test-acc=0.6712 | P=0.0943 | R=0.1133 | F1=0.1030\n",
            "[epoch 38] train-loss=1.1661 | test-loss=1.1819 | train-acc=0.4904 | test-acc=0.2684 | P=0.1469 | R=0.7054 | F1=0.2431\n",
            "[epoch 39] train-loss=1.1667 | test-loss=1.1860 | train-acc=0.4458 | test-acc=0.5572 | P=0.1547 | R=0.3716 | F1=0.2185\n",
            "[epoch 40] train-loss=1.1637 | test-loss=1.1818 | train-acc=0.4458 | test-acc=0.5447 | P=0.1390 | R=0.3338 | F1=0.1963\n",
            "[epoch 41] train-loss=1.1660 | test-loss=1.1861 | train-acc=0.3334 | test-acc=0.5447 | P=0.1390 | R=0.3338 | F1=0.1963\n",
            "[epoch 42] train-loss=1.1658 | test-loss=1.1855 | train-acc=0.4320 | test-acc=0.4181 | P=0.1539 | R=0.5544 | F1=0.2409\n",
            "[epoch 43] train-loss=1.1658 | test-loss=1.1833 | train-acc=0.5450 | test-acc=0.5203 | P=0.1082 | R=0.2598 | F1=0.1528\n",
            "[epoch 44] train-loss=1.1646 | test-loss=1.1839 | train-acc=0.4364 | test-acc=0.3824 | P=0.1241 | R=0.4471 | F1=0.1943\n",
            "[epoch 45] train-loss=1.1632 | test-loss=1.1839 | train-acc=0.5015 | test-acc=0.5200 | P=0.1082 | R=0.2598 | F1=0.1528\n",
            "[epoch 46] train-loss=1.1642 | test-loss=1.1840 | train-acc=0.6495 | test-acc=0.4553 | P=0.1849 | R=0.6662 | F1=0.2895\n",
            "[epoch 47] train-loss=1.1653 | test-loss=1.1843 | train-acc=0.4831 | test-acc=0.7316 | P=0.2453 | R=0.2946 | F1=0.2677\n",
            "[epoch 48] train-loss=1.1641 | test-loss=1.1841 | train-acc=0.5146 | test-acc=0.5940 | P=0.2006 | R=0.4819 | F1=0.2833\n",
            "[epoch 49] train-loss=1.1633 | test-loss=1.1835 | train-acc=0.6059 | test-acc=0.5693 | P=0.1698 | R=0.4079 | F1=0.2398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('multi-label_classifier.csv')"
      ],
      "metadata": {
        "id": "RiussApswGYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figures"
      ],
      "metadata": {
        "id": "uOilbtffBAiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "lRAB8mHEEOB7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat_df(df):\n",
        "    df = df.drop(\n",
        "        columns=['train_accuracy','train_precision','train_recall','train_fscore']\n",
        "    )\n",
        "    df = pd.melt(\n",
        "        df,\n",
        "        id_vars=['epoch'],\n",
        "        value_vars=['train_loss','test_accuracy','test_precision','test_recall','test_fscore','test_loss']\n",
        "    )\n",
        "    df.rename(columns={'epoch': 'Epoch', 'variable': 'Variable', 'value': 'Value'}, inplace=True)\n",
        "    # df = df.replace('train_accuracy', 'Train Accuracy')\n",
        "    # df = df.replace('train_precision', 'Train Precision')\n",
        "    # df = df.replace('train_recall', 'Train Recall')\n",
        "    # df = df.replace('train_fscore', 'Train F-score')\n",
        "    df = df.replace('train_loss', 'Train Loss')\n",
        "    df = df.replace('test_accuracy', 'Test Accuracy')\n",
        "    df = df.replace('test_precision', 'Test Precision')\n",
        "    df = df.replace('test_recall', 'Test Recall')\n",
        "    df = df.replace('test_fscore', 'Test F-score')\n",
        "    df = df.replace('test_loss', 'Test Loss')\n",
        "    return df\n",
        "\n",
        "\n",
        "def reformat_df_hyper(df):\n",
        "    df = df.drop(\n",
        "        columns=['train_accuracy','train_precision','train_recall','train_fscore']\n",
        "    )\n",
        "    df = pd.melt(\n",
        "        df,\n",
        "        id_vars=['epoch', 'conv_channels', 'dropout_rate', 'lr', 'momentum'],\n",
        "        value_vars=['train_loss','test_accuracy','test_precision','test_recall','test_fscore','test_loss']\n",
        "    )\n",
        "    df.rename(columns={'epoch': 'Epoch', 'variable': 'Variable', 'value': 'Value'}, inplace=True)\n",
        "    # df = df.replace('train_accuracy', 'Train Accuracy')\n",
        "    # df = df.replace('train_precision', 'Train Precision')\n",
        "    # df = df.replace('train_recall', 'Train Recall')\n",
        "    # df = df.replace('train_fscore', 'Train F-score')\n",
        "    df = df.replace('train_loss', 'Train Loss')\n",
        "    df = df.replace('test_accuracy', 'Test Accuracy')\n",
        "    df = df.replace('test_precision', 'Test Precision')\n",
        "    df = df.replace('test_recall', 'Test Recall')\n",
        "    df = df.replace('test_fscore', 'Test F-score')\n",
        "    df = df.replace('test_loss', 'Test Loss')\n",
        "    return df\n",
        "\n",
        "\n",
        "def plot_single_model(df, **kwargs):\n",
        "    ax = sns.lineplot(df, x='Epoch', y='Value', hue='Variable')\n",
        "    sns.move_legend(\n",
        "        obj=ax,\n",
        "        loc='upper left',\n",
        "        bbox_to_anchor=(1, 1)\n",
        "    )\n",
        "    if 'filepath' in kwargs.keys():\n",
        "        plt.savefig(kwargs['filepath'], format='svg', bbox_inches='tight')\n",
        "        plt.clf()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Test case\n",
        "df = pd.read_csv('GO_3A0005576.csv')\n",
        "df = reformat_df(df)\n",
        "plot_single_model(df)"
      ],
      "metadata": {
        "id": "GqAqH6ylA_w-",
        "outputId": "189af445-033a-4ae9-ac90-fd7b40d7b31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "go_csv = [\n",
        "    \"GO_3A0005576\",\n",
        "    \"GO_3A0005739\",\n",
        "    \"GO_3A0007165\",\n",
        "    \"GO_3A0043066\",\n",
        "    \"GO_3A0055085\"\n",
        "]\n",
        "\n",
        "\n",
        "for go in go_csv:\n",
        "    df = pd.read_csv(f'{go}.csv')\n",
        "    df = reformat_df(df)\n",
        "    plot_single_model(df, filepath=f'{go}.svg')\n"
      ],
      "metadata": {
        "id": "lf0fZG0CF_gQ",
        "outputId": "c5f84aba-7079-4062-8d9b-68ce97f7d605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_csv = [\n",
        "    'half_neg_len200_500_n5000nr1',\n",
        "    'half_pos_len200_500_n5000nr1'\n",
        "]\n",
        "\n",
        "for sim in sim_csv:\n",
        "    df = pd.read_csv(f'{sim}.csv')\n",
        "    df = reformat_df(df)\n",
        "    plot_single_model(df, filepath=f'{sim}.svg')"
      ],
      "metadata": {
        "id": "0sro9icJHXQt",
        "outputId": "ebcba2a3-3e6d-49c3-b35f-04669a29033d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('GO_3A0005576_full_set.csv')\n",
        "df = reformat_df(df)\n",
        "plot_single_model(df, filepath='GO_3A0005576_full_set.svg')"
      ],
      "metadata": {
        "id": "7F5zlDwEJxeb",
        "outputId": "8ef584d1-2701-4381-93f5-474957462018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('hyperparameter_grid_len200_500_n5000nr1.csv')\n",
        "df = reformat_df_hyper(df)\n",
        "\n",
        "groups = df.groupby(['conv_channels', 'dropout_rate', 'lr', 'momentum'])\n",
        "\n",
        "split_dfs = {name: group for name, group in groups}\n",
        "\n",
        "for key in split_dfs.keys():\n",
        "    sub_df = split_dfs[key]\n",
        "    path = f'hyper_conv_channels_{key[0]}_dropout_{key[1]}_lr_{key[2]}_momentum_{key[3]}'.replace('.', '_') + '.svg'\n",
        "    plot_single_model(sub_df, filepath=path)"
      ],
      "metadata": {
        "id": "DaYwNE_JJ8F9",
        "outputId": "8b2923e7-b8b0-4bfc-82f6-c04c9eaaf4ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}