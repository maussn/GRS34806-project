{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bioinformatics Project 2025 - Motif CNN & GO Prediction\n",
        "\n",
        "**Course:** GRS34806 Deep Learning\n",
        "\n",
        "**Authors:** Berkay Helvaci & Maurits Naber\n",
        "\n",
        "**Date:** 04/2025\n",
        "\n"
      ],
      "metadata": {
        "id": "HuP5FaUF6YLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "YbtfKAzz6ct5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the code last time! also the redundant libraries."
      ],
      "metadata": {
        "id": "amk7R7B2kcma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q\n",
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "Emlqnf_rAIWr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data I/O & Tokenisation"
      ],
      "metadata": {
        "id": "g96CRPCRCbdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. read() --------------------------------------------------------------------\n",
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 2. split_labelled() ----------------------------------------------------------\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    \"\"\"Return two separate sequence lists: positives & negatives.\"\"\"\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "# 3. remove_sequences() -----\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    \"\"\"Randomly keeps half of the list\"\"\"\n",
        "    random.shuffle(datalist)\n",
        "    keep = round(len(datalist) * fraction)\n",
        "    return datalist[:keep]\n",
        "\n",
        "\n",
        "# 4. fuse_sequence_lists() ------------\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    \"\"\"Merge postives and negetaves into one list + label\"\"\"\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 5. generate_train_test() --------\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "# 6. Tokenisation & Padding --------\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "# 7. load_array() & load_data()\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter\n",
        "\n",
        "\n",
        "def read_fasta(fasta):\n",
        "    seqs = []\n",
        "    with open(fasta, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if line[0] == '>':\n",
        "                continue\n",
        "            else:\n",
        "                seqs.append(line.rstrip('\\n'))\n",
        "    return seqs"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "_b5Kq5jEKZwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "9a5774f7-b9ae-4857-fb9b-1cb5c0e282c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training / Evaluation"
      ],
      "metadata": {
        "id": "BhuHUN6TRLun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    # Initialize weights in the model suing xavier_uniform\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    # Trainer class\n",
        "    def __init__(self, model, loss_fn, optimizer, device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.columns = [\n",
        "            'epoch',\n",
        "            'train_accuracy',\n",
        "            'train_precision',\n",
        "            'train_recall',\n",
        "            'train_fscore',\n",
        "            'train_loss',\n",
        "            'test_accuracy',\n",
        "            'test_precision',\n",
        "            'test_recall',\n",
        "            'test_fscore',\n",
        "            'test_loss'\n",
        "        ]\n",
        "        self.df = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "\n",
        "    # One training epoch -------------------------------------------------------\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.train(True)\n",
        "\n",
        "        # Iterate through batches and train model\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            # Confusion matrix calculation for each output\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j])) # Index = 0 means unannotated, index = 1 means annotated\n",
        "                l = l.item()\n",
        "                if o == 1 and l == 1:\n",
        "                    tpos += 1\n",
        "                elif o == 1 and l == 0:\n",
        "                    fpos += 1\n",
        "                elif o == 0 and l == 0:\n",
        "                    tneg += 1\n",
        "                elif o == 0 and l == 1:\n",
        "                    fneg += 1\n",
        "                else:\n",
        "                    raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "    # Evaluation epoch ---------------------------------------------------------\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter, start=1):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "\n",
        "                # Confusion matrix calculation\n",
        "                for j, l in enumerate(labels):\n",
        "                    o = outputs[j].tolist().index(max(outputs[j])) # Index = 0 means unannotated, index = 1 means annotated\n",
        "                    l = l.item()\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _load_into_dict(self, epoch, train_stats, test_stats):\n",
        "        row = [epoch] + list(train_stats) + list(test_stats)\n",
        "        row = pd.DataFrame(row, index=self.columns).T\n",
        "        self.df = pd.concat([self.df, row], axis=0)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_stats = self._train_one_epoch(train_iter)\n",
        "\n",
        "            test_stats = self._test_one_epoch(test_iter)\n",
        "            self._load_into_dict(epoch, train_stats, test_stats)\n",
        "            print(f\"[epoch {epoch:02d}] \"\n",
        "                  f\"train-loss={train_stats[-1]:.4f} | \"\n",
        "                  f\"test-loss={test_stats[-1]:.4f} | \"\n",
        "                  f\"train-acc={train_stats[0]:.4f} | \"\n",
        "                  f\"test-acc={test_stats[0]:.4f} | \"\n",
        "                  f\"P={test_stats[1]:.4f} | R={test_stats[2]:.4f} | F1={test_stats[3]:.4f}\")\n",
        "\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "C0xPrmp3jHjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, vocab_size: int = 21,\n",
        "                 dropout_rate = 0, conv_channels: int = 128,\n",
        "                 use_bias: bool = False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "UeAeB8Wo79Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "param_grid = {\n",
        "    'dropout_rate': [0, 0.3],\n",
        "    'lr': [0.01, 0.001],\n",
        "    'momentum': [0, 0.5],\n",
        "    'conv_channels': [64, 128]\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "df = None\n",
        "\n",
        "# Train the model on each parameter combination\n",
        "for params in grid:\n",
        "    print(\"Current hyper-parameters:\", params)\n",
        "    model = BerryCNN1D(\n",
        "        vocab_size=21,\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        conv_channels=params['conv_channels']\n",
        "    )\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        momentum=params['momentum']\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "\n",
        "    out_df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    # Load training statistics into dataframe for figures later\n",
        "    for p in params.keys():\n",
        "        out_df[p] = params[p]\n",
        "\n",
        "    acc = out_df['test_accuracy'].max()\n",
        "\n",
        "    if acc >= best_acc:\n",
        "        best_acc = []\n",
        "        best_acc = acc\n",
        "        best_params = params\n",
        "        print(f\"New best accuracy {best_acc:.4f} with {best_params} \\n\")\n",
        "\n",
        "    if type(df) != pd.DataFrame:\n",
        "        df = out_df\n",
        "    else:\n",
        "        df = pd.concat([df, out_df], axis=0)\n",
        "\n",
        "print(\"Best hyperâ€‘parameters found:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HESI-RwU5o",
        "outputId": "4f82f392-8efa-42a8-ecaf-b523e8d3d7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4473 | test-loss=0.0441 | train-acc=0.7605 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 01] train-loss=0.0196 | test-loss=0.0093 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0068 | test-loss=0.0045 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0042 | test-loss=0.0030 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0030 | test-loss=0.0021 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0023 | test-loss=0.0017 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0018 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0015 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0013 | test-loss=0.0010 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0011 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1593 | test-loss=0.0078 | train-acc=0.9337 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0044 | test-loss=0.0031 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0021 | test-loss=0.0019 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0013 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0010 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0008 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0006 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0005 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0004 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0004 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7035 | test-loss=0.6826 | train-acc=0.5045 | test-acc=0.5390 | P=0.5675 | R=0.4769 | F1=0.5183\n",
            "[epoch 01] train-loss=0.6851 | test-loss=0.6702 | train-acc=0.5605 | test-acc=0.5750 | P=0.5604 | R=0.8481 | F1=0.6748\n",
            "[epoch 02] train-loss=0.6657 | test-loss=0.6565 | train-acc=0.6310 | test-acc=0.6230 | P=0.8824 | R=0.3173 | F1=0.4668\n",
            "[epoch 03] train-loss=0.6267 | test-loss=0.5976 | train-acc=0.7220 | test-acc=0.7510 | P=0.8538 | R=0.6288 | F1=0.7243\n",
            "[epoch 04] train-loss=0.5370 | test-loss=0.4589 | train-acc=0.8570 | test-acc=0.9550 | P=0.9857 | R=0.9269 | F1=0.9554\n",
            "[epoch 05] train-loss=0.3603 | test-loss=0.2700 | train-acc=0.9895 | test-acc=0.9960 | P=0.9924 | R=1.0000 | F1=0.9962\n",
            "[epoch 06] train-loss=0.2055 | test-loss=0.1541 | train-acc=0.9990 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 07] train-loss=0.1196 | test-loss=0.0940 | train-acc=0.9995 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 08] train-loss=0.0766 | test-loss=0.0642 | train-acc=1.0000 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 09] train-loss=0.0538 | test-loss=0.0474 | train-acc=1.0000 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6966 | test-loss=0.6864 | train-acc=0.5002 | test-acc=0.5140 | P=0.5500 | R=0.3596 | F1=0.4349\n",
            "[epoch 01] train-loss=0.6840 | test-loss=0.6629 | train-acc=0.5590 | test-acc=0.6290 | P=0.5995 | R=0.8635 | F1=0.7076\n",
            "[epoch 02] train-loss=0.5593 | test-loss=0.3560 | train-acc=0.8650 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.1860 | test-loss=0.0907 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0578 | test-loss=0.0404 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0295 | test-loss=0.0244 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0189 | test-loss=0.0172 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0137 | test-loss=0.0131 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0106 | test-loss=0.0105 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0086 | test-loss=0.0088 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6026 | test-loss=0.1952 | train-acc=0.6530 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 01] train-loss=0.1435 | test-loss=0.0372 | train-acc=0.9580 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 02] train-loss=0.0524 | test-loss=0.0110 | train-acc=0.9858 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0369 | test-loss=0.0081 | train-acc=0.9900 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0270 | test-loss=0.0052 | train-acc=0.9915 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0237 | test-loss=0.0077 | train-acc=0.9940 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0216 | test-loss=0.0068 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0211 | test-loss=0.0033 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0207 | test-loss=0.0044 | train-acc=0.9938 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0182 | test-loss=0.0046 | train-acc=0.9948 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4366 | test-loss=0.0229 | train-acc=0.7542 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0356 | test-loss=0.0106 | train-acc=0.9912 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0244 | test-loss=0.0062 | train-acc=0.9948 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0188 | test-loss=0.0068 | train-acc=0.9955 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0096 | test-loss=0.0046 | train-acc=0.9982 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 05] train-loss=0.0073 | test-loss=0.0025 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0065 | test-loss=0.0026 | train-acc=0.9982 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0044 | test-loss=0.0024 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0050 | test-loss=0.0016 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0053 | test-loss=0.0039 | train-acc=0.9988 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7633 | test-loss=0.6884 | train-acc=0.4968 | test-acc=0.5100 | P=0.5852 | R=0.1981 | F1=0.2960\n",
            "[epoch 01] train-loss=0.7195 | test-loss=0.6728 | train-acc=0.5100 | test-acc=0.5670 | P=0.5589 | R=0.7942 | F1=0.6561\n",
            "[epoch 02] train-loss=0.6985 | test-loss=0.6517 | train-acc=0.5375 | test-acc=0.7220 | P=0.7597 | R=0.6808 | F1=0.7181\n",
            "[epoch 03] train-loss=0.6628 | test-loss=0.5927 | train-acc=0.6132 | test-acc=0.9160 | P=0.8759 | R=0.9769 | F1=0.9236\n",
            "[epoch 04] train-loss=0.5928 | test-loss=0.4925 | train-acc=0.7245 | test-acc=0.9870 | P=0.9756 | R=1.0000 | F1=0.9877\n",
            "[epoch 05] train-loss=0.4836 | test-loss=0.3565 | train-acc=0.8190 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 06] train-loss=0.3605 | test-loss=0.2285 | train-acc=0.8922 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 07] train-loss=0.2747 | test-loss=0.1483 | train-acc=0.9290 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "[epoch 08] train-loss=0.2093 | test-loss=0.0953 | train-acc=0.9453 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "[epoch 09] train-loss=0.1679 | test-loss=0.0756 | train-acc=0.9557 | test-acc=0.9970 | P=0.9943 | R=1.0000 | F1=0.9971\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7220 | test-loss=0.6688 | train-acc=0.5072 | test-acc=0.5380 | P=0.5298 | R=0.9904 | F1=0.6903\n",
            "[epoch 01] train-loss=0.6366 | test-loss=0.4940 | train-acc=0.6378 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.4142 | test-loss=0.2130 | train-acc=0.8690 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.2519 | test-loss=0.0994 | train-acc=0.9377 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1649 | test-loss=0.0591 | train-acc=0.9583 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.1345 | test-loss=0.0432 | train-acc=0.9627 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.1070 | test-loss=0.0335 | train-acc=0.9710 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0968 | test-loss=0.0292 | train-acc=0.9745 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0782 | test-loss=0.0241 | train-acc=0.9805 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0666 | test-loss=0.0196 | train-acc=0.9845 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.2003 | test-loss=0.0157 | train-acc=0.9205 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0089 | test-loss=0.0054 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0040 | test-loss=0.0031 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0025 | test-loss=0.0021 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0018 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0014 | test-loss=0.0013 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0012 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0010 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0008 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0007 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1454 | test-loss=0.0066 | train-acc=0.9337 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0038 | test-loss=0.0027 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0019 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0012 | test-loss=0.0012 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0009 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0007 | test-loss=0.0008 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0006 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0005 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0004 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0004 | test-loss=0.0004 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6912 | test-loss=0.6771 | train-acc=0.5310 | test-acc=0.5470 | P=0.5356 | R=0.9692 | F1=0.6899\n",
            "[epoch 01] train-loss=0.6635 | test-loss=0.6234 | train-acc=0.6522 | test-acc=0.8210 | P=0.7549 | R=0.9712 | F1=0.8495\n",
            "[epoch 02] train-loss=0.5465 | test-loss=0.4256 | train-acc=0.9350 | test-acc=0.9950 | P=0.9905 | R=1.0000 | F1=0.9952\n",
            "[epoch 03] train-loss=0.3028 | test-loss=0.1943 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1364 | test-loss=0.0934 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0717 | test-loss=0.0548 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0448 | test-loss=0.0367 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0313 | test-loss=0.0270 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0236 | test-loss=0.0211 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0187 | test-loss=0.0171 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6947 | test-loss=0.6558 | train-acc=0.5195 | test-acc=0.5950 | P=0.5626 | R=0.9942 | F1=0.7186\n",
            "[epoch 01] train-loss=0.5590 | test-loss=0.3783 | train-acc=0.8702 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.2137 | test-loss=0.1046 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0662 | test-loss=0.0426 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0316 | test-loss=0.0242 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0195 | test-loss=0.0163 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0137 | test-loss=0.0120 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0104 | test-loss=0.0094 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0083 | test-loss=0.0077 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0069 | test-loss=0.0065 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3869 | test-loss=0.0343 | train-acc=0.8073 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0526 | test-loss=0.0163 | train-acc=0.9875 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0263 | test-loss=0.0068 | train-acc=0.9940 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0151 | test-loss=0.0045 | train-acc=0.9960 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0124 | test-loss=0.0031 | train-acc=0.9968 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0105 | test-loss=0.0026 | train-acc=0.9972 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0105 | test-loss=0.0025 | train-acc=0.9978 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0052 | test-loss=0.0015 | train-acc=0.9992 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0059 | test-loss=0.0015 | train-acc=0.9982 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0056 | test-loss=0.0010 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3032 | test-loss=0.0183 | train-acc=0.8482 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0233 | test-loss=0.0034 | train-acc=0.9938 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0147 | test-loss=0.0027 | train-acc=0.9970 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0083 | test-loss=0.0017 | train-acc=0.9972 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0050 | test-loss=0.0021 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0054 | test-loss=0.0026 | train-acc=0.9985 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0051 | test-loss=0.0019 | train-acc=0.9988 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0027 | test-loss=0.0010 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0031 | test-loss=0.0007 | train-acc=0.9995 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0019 | test-loss=0.0018 | train-acc=0.9998 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7327 | test-loss=0.6814 | train-acc=0.5052 | test-acc=0.5590 | P=0.6000 | R=0.4558 | F1=0.5180\n",
            "[epoch 01] train-loss=0.6989 | test-loss=0.6509 | train-acc=0.5407 | test-acc=0.7810 | P=0.7980 | R=0.7750 | F1=0.7863\n",
            "[epoch 02] train-loss=0.6485 | test-loss=0.5735 | train-acc=0.6282 | test-acc=0.9860 | P=1.0000 | R=0.9731 | F1=0.9864\n",
            "[epoch 03] train-loss=0.5637 | test-loss=0.4580 | train-acc=0.7628 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.4722 | test-loss=0.3399 | train-acc=0.8355 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.4071 | test-loss=0.2624 | train-acc=0.8462 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.3606 | test-loss=0.2070 | train-acc=0.8512 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 07] train-loss=0.3143 | test-loss=0.1577 | train-acc=0.8690 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.2755 | test-loss=0.1186 | train-acc=0.9050 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.2393 | test-loss=0.0969 | train-acc=0.9335 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-683adbe3301c>:107: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.7109 | test-loss=0.6522 | train-acc=0.5220 | test-acc=0.7120 | P=0.9056 | R=0.4981 | F1=0.6427\n",
            "[epoch 01] train-loss=0.5907 | test-loss=0.4010 | train-acc=0.6910 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 02] train-loss=0.3565 | test-loss=0.1776 | train-acc=0.8970 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.2197 | test-loss=0.0876 | train-acc=0.9450 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.1541 | test-loss=0.0525 | train-acc=0.9603 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.1123 | test-loss=0.0364 | train-acc=0.9680 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 06] train-loss=0.0853 | test-loss=0.0259 | train-acc=0.9780 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0723 | test-loss=0.0249 | train-acc=0.9772 | test-acc=0.9990 | P=0.9981 | R=1.0000 | F1=0.9990\n",
            "[epoch 08] train-loss=0.0531 | test-loss=0.0208 | train-acc=0.9868 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "[epoch 09] train-loss=0.0448 | test-loss=0.0174 | train-acc=0.9882 | test-acc=0.9980 | P=0.9962 | R=1.0000 | F1=0.9981\n",
            "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Best hyperâ€‘parameters found: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on reduced datasets"
      ],
      "metadata": {
        "id": "8ZdNGslz0cAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half of positives"
      ],
      "metadata": {
        "id": "301fqHMW1mGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "pos_datalist = remove_sequences(pos_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "\n",
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n58u1CAg0rbb",
        "outputId": "af011a41-be1e-4133-8498-84c10298b858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.2455 | test-loss=0.0126 | train-acc=0.8971 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 01] train-loss=0.0077 | test-loss=0.0040 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0034 | test-loss=0.0021 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0021 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0016 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0012 | test-loss=0.0009 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0010 | test-loss=0.0007 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0008 | test-loss=0.0006 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0007 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0006 | test-loss=0.0005 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('half_pos_len200_500_n5000nr1.csv')"
      ],
      "metadata": {
        "id": "SjVt5LX-1S80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half of negatives"
      ],
      "metadata": {
        "id": "qaxou8V21paQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"len200_500_n5000nr1.seq\", \"len200_500_n5000nr1.pos\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfBF1M-W1h9I",
        "outputId": "315707a3-2da9-4416-ae91-92e6248f6408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcLovPuh1r3s",
        "outputId": "d3a9da20-f064-499e-8011-86da3d7a4f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-1cb05001b72f>:128: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.5165 | test-loss=0.0688 | train-acc=0.7465 | test-acc=0.9960 | P=0.9941 | R=1.0000 | F1=0.9970\n",
            "[epoch 01] train-loss=0.0241 | test-loss=0.0087 | train-acc=0.9983 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 02] train-loss=0.0067 | test-loss=0.0043 | train-acc=0.9993 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 03] train-loss=0.0038 | test-loss=0.0029 | train-acc=0.9997 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 04] train-loss=0.0025 | test-loss=0.0022 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 05] train-loss=0.0019 | test-loss=0.0018 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 06] train-loss=0.0015 | test-loss=0.0016 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 07] train-loss=0.0012 | test-loss=0.0014 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 08] train-loss=0.0010 | test-loss=0.0012 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
            "[epoch 09] train-loss=0.0009 | test-loss=0.0011 | train-acc=1.0000 | test-acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('half_neg_len200_500_n5000nr1.csv')"
      ],
      "metadata": {
        "id": "B2dtThLk1t0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on GO annotations"
      ],
      "metadata": {
        "id": "L6-AIB-L0ToX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full set"
      ],
      "metadata": {
        "id": "1MI_br9w7v9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0005576.annotprot\")\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0.2,conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "df.to_csv(\"GO_3A0005576_full_set.csv\")\n"
      ],
      "metadata": {
        "id": "yDEFWAwbK_s3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d299a2-8393-493d-cd7f-9a170ae988fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1911 | test-loss=0.1870 | train-acc=0.9536 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.1806 | test-loss=0.1850 | train-acc=0.9552 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.1770 | test-loss=0.1879 | train-acc=0.9552 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.1747 | test-loss=0.1819 | train-acc=0.9552 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.1687 | test-loss=0.1829 | train-acc=0.9552 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.1582 | test-loss=0.1812 | train-acc=0.9552 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.1497 | test-loss=0.1750 | train-acc=0.9554 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.1390 | test-loss=0.1764 | train-acc=0.9569 | test-acc=0.9528 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.1271 | test-loss=0.1671 | train-acc=0.9584 | test-acc=0.9528 | P=0.5000 | R=0.0156 | F1=0.0303\n",
            "[epoch 09] train-loss=0.1137 | test-loss=0.1725 | train-acc=0.9611 | test-acc=0.9543 | P=0.6250 | R=0.0781 | F1=0.1389\n",
            "[epoch 10] train-loss=0.1032 | test-loss=0.1866 | train-acc=0.9646 | test-acc=0.9528 | P=0.5000 | R=0.0156 | F1=0.0303\n",
            "[epoch 11] train-loss=0.0880 | test-loss=0.1878 | train-acc=0.9672 | test-acc=0.9565 | P=0.6087 | R=0.2188 | F1=0.3218\n",
            "[epoch 12] train-loss=0.0790 | test-loss=0.2131 | train-acc=0.9727 | test-acc=0.9528 | P=0.5000 | R=0.0156 | F1=0.0303\n",
            "[epoch 13] train-loss=0.0686 | test-loss=0.1638 | train-acc=0.9749 | test-acc=0.9536 | P=0.5556 | R=0.0781 | F1=0.1370\n",
            "[epoch 14] train-loss=0.0596 | test-loss=0.2037 | train-acc=0.9807 | test-acc=0.9536 | P=0.6667 | R=0.0312 | F1=0.0597\n",
            "[epoch 15] train-loss=0.0445 | test-loss=0.2344 | train-acc=0.9849 | test-acc=0.9528 | P=0.5000 | R=0.0156 | F1=0.0303\n",
            "[epoch 16] train-loss=0.0425 | test-loss=0.1733 | train-acc=0.9856 | test-acc=0.9536 | P=0.5333 | R=0.1250 | F1=0.2025\n",
            "[epoch 17] train-loss=0.0354 | test-loss=0.1775 | train-acc=0.9891 | test-acc=0.9521 | P=0.4545 | R=0.0781 | F1=0.1333\n",
            "[epoch 18] train-loss=0.0322 | test-loss=0.2177 | train-acc=0.9897 | test-acc=0.9543 | P=0.7500 | R=0.0469 | F1=0.0882\n",
            "[epoch 19] train-loss=0.0229 | test-loss=0.1852 | train-acc=0.9934 | test-acc=0.9521 | P=0.4667 | R=0.1094 | F1=0.1772\n",
            "[epoch 20] train-loss=0.0208 | test-loss=0.2130 | train-acc=0.9958 | test-acc=0.9550 | P=0.8000 | R=0.0625 | F1=0.1159\n",
            "[epoch 21] train-loss=0.0178 | test-loss=0.1901 | train-acc=0.9956 | test-acc=0.9425 | P=0.3478 | R=0.2500 | F1=0.2909\n",
            "[epoch 22] train-loss=0.0177 | test-loss=0.2282 | train-acc=0.9961 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 23] train-loss=0.0136 | test-loss=0.2024 | train-acc=0.9969 | test-acc=0.9543 | P=0.6250 | R=0.0781 | F1=0.1389\n",
            "[epoch 24] train-loss=0.0133 | test-loss=0.2225 | train-acc=0.9978 | test-acc=0.9536 | P=0.5714 | R=0.0625 | F1=0.1127\n",
            "[epoch 25] train-loss=0.0105 | test-loss=0.2264 | train-acc=0.9983 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 26] train-loss=0.0114 | test-loss=0.2298 | train-acc=0.9978 | test-acc=0.9536 | P=0.5714 | R=0.0625 | F1=0.1127\n",
            "[epoch 27] train-loss=0.0104 | test-loss=0.2645 | train-acc=0.9987 | test-acc=0.9543 | P=0.7500 | R=0.0469 | F1=0.0882\n",
            "[epoch 28] train-loss=0.0100 | test-loss=0.2403 | train-acc=0.9980 | test-acc=0.9536 | P=0.5714 | R=0.0625 | F1=0.1127\n",
            "[epoch 29] train-loss=0.0105 | test-loss=0.2674 | train-acc=0.9976 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 30] train-loss=0.0057 | test-loss=0.2812 | train-acc=0.9994 | test-acc=0.9550 | P=0.8000 | R=0.0625 | F1=0.1159\n",
            "[epoch 31] train-loss=0.0050 | test-loss=0.2695 | train-acc=0.9998 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 32] train-loss=0.0050 | test-loss=0.2366 | train-acc=0.9994 | test-acc=0.9528 | P=0.5000 | R=0.0938 | F1=0.1579\n",
            "[epoch 33] train-loss=0.0053 | test-loss=0.2573 | train-acc=0.9993 | test-acc=0.9558 | P=0.7500 | R=0.0938 | F1=0.1667\n",
            "[epoch 34] train-loss=0.0049 | test-loss=0.2940 | train-acc=0.9993 | test-acc=0.9543 | P=0.7500 | R=0.0469 | F1=0.0882\n",
            "[epoch 35] train-loss=0.0052 | test-loss=0.2770 | train-acc=0.9993 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 36] train-loss=0.0044 | test-loss=0.2946 | train-acc=0.9996 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 37] train-loss=0.0059 | test-loss=0.2966 | train-acc=0.9993 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 38] train-loss=0.0056 | test-loss=0.2778 | train-acc=0.9987 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 39] train-loss=0.0061 | test-loss=0.2830 | train-acc=0.9991 | test-acc=0.9543 | P=0.7500 | R=0.0469 | F1=0.0882\n",
            "[epoch 40] train-loss=0.0040 | test-loss=0.3175 | train-acc=0.9996 | test-acc=0.9536 | P=0.6000 | R=0.0469 | F1=0.0870\n",
            "[epoch 41] train-loss=0.0044 | test-loss=0.3014 | train-acc=0.9993 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 42] train-loss=0.0033 | test-loss=0.2958 | train-acc=0.9996 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 43] train-loss=0.0066 | test-loss=0.2775 | train-acc=0.9980 | test-acc=0.9550 | P=0.7143 | R=0.0781 | F1=0.1408\n",
            "[epoch 44] train-loss=0.0048 | test-loss=0.4802 | train-acc=0.9991 | test-acc=0.9536 | P=0.6667 | R=0.0312 | F1=0.0597\n",
            "[epoch 45] train-loss=0.0036 | test-loss=0.3312 | train-acc=0.9994 | test-acc=0.9543 | P=0.7500 | R=0.0469 | F1=0.0882\n",
            "[epoch 46] train-loss=0.0028 | test-loss=0.2624 | train-acc=0.9998 | test-acc=0.9543 | P=0.6000 | R=0.0938 | F1=0.1622\n",
            "[epoch 47] train-loss=0.0037 | test-loss=0.3206 | train-acc=0.9991 | test-acc=0.9543 | P=0.6667 | R=0.0625 | F1=0.1143\n",
            "[epoch 48] train-loss=0.0034 | test-loss=0.2755 | train-acc=0.9996 | test-acc=0.9536 | P=0.5556 | R=0.0781 | F1=0.1370\n",
            "[epoch 49] train-loss=0.0021 | test-loss=0.3178 | train-acc=0.9998 | test-acc=0.9550 | P=0.8000 | R=0.0625 | F1=0.1159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half positives"
      ],
      "metadata": {
        "id": "0keR8voU7yTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0005576.annotprot\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "pos_datalist = remove_sequences(pos_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0.2,conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "df.to_csv(\"GO_3A0005576_half_pos.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ITkHkZ67k0N",
        "outputId": "7e63b7d1-877f-4181-cbe0-f0bdf0e9c425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.1183 | test-loss=0.1066 | train-acc=0.9746 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.1124 | test-loss=0.1091 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.1104 | test-loss=0.1083 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.1086 | test-loss=0.1074 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.1065 | test-loss=0.1018 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.1013 | test-loss=0.1037 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.0985 | test-loss=0.1006 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.0928 | test-loss=0.0990 | train-acc=0.9764 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.0905 | test-loss=0.1088 | train-acc=0.9766 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.0841 | test-loss=0.0984 | train-acc=0.9766 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.0798 | test-loss=0.0964 | train-acc=0.9768 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 11] train-loss=0.0707 | test-loss=0.0981 | train-acc=0.9776 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 12] train-loss=0.0690 | test-loss=0.1009 | train-acc=0.9783 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 13] train-loss=0.0573 | test-loss=0.0964 | train-acc=0.9808 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 14] train-loss=0.0535 | test-loss=0.0966 | train-acc=0.9815 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 15] train-loss=0.0458 | test-loss=0.1175 | train-acc=0.9845 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 16] train-loss=0.0374 | test-loss=0.1055 | train-acc=0.9868 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 17] train-loss=0.0315 | test-loss=0.1021 | train-acc=0.9900 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 18] train-loss=0.0302 | test-loss=0.1431 | train-acc=0.9902 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 19] train-loss=0.0234 | test-loss=0.1006 | train-acc=0.9928 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 20] train-loss=0.0194 | test-loss=0.1054 | train-acc=0.9942 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 21] train-loss=0.0157 | test-loss=0.1465 | train-acc=0.9959 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 22] train-loss=0.0138 | test-loss=0.1205 | train-acc=0.9959 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 23] train-loss=0.0122 | test-loss=0.1079 | train-acc=0.9972 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 24] train-loss=0.0112 | test-loss=0.1504 | train-acc=0.9981 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 25] train-loss=0.0094 | test-loss=0.1285 | train-acc=0.9983 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 26] train-loss=0.0088 | test-loss=0.1126 | train-acc=0.9981 | test-acc=0.9766 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 27] train-loss=0.0066 | test-loss=0.1507 | train-acc=0.9992 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 28] train-loss=0.0072 | test-loss=0.1198 | train-acc=0.9981 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 29] train-loss=0.0065 | test-loss=0.1244 | train-acc=0.9992 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 30] train-loss=0.0044 | test-loss=0.1359 | train-acc=0.9996 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 31] train-loss=0.0044 | test-loss=0.1209 | train-acc=0.9994 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 32] train-loss=0.0033 | test-loss=0.1336 | train-acc=1.0000 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 33] train-loss=0.0042 | test-loss=0.1461 | train-acc=0.9996 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 34] train-loss=0.0032 | test-loss=0.1669 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 35] train-loss=0.0032 | test-loss=0.1522 | train-acc=1.0000 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 36] train-loss=0.0023 | test-loss=0.1718 | train-acc=1.0000 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 37] train-loss=0.0042 | test-loss=0.1614 | train-acc=0.9992 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 38] train-loss=0.0033 | test-loss=0.1440 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 39] train-loss=0.0022 | test-loss=0.1604 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 40] train-loss=0.0024 | test-loss=0.1477 | train-acc=0.9998 | test-acc=0.9774 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 41] train-loss=0.0022 | test-loss=0.1417 | train-acc=1.0000 | test-acc=0.9766 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 42] train-loss=0.0022 | test-loss=0.1296 | train-acc=0.9998 | test-acc=0.9766 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 43] train-loss=0.0027 | test-loss=0.1626 | train-acc=0.9996 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 44] train-loss=0.0023 | test-loss=0.1648 | train-acc=0.9996 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 45] train-loss=0.0020 | test-loss=0.1711 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 46] train-loss=0.0017 | test-loss=0.1573 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 47] train-loss=0.0016 | test-loss=0.1598 | train-acc=1.0000 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 48] train-loss=0.0013 | test-loss=0.1624 | train-acc=1.0000 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 49] train-loss=0.0018 | test-loss=0.1599 | train-acc=0.9998 | test-acc=0.9781 | P=0.0000 | R=0.0000 | F1=0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Half negatives"
      ],
      "metadata": {
        "id": "WBv-Uvbj72-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0005576.annotprot\")\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "model = BerryCNN1D(vocab_size=21,dropout_rate=0.2,conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.01,\n",
        "    momentum=0.5\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "df.to_csv(\"GO_3A0005576_half_neg.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6ki3olN73Ut",
        "outputId": "bec6d4fc-f8f1-461a-da77-9096c6c6a0b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.3024 | test-loss=0.2880 | train-acc=0.9140 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.2884 | test-loss=0.2869 | train-acc=0.9140 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.2862 | test-loss=0.2843 | train-acc=0.9140 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.2692 | test-loss=0.2850 | train-acc=0.9140 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.2663 | test-loss=0.2747 | train-acc=0.9143 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.2487 | test-loss=0.3015 | train-acc=0.9140 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.2306 | test-loss=0.2782 | train-acc=0.9171 | test-acc=0.9111 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2155 | test-loss=0.2530 | train-acc=0.9224 | test-acc=0.9126 | P=1.0000 | R=0.0159 | F1=0.0312\n",
            "[epoch 08] train-loss=0.1931 | test-loss=0.2868 | train-acc=0.9305 | test-acc=0.9126 | P=1.0000 | R=0.0159 | F1=0.0312\n",
            "[epoch 09] train-loss=0.1840 | test-loss=0.2583 | train-acc=0.9341 | test-acc=0.9126 | P=1.0000 | R=0.0159 | F1=0.0312\n",
            "[epoch 10] train-loss=0.1605 | test-loss=0.2463 | train-acc=0.9425 | test-acc=0.9168 | P=0.8333 | R=0.0794 | F1=0.1449\n",
            "[epoch 11] train-loss=0.1464 | test-loss=0.2519 | train-acc=0.9422 | test-acc=0.9126 | P=0.5172 | R=0.2381 | F1=0.3261\n",
            "[epoch 12] train-loss=0.1318 | test-loss=0.2841 | train-acc=0.9520 | test-acc=0.9126 | P=1.0000 | R=0.0159 | F1=0.0312\n",
            "[epoch 13] train-loss=0.1097 | test-loss=0.2402 | train-acc=0.9637 | test-acc=0.9097 | P=0.4828 | R=0.2222 | F1=0.3043\n",
            "[epoch 14] train-loss=0.0916 | test-loss=0.2496 | train-acc=0.9700 | test-acc=0.9126 | P=0.5116 | R=0.3492 | F1=0.4151\n",
            "[epoch 15] train-loss=0.0811 | test-loss=0.2610 | train-acc=0.9718 | test-acc=0.9182 | P=0.7778 | R=0.1111 | F1=0.1944\n",
            "[epoch 16] train-loss=0.0692 | test-loss=0.2951 | train-acc=0.9785 | test-acc=0.9182 | P=1.0000 | R=0.0794 | F1=0.1471\n",
            "[epoch 17] train-loss=0.0598 | test-loss=0.3274 | train-acc=0.9810 | test-acc=0.9168 | P=1.0000 | R=0.0635 | F1=0.1194\n",
            "[epoch 18] train-loss=0.0407 | test-loss=0.2884 | train-acc=0.9926 | test-acc=0.9168 | P=0.6667 | R=0.1270 | F1=0.2133\n",
            "[epoch 19] train-loss=0.0418 | test-loss=0.2755 | train-acc=0.9894 | test-acc=0.9154 | P=0.6154 | R=0.1270 | F1=0.2105\n",
            "[epoch 20] train-loss=0.0337 | test-loss=0.2974 | train-acc=0.9944 | test-acc=0.9196 | P=0.8000 | R=0.1270 | F1=0.2192\n",
            "[epoch 21] train-loss=0.0301 | test-loss=0.3564 | train-acc=0.9954 | test-acc=0.9196 | P=0.8750 | R=0.1111 | F1=0.1972\n",
            "[epoch 22] train-loss=0.0257 | test-loss=0.4911 | train-acc=0.9965 | test-acc=0.9140 | P=1.0000 | R=0.0317 | F1=0.0615\n",
            "[epoch 23] train-loss=0.0239 | test-loss=0.2653 | train-acc=0.9968 | test-acc=0.9097 | P=0.4762 | R=0.1587 | F1=0.2381\n",
            "[epoch 24] train-loss=0.0205 | test-loss=0.3178 | train-acc=0.9968 | test-acc=0.9168 | P=0.7000 | R=0.1111 | F1=0.1918\n",
            "[epoch 25] train-loss=0.0176 | test-loss=0.2835 | train-acc=0.9975 | test-acc=0.9126 | P=0.5263 | R=0.1587 | F1=0.2439\n",
            "[epoch 26] train-loss=0.0156 | test-loss=0.2971 | train-acc=0.9968 | test-acc=0.9126 | P=0.5263 | R=0.1587 | F1=0.2439\n",
            "[epoch 27] train-loss=0.0174 | test-loss=0.3014 | train-acc=0.9972 | test-acc=0.9154 | P=0.6000 | R=0.1429 | F1=0.2308\n",
            "[epoch 28] train-loss=0.0142 | test-loss=0.3658 | train-acc=0.9979 | test-acc=0.9210 | P=1.0000 | R=0.1111 | F1=0.2000\n",
            "[epoch 29] train-loss=0.0115 | test-loss=0.3085 | train-acc=0.9993 | test-acc=0.9168 | P=0.6429 | R=0.1429 | F1=0.2338\n",
            "[epoch 30] train-loss=0.0089 | test-loss=0.2563 | train-acc=0.9993 | test-acc=0.9168 | P=0.5556 | R=0.3175 | F1=0.4040\n",
            "[epoch 31] train-loss=0.0101 | test-loss=0.3030 | train-acc=0.9993 | test-acc=0.9111 | P=0.5000 | R=0.1429 | F1=0.2222\n",
            "[epoch 32] train-loss=0.0085 | test-loss=0.3804 | train-acc=0.9993 | test-acc=0.9196 | P=0.8000 | R=0.1270 | F1=0.2192\n",
            "[epoch 33] train-loss=0.0070 | test-loss=0.3813 | train-acc=1.0000 | test-acc=0.9196 | P=0.8750 | R=0.1111 | F1=0.1972\n",
            "[epoch 34] train-loss=0.0079 | test-loss=0.4327 | train-acc=0.9993 | test-acc=0.9196 | P=1.0000 | R=0.0952 | F1=0.1739\n",
            "[epoch 35] train-loss=0.0082 | test-loss=0.3674 | train-acc=0.9989 | test-acc=0.9210 | P=1.0000 | R=0.1111 | F1=0.2000\n",
            "[epoch 36] train-loss=0.0072 | test-loss=0.4367 | train-acc=0.9989 | test-acc=0.9196 | P=1.0000 | R=0.0952 | F1=0.1739\n",
            "[epoch 37] train-loss=0.0055 | test-loss=0.4053 | train-acc=0.9996 | test-acc=0.9210 | P=1.0000 | R=0.1111 | F1=0.2000\n",
            "[epoch 38] train-loss=0.0071 | test-loss=0.4245 | train-acc=0.9989 | test-acc=0.9196 | P=1.0000 | R=0.0952 | F1=0.1739\n",
            "[epoch 39] train-loss=0.0056 | test-loss=0.4166 | train-acc=0.9996 | test-acc=0.9196 | P=0.8750 | R=0.1111 | F1=0.1972\n",
            "[epoch 40] train-loss=0.0051 | test-loss=0.3282 | train-acc=0.9996 | test-acc=0.9154 | P=0.6000 | R=0.1429 | F1=0.2308\n",
            "[epoch 41] train-loss=0.0048 | test-loss=0.4170 | train-acc=0.9996 | test-acc=0.9182 | P=0.7778 | R=0.1111 | F1=0.1944\n",
            "[epoch 42] train-loss=0.0051 | test-loss=0.4704 | train-acc=0.9996 | test-acc=0.9196 | P=1.0000 | R=0.0952 | F1=0.1739\n",
            "[epoch 43] train-loss=0.0054 | test-loss=0.2729 | train-acc=0.9996 | test-acc=0.9154 | P=0.5455 | R=0.2857 | F1=0.3750\n",
            "[epoch 44] train-loss=0.0075 | test-loss=0.3314 | train-acc=0.9993 | test-acc=0.9126 | P=0.5294 | R=0.1429 | F1=0.2250\n",
            "[epoch 45] train-loss=0.0061 | test-loss=0.3778 | train-acc=0.9989 | test-acc=0.9182 | P=0.7273 | R=0.1270 | F1=0.2162\n",
            "[epoch 46] train-loss=0.0043 | test-loss=0.3730 | train-acc=1.0000 | test-acc=0.9182 | P=0.6923 | R=0.1429 | F1=0.2368\n",
            "[epoch 47] train-loss=0.0038 | test-loss=0.4359 | train-acc=1.0000 | test-acc=0.9210 | P=1.0000 | R=0.1111 | F1=0.2000\n",
            "[epoch 48] train-loss=0.0037 | test-loss=0.3615 | train-acc=0.9996 | test-acc=0.9182 | P=0.6923 | R=0.1429 | F1=0.2368\n",
            "[epoch 49] train-loss=0.0025 | test-loss=0.3820 | train-acc=1.0000 | test-acc=0.9196 | P=0.7500 | R=0.1429 | F1=0.2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All five sets and large test set"
      ],
      "metadata": {
        "id": "HZGtsxFM8DUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = read_fasta('test_set_filt.f')\n",
        "\n",
        "# Distribution of sequence lengths in the large test set\n",
        "len_list = []\n",
        "for s in test_set:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Z_1i0nRKzdYo",
        "outputId": "392b3ff8-ea6b-40b2-8c2d-059815997b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "go_annotations = [\"GO_3A0005576\", \"GO_3A0005739\", \"GO_3A0007165\", \"GO_3A0043066\", \"GO_3A0055085\"]\n",
        "\n",
        "datalist_large_test = read_fasta('test_set_filt.f')\n",
        "labellist_large_test = [False for _ in range(len(datalist_large_test))]\n",
        "large_test = (datalist_large_test, labellist_large_test)\n",
        "\n",
        "large_test_result = []\n",
        "\n",
        "for go in go_annotations:\n",
        "    datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", f\"{go}.annotprot\")\n",
        "    pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "    neg_datalist = remove_sequences(neg_datalist, 0.2)\n",
        "    datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "    traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "    traindataset = [traindatalist, trainlabellist]\n",
        "    testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "    # Set batch_size and num_steps (maximum sequence length)\n",
        "    train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "    test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "    # Train model\n",
        "    model = BerryCNN1D(vocab_size=21,dropout_rate=0,conv_channels=64)\n",
        "    model.apply(init_weights)\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=0.01,\n",
        "        momentum=0.5\n",
        "    )\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "    df = trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    df.to_csv(f\"{go}.csv\")\n",
        "\n",
        "    # Run on large set\n",
        "    large_set_iter = load_data(batch_size, num_steps, large_test)\n",
        "\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    model.eval()\n",
        "\n",
        "    for seq, _ in large_set_iter:\n",
        "        outputs = model(seq.to(device))\n",
        "        for output in outputs:\n",
        "            o = output.tolist().index(max(output))\n",
        "            if o == 0:\n",
        "                neg += 1\n",
        "            elif o == 1:\n",
        "                pos += 1\n",
        "            else:\n",
        "                raise ValueError(f'{o=}')\n",
        "    print(f'{go}:\\t{pos = }\\t{neg = }')\n",
        "    large_test_result.append([go, pos])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix_1KPPF5gJI",
        "outputId": "33729ea3-8ccd-456d-ec21-dd5faf782790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.5105 | test-loss=0.6011 | train-acc=0.8081 | test-acc=0.7750 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.4712 | test-loss=0.5881 | train-acc=0.8167 | test-acc=0.7750 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4517 | test-loss=0.5384 | train-acc=0.8167 | test-acc=0.7781 | P=1.0000 | R=0.0139 | F1=0.0274\n",
            "[epoch 03] train-loss=0.4283 | test-loss=0.5018 | train-acc=0.8229 | test-acc=0.7750 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.4047 | test-loss=0.5872 | train-acc=0.8284 | test-acc=0.7125 | P=0.3864 | R=0.4722 | F1=0.4250\n",
            "[epoch 05] train-loss=0.3722 | test-loss=0.5152 | train-acc=0.8401 | test-acc=0.7438 | P=0.3214 | R=0.1250 | F1=0.1800\n",
            "[epoch 06] train-loss=0.3521 | test-loss=0.5542 | train-acc=0.8440 | test-acc=0.7188 | P=0.3977 | R=0.4861 | F1=0.4375\n",
            "[epoch 07] train-loss=0.3153 | test-loss=0.5328 | train-acc=0.8619 | test-acc=0.7500 | P=0.4444 | R=0.4444 | F1=0.4444\n",
            "[epoch 08] train-loss=0.2707 | test-loss=0.5496 | train-acc=0.8892 | test-acc=0.7219 | P=0.4045 | R=0.5000 | F1=0.4472\n",
            "[epoch 09] train-loss=0.2462 | test-loss=0.4923 | train-acc=0.9064 | test-acc=0.7750 | P=0.5000 | R=0.1528 | F1=0.2340\n",
            "[epoch 10] train-loss=0.1954 | test-loss=0.5124 | train-acc=0.9282 | test-acc=0.7469 | P=0.3953 | R=0.2361 | F1=0.2957\n",
            "[epoch 11] train-loss=0.1763 | test-loss=0.6201 | train-acc=0.9415 | test-acc=0.7719 | P=0.4000 | R=0.0278 | F1=0.0519\n",
            "[epoch 12] train-loss=0.1370 | test-loss=0.7018 | train-acc=0.9626 | test-acc=0.7656 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 13] train-loss=0.1166 | test-loss=0.8090 | train-acc=0.9711 | test-acc=0.7719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 14] train-loss=0.0907 | test-loss=0.5937 | train-acc=0.9860 | test-acc=0.7844 | P=0.5714 | R=0.1667 | F1=0.2581\n",
            "[epoch 15] train-loss=0.0739 | test-loss=0.7859 | train-acc=0.9945 | test-acc=0.7719 | P=0.4000 | R=0.0278 | F1=0.0519\n",
            "[epoch 16] train-loss=0.0622 | test-loss=0.8413 | train-acc=0.9938 | test-acc=0.7719 | P=0.3333 | R=0.0139 | F1=0.0267\n",
            "[epoch 17] train-loss=0.0440 | test-loss=0.6800 | train-acc=1.0000 | test-acc=0.7844 | P=0.5789 | R=0.1528 | F1=0.2418\n",
            "[epoch 18] train-loss=0.0343 | test-loss=0.6041 | train-acc=1.0000 | test-acc=0.7656 | P=0.4595 | R=0.2361 | F1=0.3119\n",
            "[epoch 19] train-loss=0.0276 | test-loss=0.6123 | train-acc=1.0000 | test-acc=0.7594 | P=0.4359 | R=0.2361 | F1=0.3063\n",
            "[epoch 20] train-loss=0.0232 | test-loss=0.7421 | train-acc=1.0000 | test-acc=0.7875 | P=0.6250 | R=0.1389 | F1=0.2273\n",
            "[epoch 21] train-loss=0.0218 | test-loss=0.7215 | train-acc=1.0000 | test-acc=0.7781 | P=0.5238 | R=0.1528 | F1=0.2366\n",
            "[epoch 22] train-loss=0.0175 | test-loss=0.6643 | train-acc=1.0000 | test-acc=0.7781 | P=0.5152 | R=0.2361 | F1=0.3238\n",
            "[epoch 23] train-loss=0.0151 | test-loss=0.6888 | train-acc=1.0000 | test-acc=0.7719 | P=0.4839 | R=0.2083 | F1=0.2913\n",
            "[epoch 24] train-loss=0.0136 | test-loss=0.7293 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1667 | F1=0.2500\n",
            "[epoch 25] train-loss=0.0120 | test-loss=0.7707 | train-acc=1.0000 | test-acc=0.7812 | P=0.5500 | R=0.1528 | F1=0.2391\n",
            "[epoch 26] train-loss=0.0110 | test-loss=0.7923 | train-acc=1.0000 | test-acc=0.7812 | P=0.5500 | R=0.1528 | F1=0.2391\n",
            "[epoch 27] train-loss=0.0101 | test-loss=0.8153 | train-acc=1.0000 | test-acc=0.7812 | P=0.5556 | R=0.1389 | F1=0.2222\n",
            "[epoch 28] train-loss=0.0093 | test-loss=0.7690 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1667 | F1=0.2500\n",
            "[epoch 29] train-loss=0.0084 | test-loss=0.7639 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1806 | F1=0.2653\n",
            "[epoch 30] train-loss=0.0079 | test-loss=0.7974 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1528 | F1=0.2340\n",
            "[epoch 31] train-loss=0.0073 | test-loss=0.7428 | train-acc=1.0000 | test-acc=0.7781 | P=0.5161 | R=0.2222 | F1=0.3107\n",
            "[epoch 32] train-loss=0.0069 | test-loss=0.8273 | train-acc=1.0000 | test-acc=0.7781 | P=0.5238 | R=0.1528 | F1=0.2366\n",
            "[epoch 33] train-loss=0.0066 | test-loss=0.7946 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1806 | F1=0.2653\n",
            "[epoch 34] train-loss=0.0062 | test-loss=0.8109 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1667 | F1=0.2500\n",
            "[epoch 35] train-loss=0.0058 | test-loss=0.8046 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1806 | F1=0.2653\n",
            "[epoch 36] train-loss=0.0054 | test-loss=0.7508 | train-acc=1.0000 | test-acc=0.7719 | P=0.4848 | R=0.2222 | F1=0.3048\n",
            "[epoch 37] train-loss=0.0052 | test-loss=0.8754 | train-acc=1.0000 | test-acc=0.7781 | P=0.5263 | R=0.1389 | F1=0.2198\n",
            "[epoch 38] train-loss=0.0049 | test-loss=0.8443 | train-acc=1.0000 | test-acc=0.7719 | P=0.4783 | R=0.1528 | F1=0.2316\n",
            "[epoch 39] train-loss=0.0047 | test-loss=0.8268 | train-acc=1.0000 | test-acc=0.7781 | P=0.5185 | R=0.1944 | F1=0.2828\n",
            "[epoch 40] train-loss=0.0045 | test-loss=0.8265 | train-acc=1.0000 | test-acc=0.7781 | P=0.5185 | R=0.1944 | F1=0.2828\n",
            "[epoch 41] train-loss=0.0043 | test-loss=0.8259 | train-acc=1.0000 | test-acc=0.7781 | P=0.5172 | R=0.2083 | F1=0.2970\n",
            "[epoch 42] train-loss=0.0041 | test-loss=0.8780 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1528 | F1=0.2340\n",
            "[epoch 43] train-loss=0.0039 | test-loss=0.8488 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1806 | F1=0.2653\n",
            "[epoch 44] train-loss=0.0038 | test-loss=0.7975 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.2222 | F1=0.3077\n",
            "[epoch 45] train-loss=0.0037 | test-loss=0.8512 | train-acc=1.0000 | test-acc=0.7781 | P=0.5185 | R=0.1944 | F1=0.2828\n",
            "[epoch 46] train-loss=0.0035 | test-loss=0.8391 | train-acc=1.0000 | test-acc=0.7781 | P=0.5172 | R=0.2083 | F1=0.2970\n",
            "[epoch 47] train-loss=0.0034 | test-loss=0.8228 | train-acc=1.0000 | test-acc=0.7781 | P=0.5161 | R=0.2222 | F1=0.3107\n",
            "[epoch 48] train-loss=0.0033 | test-loss=0.8884 | train-acc=1.0000 | test-acc=0.7781 | P=0.5217 | R=0.1667 | F1=0.2526\n",
            "[epoch 49] train-loss=0.0032 | test-loss=0.8710 | train-acc=1.0000 | test-acc=0.7750 | P=0.5000 | R=0.1806 | F1=0.2653\n",
            "GO_3A0005576:\tpos = 1408\tneg = 13357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6116 | test-loss=0.5879 | train-acc=0.7008 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.5821 | test-loss=0.5735 | train-acc=0.7318 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.5712 | test-loss=0.5721 | train-acc=0.7296 | test-acc=0.7176 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.5430 | test-loss=0.5695 | train-acc=0.7340 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.5192 | test-loss=0.5727 | train-acc=0.7426 | test-acc=0.7205 | P=0.5000 | R=0.1443 | F1=0.2240\n",
            "[epoch 05] train-loss=0.4777 | test-loss=0.6312 | train-acc=0.7722 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.4533 | test-loss=0.6521 | train-acc=0.7916 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.4072 | test-loss=0.6202 | train-acc=0.8291 | test-acc=0.6311 | P=0.3817 | R=0.5155 | F1=0.4386\n",
            "[epoch 08] train-loss=0.3676 | test-loss=0.8558 | train-acc=0.8407 | test-acc=0.7205 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3311 | test-loss=0.5644 | train-acc=0.8681 | test-acc=0.7118 | P=0.4754 | R=0.2990 | F1=0.3671\n",
            "[epoch 10] train-loss=0.3023 | test-loss=0.5672 | train-acc=0.8681 | test-acc=0.7147 | P=0.4848 | R=0.3299 | F1=0.3926\n",
            "[epoch 11] train-loss=0.2429 | test-loss=0.5967 | train-acc=0.9257 | test-acc=0.7349 | P=0.6000 | R=0.1546 | F1=0.2459\n",
            "[epoch 12] train-loss=0.2004 | test-loss=0.6192 | train-acc=0.9387 | test-acc=0.7262 | P=0.5357 | R=0.1546 | F1=0.2400\n",
            "[epoch 13] train-loss=0.1872 | test-loss=0.5920 | train-acc=0.9488 | test-acc=0.7205 | P=0.5000 | R=0.2371 | F1=0.3217\n",
            "[epoch 14] train-loss=0.1401 | test-loss=0.7750 | train-acc=0.9676 | test-acc=0.7262 | P=0.6000 | R=0.0619 | F1=0.1121\n",
            "[epoch 15] train-loss=0.1093 | test-loss=0.7181 | train-acc=0.9820 | test-acc=0.6110 | P=0.3797 | R=0.6186 | F1=0.4706\n",
            "[epoch 16] train-loss=0.0809 | test-loss=0.6320 | train-acc=0.9921 | test-acc=0.7118 | P=0.4805 | R=0.3814 | F1=0.4253\n",
            "[epoch 17] train-loss=0.0570 | test-loss=0.6899 | train-acc=0.9978 | test-acc=0.6628 | P=0.4153 | R=0.5052 | F1=0.4558\n",
            "[epoch 18] train-loss=0.0470 | test-loss=0.7665 | train-acc=0.9986 | test-acc=0.7291 | P=0.5600 | R=0.1443 | F1=0.2295\n",
            "[epoch 19] train-loss=0.0432 | test-loss=0.6737 | train-acc=0.9971 | test-acc=0.7291 | P=0.5211 | R=0.3814 | F1=0.4405\n",
            "[epoch 20] train-loss=0.0317 | test-loss=0.6754 | train-acc=0.9986 | test-acc=0.7032 | P=0.4667 | R=0.4330 | F1=0.4492\n",
            "[epoch 21] train-loss=0.0265 | test-loss=0.6957 | train-acc=0.9993 | test-acc=0.7118 | P=0.4810 | R=0.3918 | F1=0.4318\n",
            "[epoch 22] train-loss=0.0268 | test-loss=0.7757 | train-acc=0.9978 | test-acc=0.7291 | P=0.5405 | R=0.2062 | F1=0.2985\n",
            "[epoch 23] train-loss=0.0249 | test-loss=0.7458 | train-acc=0.9978 | test-acc=0.7262 | P=0.5208 | R=0.2577 | F1=0.3448\n",
            "[epoch 24] train-loss=0.0254 | test-loss=0.7106 | train-acc=0.9964 | test-acc=0.7061 | P=0.4719 | R=0.4330 | F1=0.4516\n",
            "[epoch 25] train-loss=0.0213 | test-loss=0.7525 | train-acc=0.9986 | test-acc=0.7291 | P=0.5254 | R=0.3196 | F1=0.3974\n",
            "[epoch 26] train-loss=0.0201 | test-loss=0.7512 | train-acc=0.9971 | test-acc=0.7176 | P=0.4921 | R=0.3196 | F1=0.3875\n",
            "[epoch 27] train-loss=0.0182 | test-loss=0.7848 | train-acc=0.9978 | test-acc=0.7176 | P=0.4894 | R=0.2371 | F1=0.3194\n",
            "[epoch 28] train-loss=0.0131 | test-loss=0.7565 | train-acc=0.9993 | test-acc=0.7291 | P=0.5224 | R=0.3608 | F1=0.4268\n",
            "[epoch 29] train-loss=0.0163 | test-loss=0.8267 | train-acc=0.9986 | test-acc=0.7262 | P=0.5238 | R=0.2268 | F1=0.3165\n",
            "[epoch 30] train-loss=0.0150 | test-loss=0.7720 | train-acc=0.9986 | test-acc=0.7320 | P=0.5294 | R=0.3711 | F1=0.4364\n",
            "[epoch 31] train-loss=0.0163 | test-loss=0.7928 | train-acc=0.9971 | test-acc=0.7349 | P=0.5424 | R=0.3299 | F1=0.4103\n",
            "[epoch 32] train-loss=0.0112 | test-loss=0.8154 | train-acc=0.9993 | test-acc=0.7205 | P=0.5000 | R=0.2784 | F1=0.3576\n",
            "[epoch 33] train-loss=0.0126 | test-loss=0.8092 | train-acc=0.9993 | test-acc=0.7320 | P=0.5345 | R=0.3196 | F1=0.4000\n",
            "[epoch 34] train-loss=0.0153 | test-loss=0.7811 | train-acc=0.9986 | test-acc=0.7262 | P=0.5132 | R=0.4021 | F1=0.4509\n",
            "[epoch 35] train-loss=0.0109 | test-loss=0.7974 | train-acc=0.9993 | test-acc=0.7147 | P=0.4868 | R=0.3814 | F1=0.4277\n",
            "[epoch 36] train-loss=0.0144 | test-loss=0.8311 | train-acc=0.9986 | test-acc=0.7291 | P=0.5263 | R=0.3093 | F1=0.3896\n",
            "[epoch 37] train-loss=0.0131 | test-loss=0.8038 | train-acc=0.9986 | test-acc=0.7003 | P=0.4598 | R=0.4124 | F1=0.4348\n",
            "[epoch 38] train-loss=0.0092 | test-loss=0.8824 | train-acc=0.9993 | test-acc=0.7320 | P=0.5476 | R=0.2371 | F1=0.3309\n",
            "[epoch 39] train-loss=0.0123 | test-loss=0.8137 | train-acc=0.9986 | test-acc=0.7118 | P=0.4815 | R=0.4021 | F1=0.4382\n",
            "[epoch 40] train-loss=0.0091 | test-loss=0.8081 | train-acc=0.9986 | test-acc=0.7176 | P=0.4938 | R=0.4124 | F1=0.4494\n",
            "[epoch 41] train-loss=0.0088 | test-loss=0.8580 | train-acc=0.9986 | test-acc=0.7291 | P=0.5254 | R=0.3196 | F1=0.3974\n",
            "[epoch 42] train-loss=0.0126 | test-loss=0.8305 | train-acc=0.9978 | test-acc=0.7205 | P=0.5000 | R=0.3814 | F1=0.4327\n",
            "[epoch 43] train-loss=0.0088 | test-loss=0.8538 | train-acc=0.9993 | test-acc=0.7233 | P=0.5077 | R=0.3402 | F1=0.4074\n",
            "[epoch 44] train-loss=0.0077 | test-loss=0.8555 | train-acc=0.9993 | test-acc=0.7205 | P=0.5000 | R=0.3402 | F1=0.4049\n",
            "[epoch 45] train-loss=0.0125 | test-loss=0.8549 | train-acc=0.9978 | test-acc=0.7118 | P=0.4783 | R=0.3402 | F1=0.3976\n",
            "[epoch 46] train-loss=0.0125 | test-loss=0.8771 | train-acc=0.9978 | test-acc=0.7320 | P=0.5345 | R=0.3196 | F1=0.4000\n",
            "[epoch 47] train-loss=0.0084 | test-loss=0.8702 | train-acc=0.9993 | test-acc=0.7205 | P=0.5000 | R=0.3505 | F1=0.4121\n",
            "[epoch 48] train-loss=0.0079 | test-loss=0.8552 | train-acc=0.9993 | test-acc=0.7176 | P=0.4933 | R=0.3814 | F1=0.4302\n",
            "[epoch 49] train-loss=0.0073 | test-loss=0.8827 | train-acc=0.9993 | test-acc=0.7262 | P=0.5152 | R=0.3505 | F1=0.4172\n",
            "GO_3A0005739:\tpos = 2328\tneg = 12437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.6075 | test-loss=0.5233 | train-acc=0.7378 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.5747 | test-loss=0.5472 | train-acc=0.7400 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.5573 | test-loss=0.5671 | train-acc=0.7400 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.5364 | test-loss=0.5186 | train-acc=0.7482 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.5055 | test-loss=0.5373 | train-acc=0.7496 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.4843 | test-loss=0.5139 | train-acc=0.7718 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.4536 | test-loss=0.5121 | train-acc=0.7814 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.4240 | test-loss=0.7062 | train-acc=0.8072 | test-acc=0.5044 | P=0.2667 | R=0.6753 | F1=0.3824\n",
            "[epoch 08] train-loss=0.3859 | test-loss=0.5473 | train-acc=0.8471 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3467 | test-loss=0.6010 | train-acc=0.8582 | test-acc=0.6785 | P=0.3140 | R=0.3506 | F1=0.3313\n",
            "[epoch 10] train-loss=0.3077 | test-loss=0.6019 | train-acc=0.8804 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 11] train-loss=0.2791 | test-loss=1.0128 | train-acc=0.8922 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 12] train-loss=0.2492 | test-loss=0.7966 | train-acc=0.9269 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 13] train-loss=0.2025 | test-loss=0.5748 | train-acc=0.9298 | test-acc=0.7522 | P=0.3333 | R=0.0909 | F1=0.1429\n",
            "[epoch 14] train-loss=0.1507 | test-loss=0.6305 | train-acc=0.9675 | test-acc=0.7788 | P=0.6667 | R=0.0519 | F1=0.0964\n",
            "[epoch 15] train-loss=0.1165 | test-loss=1.2856 | train-acc=0.9860 | test-acc=0.7729 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 16] train-loss=0.0940 | test-loss=0.6369 | train-acc=0.9911 | test-acc=0.7493 | P=0.3182 | R=0.0909 | F1=0.1414\n",
            "[epoch 17] train-loss=0.0639 | test-loss=1.3404 | train-acc=0.9978 | test-acc=0.3717 | P=0.2500 | R=0.8831 | F1=0.3897\n",
            "[epoch 18] train-loss=0.0574 | test-loss=0.8870 | train-acc=0.9970 | test-acc=0.5398 | P=0.2663 | R=0.5844 | F1=0.3659\n",
            "[epoch 19] train-loss=0.0505 | test-loss=0.6449 | train-acc=0.9970 | test-acc=0.7493 | P=0.3947 | R=0.1948 | F1=0.2609\n",
            "[epoch 20] train-loss=0.0318 | test-loss=0.6598 | train-acc=1.0000 | test-acc=0.7493 | P=0.3947 | R=0.1948 | F1=0.2609\n",
            "[epoch 21] train-loss=0.0266 | test-loss=0.6792 | train-acc=1.0000 | test-acc=0.7493 | P=0.3889 | R=0.1818 | F1=0.2478\n",
            "[epoch 22] train-loss=0.0225 | test-loss=0.6753 | train-acc=1.0000 | test-acc=0.7375 | P=0.3571 | R=0.1948 | F1=0.2521\n",
            "[epoch 23] train-loss=0.0190 | test-loss=0.7414 | train-acc=1.0000 | test-acc=0.7670 | P=0.4583 | R=0.1429 | F1=0.2178\n",
            "[epoch 24] train-loss=0.0169 | test-loss=0.6861 | train-acc=1.0000 | test-acc=0.7257 | P=0.3400 | R=0.2208 | F1=0.2677\n",
            "[epoch 25] train-loss=0.0147 | test-loss=0.7129 | train-acc=1.0000 | test-acc=0.7463 | P=0.3846 | R=0.1948 | F1=0.2586\n",
            "[epoch 26] train-loss=0.0133 | test-loss=0.6989 | train-acc=1.0000 | test-acc=0.7139 | P=0.3276 | R=0.2468 | F1=0.2815\n",
            "[epoch 27] train-loss=0.0123 | test-loss=0.7471 | train-acc=1.0000 | test-acc=0.7581 | P=0.4242 | R=0.1818 | F1=0.2545\n",
            "[epoch 28] train-loss=0.0111 | test-loss=0.8139 | train-acc=1.0000 | test-acc=0.7699 | P=0.4783 | R=0.1429 | F1=0.2200\n",
            "[epoch 29] train-loss=0.0103 | test-loss=0.7593 | train-acc=1.0000 | test-acc=0.7552 | P=0.4118 | R=0.1818 | F1=0.2523\n",
            "[epoch 30] train-loss=0.0094 | test-loss=0.7875 | train-acc=1.0000 | test-acc=0.7640 | P=0.4516 | R=0.1818 | F1=0.2593\n",
            "[epoch 31] train-loss=0.0088 | test-loss=0.7452 | train-acc=1.0000 | test-acc=0.7434 | P=0.3864 | R=0.2208 | F1=0.2810\n",
            "[epoch 32] train-loss=0.0083 | test-loss=0.7399 | train-acc=1.0000 | test-acc=0.7286 | P=0.3529 | R=0.2338 | F1=0.2812\n",
            "[epoch 33] train-loss=0.0077 | test-loss=0.7700 | train-acc=1.0000 | test-acc=0.7463 | P=0.3846 | R=0.1948 | F1=0.2586\n",
            "[epoch 34] train-loss=0.0073 | test-loss=0.7943 | train-acc=1.0000 | test-acc=0.7522 | P=0.4000 | R=0.1818 | F1=0.2500\n",
            "[epoch 35] train-loss=0.0068 | test-loss=0.7566 | train-acc=1.0000 | test-acc=0.7316 | P=0.3542 | R=0.2208 | F1=0.2720\n",
            "[epoch 36] train-loss=0.0064 | test-loss=0.7768 | train-acc=1.0000 | test-acc=0.7463 | P=0.3953 | R=0.2208 | F1=0.2833\n",
            "[epoch 37] train-loss=0.0060 | test-loss=0.7823 | train-acc=1.0000 | test-acc=0.7463 | P=0.3953 | R=0.2208 | F1=0.2833\n",
            "[epoch 38] train-loss=0.0058 | test-loss=0.7868 | train-acc=1.0000 | test-acc=0.7434 | P=0.3810 | R=0.2078 | F1=0.2689\n",
            "[epoch 39] train-loss=0.0055 | test-loss=0.8073 | train-acc=1.0000 | test-acc=0.7493 | P=0.3947 | R=0.1948 | F1=0.2609\n",
            "[epoch 40] train-loss=0.0052 | test-loss=0.7917 | train-acc=1.0000 | test-acc=0.7434 | P=0.3864 | R=0.2208 | F1=0.2810\n",
            "[epoch 41] train-loss=0.0050 | test-loss=0.8022 | train-acc=1.0000 | test-acc=0.7493 | P=0.4048 | R=0.2208 | F1=0.2857\n",
            "[epoch 42] train-loss=0.0048 | test-loss=0.7907 | train-acc=1.0000 | test-acc=0.7345 | P=0.3617 | R=0.2208 | F1=0.2742\n",
            "[epoch 43] train-loss=0.0046 | test-loss=0.8023 | train-acc=1.0000 | test-acc=0.7434 | P=0.3864 | R=0.2208 | F1=0.2810\n",
            "[epoch 44] train-loss=0.0044 | test-loss=0.8541 | train-acc=1.0000 | test-acc=0.7670 | P=0.4667 | R=0.1818 | F1=0.2617\n",
            "[epoch 45] train-loss=0.0042 | test-loss=0.8157 | train-acc=1.0000 | test-acc=0.7463 | P=0.3902 | R=0.2078 | F1=0.2712\n",
            "[epoch 46] train-loss=0.0040 | test-loss=0.8375 | train-acc=1.0000 | test-acc=0.7522 | P=0.4054 | R=0.1948 | F1=0.2632\n",
            "[epoch 47] train-loss=0.0039 | test-loss=0.8125 | train-acc=1.0000 | test-acc=0.7345 | P=0.3617 | R=0.2208 | F1=0.2742\n",
            "[epoch 48] train-loss=0.0038 | test-loss=0.8174 | train-acc=1.0000 | test-acc=0.7404 | P=0.3778 | R=0.2208 | F1=0.2787\n",
            "[epoch 49] train-loss=0.0036 | test-loss=0.8301 | train-acc=1.0000 | test-acc=0.7463 | P=0.3953 | R=0.2208 | F1=0.2833\n",
            "GO_3A0007165:\tpos = 977\tneg = 13788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4009 | test-loss=0.4022 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.3816 | test-loss=0.3729 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3684 | test-loss=0.4000 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3568 | test-loss=0.3998 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3487 | test-loss=0.3912 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3372 | test-loss=0.3730 | train-acc=0.8757 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3172 | test-loss=0.3731 | train-acc=0.8774 | test-acc=0.8675 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2988 | test-loss=0.3990 | train-acc=0.8774 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 08] train-loss=0.2775 | test-loss=0.4008 | train-acc=0.8782 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 09] train-loss=0.2552 | test-loss=0.4106 | train-acc=0.8890 | test-acc=0.8609 | P=0.2500 | R=0.0250 | F1=0.0455\n",
            "[epoch 10] train-loss=0.2247 | test-loss=0.3783 | train-acc=0.8940 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 11] train-loss=0.1935 | test-loss=0.4401 | train-acc=0.9221 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 12] train-loss=0.1670 | test-loss=0.3832 | train-acc=0.9321 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 13] train-loss=0.1381 | test-loss=0.4452 | train-acc=0.9544 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 14] train-loss=0.1162 | test-loss=0.4005 | train-acc=0.9685 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 15] train-loss=0.0906 | test-loss=0.4732 | train-acc=0.9851 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 16] train-loss=0.0788 | test-loss=0.4401 | train-acc=0.9867 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 17] train-loss=0.0633 | test-loss=0.5153 | train-acc=0.9959 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 18] train-loss=0.0488 | test-loss=0.5162 | train-acc=0.9975 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 19] train-loss=0.0419 | test-loss=0.4501 | train-acc=0.9983 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 20] train-loss=0.0340 | test-loss=0.6068 | train-acc=1.0000 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 21] train-loss=0.0288 | test-loss=0.4600 | train-acc=1.0000 | test-acc=0.8609 | P=0.2500 | R=0.0250 | F1=0.0455\n",
            "[epoch 22] train-loss=0.0245 | test-loss=0.4570 | train-acc=1.0000 | test-acc=0.8576 | P=0.2000 | R=0.0250 | F1=0.0444\n",
            "[epoch 23] train-loss=0.0214 | test-loss=0.5061 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 24] train-loss=0.0188 | test-loss=0.5560 | train-acc=1.0000 | test-acc=0.8709 | P=1.0000 | R=0.0250 | F1=0.0488\n",
            "[epoch 25] train-loss=0.0166 | test-loss=0.4955 | train-acc=1.0000 | test-acc=0.8609 | P=0.2500 | R=0.0250 | F1=0.0455\n",
            "[epoch 26] train-loss=0.0149 | test-loss=0.5226 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 27] train-loss=0.0135 | test-loss=0.5714 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 28] train-loss=0.0122 | test-loss=0.5323 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 29] train-loss=0.0113 | test-loss=0.5569 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 30] train-loss=0.0101 | test-loss=0.5853 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 31] train-loss=0.0093 | test-loss=0.5539 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 32] train-loss=0.0087 | test-loss=0.5579 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 33] train-loss=0.0082 | test-loss=0.5804 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 34] train-loss=0.0076 | test-loss=0.5940 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 35] train-loss=0.0072 | test-loss=0.5955 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 36] train-loss=0.0068 | test-loss=0.5840 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 37] train-loss=0.0065 | test-loss=0.5701 | train-acc=1.0000 | test-acc=0.8576 | P=0.2000 | R=0.0250 | F1=0.0444\n",
            "[epoch 38] train-loss=0.0061 | test-loss=0.6159 | train-acc=1.0000 | test-acc=0.8675 | P=0.5000 | R=0.0250 | F1=0.0476\n",
            "[epoch 39] train-loss=0.0057 | test-loss=0.5802 | train-acc=1.0000 | test-acc=0.8609 | P=0.2500 | R=0.0250 | F1=0.0455\n",
            "[epoch 40] train-loss=0.0055 | test-loss=0.5739 | train-acc=1.0000 | test-acc=0.8576 | P=0.2000 | R=0.0250 | F1=0.0444\n",
            "[epoch 41] train-loss=0.0051 | test-loss=0.6526 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 42] train-loss=0.0049 | test-loss=0.6018 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 43] train-loss=0.0048 | test-loss=0.7356 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 44] train-loss=0.0046 | test-loss=0.7165 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 45] train-loss=0.0044 | test-loss=0.6871 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 46] train-loss=0.0042 | test-loss=0.6136 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "[epoch 47] train-loss=0.0040 | test-loss=0.6037 | train-acc=1.0000 | test-acc=0.8576 | P=0.2000 | R=0.0250 | F1=0.0444\n",
            "[epoch 48] train-loss=0.0038 | test-loss=0.5939 | train-acc=1.0000 | test-acc=0.8477 | P=0.1250 | R=0.0250 | F1=0.0417\n",
            "[epoch 49] train-loss=0.0037 | test-loss=0.6375 | train-acc=1.0000 | test-acc=0.8642 | P=0.3333 | R=0.0250 | F1=0.0465\n",
            "GO_3A0043066:\tpos = 65\tneg = 14700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1b0abac1b1a5>:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=0.4570 | test-loss=0.4163 | train-acc=0.8488 | test-acc=0.8442 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 01] train-loss=0.4222 | test-loss=0.4132 | train-acc=0.8553 | test-acc=0.8442 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4005 | test-loss=0.3976 | train-acc=0.8585 | test-acc=0.8442 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3777 | test-loss=0.3932 | train-acc=0.8553 | test-acc=0.8442 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3512 | test-loss=0.4107 | train-acc=0.8569 | test-acc=0.8539 | P=0.7143 | R=0.1042 | F1=0.1818\n",
            "[epoch 05] train-loss=0.3196 | test-loss=0.3858 | train-acc=0.8707 | test-acc=0.8571 | P=0.7000 | R=0.1458 | F1=0.2414\n",
            "[epoch 06] train-loss=0.2937 | test-loss=0.4028 | train-acc=0.8870 | test-acc=0.8442 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2636 | test-loss=0.3829 | train-acc=0.8959 | test-acc=0.8474 | P=1.0000 | R=0.0208 | F1=0.0408\n",
            "[epoch 08] train-loss=0.2238 | test-loss=0.3384 | train-acc=0.9122 | test-acc=0.8799 | P=0.6897 | R=0.4167 | F1=0.5195\n",
            "[epoch 09] train-loss=0.1899 | test-loss=0.3616 | train-acc=0.9390 | test-acc=0.8539 | P=1.0000 | R=0.0625 | F1=0.1176\n",
            "[epoch 10] train-loss=0.1840 | test-loss=0.3513 | train-acc=0.9317 | test-acc=0.8636 | P=1.0000 | R=0.1250 | F1=0.2222\n",
            "[epoch 11] train-loss=0.1483 | test-loss=0.4384 | train-acc=0.9520 | test-acc=0.8506 | P=1.0000 | R=0.0417 | F1=0.0800\n",
            "[epoch 12] train-loss=0.1215 | test-loss=0.3297 | train-acc=0.9626 | test-acc=0.8701 | P=0.7500 | R=0.2500 | F1=0.3750\n",
            "[epoch 13] train-loss=0.0985 | test-loss=0.3811 | train-acc=0.9724 | test-acc=0.8571 | P=0.8333 | R=0.1042 | F1=0.1852\n",
            "[epoch 14] train-loss=0.0813 | test-loss=0.3238 | train-acc=0.9837 | test-acc=0.8766 | P=0.6923 | R=0.3750 | F1=0.4865\n",
            "[epoch 15] train-loss=0.0623 | test-loss=0.3403 | train-acc=0.9927 | test-acc=0.8701 | P=0.7000 | R=0.2917 | F1=0.4118\n",
            "[epoch 16] train-loss=0.0482 | test-loss=0.3465 | train-acc=0.9976 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 17] train-loss=0.0400 | test-loss=0.3532 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 18] train-loss=0.0315 | test-loss=0.3791 | train-acc=1.0000 | test-acc=0.8701 | P=0.7222 | R=0.2708 | F1=0.3939\n",
            "[epoch 19] train-loss=0.0253 | test-loss=0.3616 | train-acc=1.0000 | test-acc=0.8831 | P=0.7500 | R=0.3750 | F1=0.5000\n",
            "[epoch 20] train-loss=0.0232 | test-loss=0.3487 | train-acc=1.0000 | test-acc=0.8766 | P=0.6250 | R=0.5208 | F1=0.5682\n",
            "[epoch 21] train-loss=0.0198 | test-loss=0.4946 | train-acc=1.0000 | test-acc=0.8539 | P=0.8000 | R=0.0833 | F1=0.1509\n",
            "[epoch 22] train-loss=0.0170 | test-loss=0.3745 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 23] train-loss=0.0155 | test-loss=0.3757 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 24] train-loss=0.0140 | test-loss=0.4161 | train-acc=1.0000 | test-acc=0.8701 | P=0.7222 | R=0.2708 | F1=0.3939\n",
            "[epoch 25] train-loss=0.0121 | test-loss=0.4187 | train-acc=1.0000 | test-acc=0.8734 | P=0.7368 | R=0.2917 | F1=0.4179\n",
            "[epoch 26] train-loss=0.0112 | test-loss=0.4179 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 27] train-loss=0.0099 | test-loss=0.3928 | train-acc=1.0000 | test-acc=0.8831 | P=0.7500 | R=0.3750 | F1=0.5000\n",
            "[epoch 28] train-loss=0.0092 | test-loss=0.4407 | train-acc=1.0000 | test-acc=0.8734 | P=0.7647 | R=0.2708 | F1=0.4000\n",
            "[epoch 29] train-loss=0.0087 | test-loss=0.4143 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 30] train-loss=0.0081 | test-loss=0.4080 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 31] train-loss=0.0074 | test-loss=0.4206 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 32] train-loss=0.0070 | test-loss=0.4188 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 33] train-loss=0.0065 | test-loss=0.3971 | train-acc=1.0000 | test-acc=0.8961 | P=0.7857 | R=0.4583 | F1=0.5789\n",
            "[epoch 34] train-loss=0.0063 | test-loss=0.4173 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 35] train-loss=0.0058 | test-loss=0.4540 | train-acc=1.0000 | test-acc=0.8734 | P=0.7368 | R=0.2917 | F1=0.4179\n",
            "[epoch 36] train-loss=0.0055 | test-loss=0.4287 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 37] train-loss=0.0052 | test-loss=0.4166 | train-acc=1.0000 | test-acc=0.8831 | P=0.7500 | R=0.3750 | F1=0.5000\n",
            "[epoch 38] train-loss=0.0049 | test-loss=0.4655 | train-acc=1.0000 | test-acc=0.8734 | P=0.7368 | R=0.2917 | F1=0.4179\n",
            "[epoch 39] train-loss=0.0047 | test-loss=0.4423 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 40] train-loss=0.0045 | test-loss=0.4340 | train-acc=1.0000 | test-acc=0.8799 | P=0.7391 | R=0.3542 | F1=0.4789\n",
            "[epoch 41] train-loss=0.0043 | test-loss=0.4434 | train-acc=1.0000 | test-acc=0.8831 | P=0.7727 | R=0.3542 | F1=0.4857\n",
            "[epoch 42] train-loss=0.0041 | test-loss=0.4540 | train-acc=1.0000 | test-acc=0.8766 | P=0.7500 | R=0.3125 | F1=0.4412\n",
            "[epoch 43] train-loss=0.0040 | test-loss=0.4743 | train-acc=1.0000 | test-acc=0.8734 | P=0.7368 | R=0.2917 | F1=0.4179\n",
            "[epoch 44] train-loss=0.0038 | test-loss=0.4693 | train-acc=1.0000 | test-acc=0.8734 | P=0.7368 | R=0.2917 | F1=0.4179\n",
            "[epoch 45] train-loss=0.0037 | test-loss=0.4551 | train-acc=1.0000 | test-acc=0.8766 | P=0.7500 | R=0.3125 | F1=0.4412\n",
            "[epoch 46] train-loss=0.0035 | test-loss=0.4621 | train-acc=1.0000 | test-acc=0.8766 | P=0.7500 | R=0.3125 | F1=0.4412\n",
            "[epoch 47] train-loss=0.0034 | test-loss=0.4563 | train-acc=1.0000 | test-acc=0.8799 | P=0.7619 | R=0.3333 | F1=0.4638\n",
            "[epoch 48] train-loss=0.0033 | test-loss=0.4591 | train-acc=1.0000 | test-acc=0.8799 | P=0.7619 | R=0.3333 | F1=0.4638\n",
            "[epoch 49] train-loss=0.0032 | test-loss=0.4682 | train-acc=1.0000 | test-acc=0.8766 | P=0.7500 | R=0.3125 | F1=0.4412\n",
            "GO_3A0055085:\tpos = 250\tneg = 14515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load results from the large test set into a dataframe. The instance ended right after the above run, so I had to copy results from the stdout\n",
        "df = pd.DataFrame(\n",
        "    data={\n",
        "        'Annotation': ['GO_3A0005576', 'GO_3A0005739', 'GO_3A0007165', 'GO_3A0043066', 'GO_3A0055085'],\n",
        "        'Positive': [1408, 2328, 977, 65, 250],\n",
        "        'Negative': [13357, 12437, 13788, 14700, 14515]\n",
        "    }\n",
        ")\n",
        "\n",
        "df.to_csv('large_test_set.csv')"
      ],
      "metadata": {
        "id": "yyZs7v7kFXoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label prediction"
      ],
      "metadata": {
        "id": "1w0ZU-T_u2yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)"
      ],
      "metadata": {
        "id": "NpXTnCJ63_6D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data multiple labels"
      ],
      "metadata": {
        "id": "i1r1FMrdxNj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled_multiple_pos(datalist: list, labellist: list):\n",
        "    # same as the split_labelled function, but takes into account that a sequence has multiple labels\n",
        "    pos_datalist = []\n",
        "    pos_labellist = []\n",
        "    neg_datalist = []\n",
        "    neg_labellist = []\n",
        "    for i, labels in enumerate(labellist):\n",
        "        is_pos = False\n",
        "        for label in labels:\n",
        "            if label:\n",
        "                is_pos = True\n",
        "        if is_pos:\n",
        "            pos_datalist.append(datalist[i])\n",
        "            pos_labellist.append(labels)\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "            neg_labellist.append(labels)\n",
        "    return pos_datalist, pos_labellist, neg_datalist, neg_labellist\n",
        "\n",
        "\n",
        "def zip_n_shuffle(list1: list, list2: list) -> tuple[list, list]:\n",
        "    # Quick function to shuffle the order of sequences\n",
        "    assert len(list1) == len(list2)\n",
        "    combined = list(zip(list1, list2))\n",
        "    random.shuffle(combined)\n",
        "    list1, list2 = zip(*combined)\n",
        "    return list(list1), list(list2)\n",
        "\n",
        "\n",
        "def remove_sequences_multiple_pos(datalist: list, labellist, fraction=0.5):\n",
        "    # Fraction indicates how many sequences are KEPT\n",
        "    datalist, labellist = zip_n_shuffle(datalist, labellist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i], labellist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal_multiple_pos(reduced_datalist: list, reduced_labellist: list, compared_datalist: list):\n",
        "    # Remove sequences from one datalist until it is the same size as the other\n",
        "    # reduced_datalist -> list that needs to be reduced\n",
        "    # compared_datalist -> list for comparison\n",
        "    reduced_datalist, reduced_labellist = zip_n_shuffle(reduced_datalist, reduced_labellist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    reduced_labellist = reduced_labellist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist) or len(compared_datalist) != len(reduced_labellist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist, reduced_labellist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists_multiple_pos(pos_datalist: list, pos_labellist:list, neg_datalist: list, neg_labellist):\n",
        "    # Fuse two datalists and labellists\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labellist + neg_labellist\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def calculate_pos_weights(labellist: list):\n",
        "    # Calculate weights for the loss function\n",
        "    total_samples = len(labellist)\n",
        "    label_counts = torch.Tensor(labellist).sum(0)\n",
        "    pos_weights = (total_samples - label_counts) / (label_counts + 1e-5)\n",
        "    return pos_weights"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer multiple labels"
      ],
      "metadata": {
        "id": "o0TJEbhQxRLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def dataset_stats(dl, ll):\n",
        "    # Gives sequence lengths and amount of positive and negative labels\n",
        "    len_list = []\n",
        "    for s in dl:\n",
        "        len_list.append(len(s))\n",
        "    sns.histplot(len_list)\n",
        "\n",
        "    p = 0\n",
        "    n = 0\n",
        "    for labels in ll:\n",
        "        found_pos = False\n",
        "        for l in labels:\n",
        "            if l:\n",
        "                p += 1\n",
        "                found_pos = True\n",
        "                break\n",
        "        if not found_pos:\n",
        "            n+=1\n",
        "    print(f'{p = }\\n{n = }')\n",
        "\n",
        "\n",
        "class TrainerMultipleClasses:\n",
        "    # Trains the model\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.columns = [\n",
        "            'epoch',\n",
        "            'train_accuracy',\n",
        "            'train_precision',\n",
        "            'train_recall',\n",
        "            'train_fscore',\n",
        "            'train_loss',\n",
        "            'test_accuracy',\n",
        "            'test_precision',\n",
        "            'test_recall',\n",
        "            'test_fscore',\n",
        "            'test_loss'\n",
        "        ]\n",
        "        self.df = pd.DataFrame(columns=self.columns)\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        # Train one epoch\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.train(True)\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            # Run model on input\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "            labels = labels.type(torch.float32)\n",
        "\n",
        "            loss = loss_fn(input=outputs, target=labels)\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            # Count true/false positives/negatives\n",
        "            for b, lab in enumerate(labels):\n",
        "                out = torch.round(torch.sigmoid(outputs[b]))\n",
        "\n",
        "                for j, o in enumerate(out):\n",
        "                    # print(f'{o=}\\t{l=}')\n",
        "                    l = lab[j]\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                # Run model on input\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels\n",
        "                outputs = self.model(inputs).to('cpu')\n",
        "                labels = labels.type(torch.float32)\n",
        "                loss = loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                # Count true/false positives/negatives\n",
        "                for b, lab in enumerate(labels):\n",
        "                    out = torch.round(torch.sigmoid(outputs[b]))\n",
        "                    for j, o in enumerate(out):\n",
        "                        l = lab[j]\n",
        "                        if o == 1 and l == 1:\n",
        "                            tpos += 1\n",
        "                        elif o == 1 and l == 0:\n",
        "                            fpos += 1\n",
        "                        elif o == 0 and l == 0:\n",
        "                            tneg += 1\n",
        "                        elif o == 0 and l == 1:\n",
        "                            fneg += 1\n",
        "                        else:\n",
        "                            raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        # print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _load_into_df(self, epoch, train_stats, test_stats):\n",
        "        # Load run statistics into the dataframe\n",
        "        row = [epoch] + list(train_stats) + list(test_stats)\n",
        "        row = pd.DataFrame(row, index=self.columns).T\n",
        "        self.df = pd.concat([self.df, row], axis=0)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_stats = self._train_one_epoch(train_iter)\n",
        "\n",
        "            test_stats = self._test_one_epoch(test_iter)\n",
        "            self._load_into_df(epoch, train_stats, test_stats)\n",
        "            print(f\"[epoch {epoch:02d}] \"\n",
        "                  f\"train-loss={train_stats[-1]:.4f} | \"\n",
        "                  f\"test-loss={test_stats[-1]:.4f} | \"\n",
        "                  f\"train-acc={train_stats[0]:.4f} | \"\n",
        "                  f\"test-acc={test_stats[0]:.4f} | \"\n",
        "                  f\"P={test_stats[1]:.4f} | R={test_stats[2]:.4f} | F1={test_stats[3]:.4f}\")\n",
        "\n",
        "        return self.df"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model multiple labels"
      ],
      "metadata": {
        "id": "xsJ8Xb1zxVYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, num_classes: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(1),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.BatchNorm1d(conv_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # fully connected block 1\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=64, bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # classification head\n",
        "            nn.LazyLinear(out_features=num_classes, bias=use_bias)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load GO data multiple labels"
      ],
      "metadata": {
        "id": "5H-PP8bUxpCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "p_dl, p_ll, n_dl, n_ll = split_labelled_multiple_pos(dl, ll)\n",
        "n_dl, n_ll = remove_sequences_multiple_pos(n_dl, n_ll, 0.1)\n",
        "dl, ll = fuse_sequence_lists_multiple_pos(p_dl, p_ll, n_dl, n_ll)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.6)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "pos_weights = calculate_pos_weights(train_ll)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "f6d8353e-2478-4b6d-a4b5-0e25c4d099ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10, 15,  0,  ..., 20, 20, 20],\n",
            "        [10,  5, 15,  ..., 20, 20, 20],\n",
            "        [10, 11, 14,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10,  2, 12,  ..., 20, 20, 20],\n",
            "        [10, 14,  3,  ..., 20, 20, 20],\n",
            "        [10,  0, 11,  ..., 20, 20, 20]]), tensor([[0, 1, 0, 0, 1],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in train_dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in train_ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "391c6f31-f359-47cc-d908-16c95151fe3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 871\n",
            "n = 321\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in test_dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in test_ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "4oSjI76oHgkJ",
        "outputId": "3050795d-9c93-42c9-b1d0-3b148088a9d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 583\n",
            "n = 212\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model multiple labels"
      ],
      "metadata": {
        "id": "bcZoEI7-xuop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(num_classes=5, conv_channels=256, use_bias=True)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "ab3f29fa-ad59-4084-b7bd-1152144117d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=64, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer, device)\n",
        "df = trainer.train(epochs=50, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "88dd6b52-a235-4a22-956b-0ff2ed852b42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "<ipython-input-6-27071e2fcb4d>:132: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  self.df = pd.concat([self.df, row], axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 00] train-loss=1.1805 | test-loss=1.1727 | train-acc=0.4186 | test-acc=0.3044 | P=0.1590 | R=0.7511 | F1=0.2625\n",
            "[epoch 01] train-loss=1.1642 | test-loss=1.1767 | train-acc=0.4435 | test-acc=0.6735 | P=0.1065 | R=0.1328 | F1=0.1182\n",
            "[epoch 02] train-loss=1.1612 | test-loss=1.1767 | train-acc=0.4901 | test-acc=0.6292 | P=0.1933 | R=0.3939 | F1=0.2593\n",
            "[epoch 03] train-loss=1.1612 | test-loss=1.1755 | train-acc=0.4673 | test-acc=0.5097 | P=0.1648 | R=0.4855 | F1=0.2460\n",
            "[epoch 04] train-loss=1.1663 | test-loss=1.1843 | train-acc=0.5017 | test-acc=0.2730 | P=0.1703 | R=0.8809 | F1=0.2854\n",
            "[epoch 05] train-loss=1.1608 | test-loss=1.1881 | train-acc=0.4711 | test-acc=0.3019 | P=0.1667 | R=0.8092 | F1=0.2764\n",
            "[epoch 06] train-loss=1.1499 | test-loss=1.2032 | train-acc=0.5045 | test-acc=0.3235 | P=0.1794 | R=0.8687 | F1=0.2974\n",
            "[epoch 07] train-loss=1.1213 | test-loss=1.1717 | train-acc=0.5626 | test-acc=0.4506 | P=0.1743 | R=0.6244 | F1=0.2725\n",
            "[epoch 08] train-loss=1.0965 | test-loss=1.2382 | train-acc=0.5916 | test-acc=0.6762 | P=0.1291 | R=0.1679 | F1=0.1460\n",
            "[epoch 09] train-loss=1.0240 | test-loss=1.2397 | train-acc=0.6411 | test-acc=0.5957 | P=0.2183 | R=0.5634 | F1=0.3147\n",
            "[epoch 10] train-loss=0.9876 | test-loss=1.2575 | train-acc=0.6619 | test-acc=0.5047 | P=0.1776 | R=0.5527 | F1=0.2688\n",
            "[epoch 11] train-loss=0.8770 | test-loss=1.5184 | train-acc=0.7005 | test-acc=0.4342 | P=0.1597 | R=0.5710 | F1=0.2496\n",
            "[epoch 12] train-loss=0.7862 | test-loss=1.4115 | train-acc=0.7480 | test-acc=0.7391 | P=0.2551 | R=0.3038 | F1=0.2774\n",
            "[epoch 13] train-loss=0.6934 | test-loss=2.1582 | train-acc=0.7857 | test-acc=0.6523 | P=0.1912 | R=0.3435 | F1=0.2456\n",
            "[epoch 14] train-loss=0.7005 | test-loss=1.6206 | train-acc=0.7822 | test-acc=0.7004 | P=0.1876 | R=0.2458 | F1=0.2128\n",
            "[epoch 15] train-loss=0.7163 | test-loss=1.5747 | train-acc=0.7933 | test-acc=0.6848 | P=0.1898 | R=0.2794 | F1=0.2261\n",
            "[epoch 16] train-loss=0.7276 | test-loss=1.3109 | train-acc=0.7765 | test-acc=0.6953 | P=0.2668 | R=0.4855 | F1=0.3443\n",
            "[epoch 17] train-loss=0.6954 | test-loss=1.2356 | train-acc=0.7945 | test-acc=0.5660 | P=0.1971 | R=0.5313 | F1=0.2875\n",
            "[epoch 18] train-loss=0.5652 | test-loss=1.3186 | train-acc=0.8275 | test-acc=0.6881 | P=0.2343 | R=0.3939 | F1=0.2938\n",
            "[epoch 19] train-loss=0.4125 | test-loss=2.1557 | train-acc=0.9002 | test-acc=0.6611 | P=0.2539 | R=0.5450 | F1=0.3464\n",
            "[epoch 20] train-loss=0.3446 | test-loss=2.4234 | train-acc=0.9186 | test-acc=0.7779 | P=0.2964 | R=0.2534 | F1=0.2733\n",
            "[epoch 21] train-loss=0.3045 | test-loss=2.9079 | train-acc=0.9322 | test-acc=0.7369 | P=0.2659 | R=0.3389 | F1=0.2980\n",
            "[epoch 22] train-loss=0.3253 | test-loss=2.6712 | train-acc=0.9268 | test-acc=0.7336 | P=0.2047 | R=0.2137 | F1=0.2091\n",
            "[epoch 23] train-loss=0.3931 | test-loss=2.1614 | train-acc=0.9057 | test-acc=0.7401 | P=0.2872 | R=0.3893 | F1=0.3305\n",
            "[epoch 24] train-loss=0.5320 | test-loss=2.2227 | train-acc=0.8787 | test-acc=0.7343 | P=0.2564 | R=0.3221 | F1=0.2855\n",
            "[epoch 25] train-loss=0.6006 | test-loss=2.5517 | train-acc=0.8203 | test-acc=0.7391 | P=0.2834 | R=0.3817 | F1=0.3253\n",
            "[epoch 26] train-loss=0.2392 | test-loss=2.5084 | train-acc=0.9470 | test-acc=0.7260 | P=0.2465 | R=0.3221 | F1=0.2793\n",
            "[epoch 27] train-loss=0.1792 | test-loss=2.5852 | train-acc=0.9629 | test-acc=0.7902 | P=0.3132 | R=0.2290 | F1=0.2646\n",
            "[epoch 28] train-loss=0.2113 | test-loss=2.4888 | train-acc=0.9601 | test-acc=0.7104 | P=0.2110 | R=0.2763 | F1=0.2393\n",
            "[epoch 29] train-loss=0.1401 | test-loss=2.8847 | train-acc=0.9727 | test-acc=0.8018 | P=0.3678 | R=0.2824 | F1=0.3195\n",
            "[epoch 30] train-loss=0.0691 | test-loss=2.6951 | train-acc=0.9881 | test-acc=0.8330 | P=0.4754 | R=0.1328 | F1=0.2076\n",
            "[epoch 31] train-loss=0.0589 | test-loss=3.1033 | train-acc=0.9936 | test-acc=0.8325 | P=0.4699 | R=0.1313 | F1=0.2053\n",
            "[epoch 32] train-loss=0.0380 | test-loss=3.1056 | train-acc=0.9950 | test-acc=0.8340 | P=0.4825 | R=0.1053 | F1=0.1729\n",
            "[epoch 33] train-loss=0.0134 | test-loss=3.4560 | train-acc=0.9997 | test-acc=0.8367 | P=0.5170 | R=0.1389 | F1=0.2190\n",
            "[epoch 34] train-loss=0.0081 | test-loss=4.0044 | train-acc=0.9997 | test-acc=0.8164 | P=0.3967 | R=0.2198 | F1=0.2829\n",
            "[epoch 35] train-loss=0.0070 | test-loss=4.0285 | train-acc=0.9997 | test-acc=0.8395 | P=0.5914 | R=0.0840 | F1=0.1471\n",
            "[epoch 36] train-loss=0.0046 | test-loss=3.9140 | train-acc=0.9998 | test-acc=0.8387 | P=0.5795 | R=0.0779 | F1=0.1373\n",
            "[epoch 37] train-loss=0.0051 | test-loss=3.9718 | train-acc=0.9998 | test-acc=0.8380 | P=0.5579 | R=0.0809 | F1=0.1413\n",
            "[epoch 38] train-loss=0.0037 | test-loss=4.0785 | train-acc=0.9998 | test-acc=0.8387 | P=0.5795 | R=0.0779 | F1=0.1373\n",
            "[epoch 39] train-loss=0.0037 | test-loss=4.2289 | train-acc=0.9998 | test-acc=0.8400 | P=0.6118 | R=0.0794 | F1=0.1405\n",
            "[epoch 40] train-loss=0.0039 | test-loss=4.1601 | train-acc=0.9998 | test-acc=0.8403 | P=0.6220 | R=0.0779 | F1=0.1384\n",
            "[epoch 41] train-loss=0.0029 | test-loss=4.3068 | train-acc=0.9998 | test-acc=0.8400 | P=0.6118 | R=0.0794 | F1=0.1405\n",
            "[epoch 42] train-loss=0.0028 | test-loss=4.4428 | train-acc=0.9998 | test-acc=0.8408 | P=0.5982 | R=0.1023 | F1=0.1747\n",
            "[epoch 43] train-loss=0.0033 | test-loss=4.3795 | train-acc=0.9998 | test-acc=0.8405 | P=0.6296 | R=0.0779 | F1=0.1386\n",
            "[epoch 44] train-loss=0.0025 | test-loss=4.3713 | train-acc=0.9998 | test-acc=0.8400 | P=0.6173 | R=0.0763 | F1=0.1359\n",
            "[epoch 45] train-loss=0.0025 | test-loss=4.6914 | train-acc=0.9998 | test-acc=0.8413 | P=0.6091 | R=0.1023 | F1=0.1752\n",
            "[epoch 46] train-loss=0.0030 | test-loss=4.5065 | train-acc=0.9998 | test-acc=0.8403 | P=0.6220 | R=0.0779 | F1=0.1384\n",
            "[epoch 47] train-loss=0.0023 | test-loss=4.6662 | train-acc=0.9997 | test-acc=0.8408 | P=0.5714 | R=0.1344 | F1=0.2176\n",
            "[epoch 48] train-loss=0.0028 | test-loss=4.3595 | train-acc=0.9998 | test-acc=0.8400 | P=0.6145 | R=0.0779 | F1=0.1382\n",
            "[epoch 49] train-loss=0.0025 | test-loss=4.6021 | train-acc=0.9997 | test-acc=0.8397 | P=0.6023 | R=0.0809 | F1=0.1427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('multi-label_classifier.csv')"
      ],
      "metadata": {
        "id": "RiussApswGYU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Figures"
      ],
      "metadata": {
        "id": "uOilbtffBAiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def reformat_df(df):\n",
        "    # Reformat the dataframe so seaborn accepts it\n",
        "    df = df.drop(\n",
        "        columns=['train_accuracy','train_precision','train_recall','train_fscore']\n",
        "    )\n",
        "    df = pd.melt(\n",
        "        df,\n",
        "        id_vars=['epoch'],\n",
        "        value_vars=['train_loss','test_accuracy','test_precision','test_recall','test_fscore','test_loss']\n",
        "    )\n",
        "    df.rename(columns={'epoch': 'Epoch', 'variable': 'Variable', 'value': 'Value'}, inplace=True)\n",
        "    # df = df.replace('train_accuracy', 'Train Accuracy')\n",
        "    # df = df.replace('train_precision', 'Train Precision')\n",
        "    # df = df.replace('train_recall', 'Train Recall')\n",
        "    # df = df.replace('train_fscore', 'Train F-score')\n",
        "    df = df.replace('train_loss', 'Train Loss')\n",
        "    df = df.replace('test_accuracy', 'Test Accuracy')\n",
        "    df = df.replace('test_precision', 'Test Precision')\n",
        "    df = df.replace('test_recall', 'Test Recall')\n",
        "    df = df.replace('test_fscore', 'Test F-score')\n",
        "    df = df.replace('test_loss', 'Test Loss')\n",
        "    return df\n",
        "\n",
        "\n",
        "def reformat_df_hyper(df):\n",
        "    # Reformat dataframe of the hyperparameter run so seaborn accepts it\n",
        "    df = df.drop(\n",
        "        columns=['train_accuracy','train_precision','train_recall','train_fscore']\n",
        "    )\n",
        "    df = pd.melt(\n",
        "        df,\n",
        "        id_vars=['epoch', 'conv_channels', 'dropout_rate', 'lr', 'momentum'],\n",
        "        value_vars=['train_loss','test_accuracy','test_precision','test_recall','test_fscore','test_loss']\n",
        "    )\n",
        "    df.rename(columns={'epoch': 'Epoch', 'variable': 'Variable', 'value': 'Value'}, inplace=True)\n",
        "    # df = df.replace('train_accuracy', 'Train Accuracy')\n",
        "    # df = df.replace('train_precision', 'Train Precision')\n",
        "    # df = df.replace('train_recall', 'Train Recall')\n",
        "    # df = df.replace('train_fscore', 'Train F-score')\n",
        "    df = df.replace('train_loss', 'Train Loss')\n",
        "    df = df.replace('test_accuracy', 'Test Accuracy')\n",
        "    df = df.replace('test_precision', 'Test Precision')\n",
        "    df = df.replace('test_recall', 'Test Recall')\n",
        "    df = df.replace('test_fscore', 'Test F-score')\n",
        "    df = df.replace('test_loss', 'Test Loss')\n",
        "    return df\n",
        "\n",
        "\n",
        "def plot_single_model(df, **kwargs):\n",
        "    # Plot run statistics in a lineplot\n",
        "    # If linepath is given as arguemnt, save as .svg\n",
        "    ax = sns.lineplot(df, x='Epoch', y='Value', hue='Variable')\n",
        "    sns.move_legend(\n",
        "        obj=ax,\n",
        "        loc='upper left',\n",
        "        bbox_to_anchor=(1, 1)\n",
        "    )\n",
        "    if 'filepath' in kwargs.keys():\n",
        "        plt.savefig(kwargs['filepath'], format='svg', bbox_inches='tight')\n",
        "        plt.clf()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "GqAqH6ylA_w-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figures of the hyperparameter grid search\n",
        "df = pd.read_csv('hyperparameter_grid_len200_500_n5000nr1.csv')\n",
        "df = reformat_df_hyper(df)\n",
        "\n",
        "groups = df.groupby(['conv_channels', 'dropout_rate', 'lr', 'momentum'])\n",
        "\n",
        "split_dfs = {name: group for name, group in groups}\n",
        "\n",
        "for key in split_dfs.keys():\n",
        "    sub_df = split_dfs[key]\n",
        "    path = f'hyper_conv_channels_{key[0]}_dropout_{key[1]}_lr_{key[2]}_momentum_{key[3]}'.replace('.', '_') + '.svg'\n",
        "    plot_single_model(sub_df, filepath=path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DaYwNE_JJ8F9",
        "outputId": "8b2923e7-b8b0-4bfc-82f6-c04c9eaaf4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figures of the dataset composition with simulated data\n",
        "sim_csv = [\n",
        "    'half_neg_len200_500_n5000nr1',\n",
        "    'half_pos_len200_500_n5000nr1'\n",
        "]\n",
        "\n",
        "for sim in sim_csv:\n",
        "    df = pd.read_csv(f'{sim}.csv')\n",
        "    df = reformat_df(df)\n",
        "    plot_single_model(df, filepath=f'{sim}.svg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0sro9icJHXQt",
        "outputId": "ebcba2a3-3e6d-49c3-b35f-04669a29033d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figures of all five GO annotation models\n",
        "go_csv = [\n",
        "    \"GO_3A0005576\",\n",
        "    \"GO_3A0005739\",\n",
        "    \"GO_3A0007165\",\n",
        "    \"GO_3A0043066\",\n",
        "    \"GO_3A0055085\"\n",
        "]\n",
        "\n",
        "\n",
        "for go in go_csv:\n",
        "    df = pd.read_csv(f'{go}.csv')\n",
        "    df = reformat_df(df)\n",
        "    plot_single_model(df, filepath=f'{go}.svg')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lf0fZG0CF_gQ",
        "outputId": "45bbdfbc-9024-4b37-ae15-a3f4eaded477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figures of dataset composition with GO annotated data\n",
        "other_go_csv = [\n",
        "    \"GO_3A0005576_full_set\",\n",
        "    \"GO_3A0005576_half_pos\",\n",
        "    \"GO_3A0005576_half_neg\"\n",
        "]\n",
        "\n",
        "for go in other_go_csv:\n",
        "    df = pd.read_csv(f'{go}.csv')\n",
        "    df = reformat_df(df)\n",
        "    plot_single_model(df, filepath=f'{go}.svg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xfA-gz2b-2OV",
        "outputId": "502ad817-72b8-4a37-c794-a5b975e45169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figures of dataset composition with GO annotated data\n",
        "df = pd.read_csv('GO_3A0005576_full_set.csv')\n",
        "df = reformat_df(df)\n",
        "plot_single_model(df, filepath='GO_3A0005576_full_set.svg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7F5zlDwEJxeb",
        "outputId": "8ef584d1-2701-4381-93f5-474957462018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results of the large human test set in a barplot\n",
        "def plot_large_test_set(df, **kwargs):\n",
        "    df = df.melt(id_vars=['Annotation'], value_vars=['Positive', 'Negative'], var_name='Label', value_name='Amount')\n",
        "    ax = sns.barplot(data=df, x='Annotation', y='Amount', hue='Label')\n",
        "    plt.xticks(rotation=70)\n",
        "    sns.move_legend(\n",
        "        obj=ax,\n",
        "        loc='upper left',\n",
        "        bbox_to_anchor=(1, 1)\n",
        "    )\n",
        "    if 'filepath' in kwargs.keys():\n",
        "        plt.savefig(kwargs['filepath'], format='svg', bbox_inches='tight')\n",
        "        plt.clf()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "df = pd.read_csv('large_test_set.csv')\n",
        "plot_large_test_set(df, filepath='large_test_set_barplot.svg')\n"
      ],
      "metadata": {
        "id": "OyzgUltJHsxO",
        "outputId": "150c981e-12f5-456a-9727-ed3d57217cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create figure of the multi-label classifier run statistics\n",
        "df = pd.read_csv('multi-label_classifier.csv')\n",
        "df = reformat_df(df)\n",
        "plot_single_model(df, filepath='multi-label_classifier.svg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQa4EfD1ICyV",
        "outputId": "23c49aee-a127-445f-8a99-e3dc2deeca37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}