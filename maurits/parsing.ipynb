{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1eed23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'grs34806-deep-learning-project-data'...\n",
      "remote: Enumerating objects: 21, done.\u001b[K\n",
      "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
      "Receiving objects: 100% (21/21), 8.74 MiB | 13.58 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git\n",
    "os.chdir(\"grs34806-deep-learning-project-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e9440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install biopython --quiet\n",
    "! pip install torch --quiet\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf57731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def read(seqfile,posfile):\n",
    "    # datalist contains sequences, labellist contains labels\n",
    "    # seqfile: file with sequences\n",
    "    # posfile: file with positive cases (annotated with function)\n",
    "    idlist = []\n",
    "    datalist = []\n",
    "    labellist = []\n",
    "    with open(seqfile, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.rstrip().split('\\t')\n",
    "            idlist.append(line[0])\n",
    "            datalist.append(line[1])\n",
    "            labellist.append(False)\n",
    "    with open(posfile, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            id = line.rstrip()\n",
    "            try:\n",
    "                i = idlist.index(id)\n",
    "                labellist[i] = True\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return datalist, labellist\n",
    "\n",
    "\n",
    "\n",
    "def generate_train_test(datalist, labellist):\n",
    "    # Split up dataset in training set and test set\n",
    "    i = len(datalist) // 4 * 3\n",
    "    traindatalist = datalist[:i]\n",
    "    trainlabellist = labellist[:i]\n",
    "    testdatalist = datalist[i:]\n",
    "    testlabellist = labellist[i:]\n",
    "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
    "\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "\n",
    "    Defined in :numref:`sec_utils`\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "\n",
    "def load_data(batch_size, num_steps, dataset):\n",
    "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
    "    seq,lab = dataset\n",
    "    seq = tokenize(seq, mapaa2num)\n",
    "    seq_array = build_seq_array(seq, num_steps)\n",
    "    data_arrays = (seq_array, torch.tensor(lab))\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter\n",
    "\n",
    "\n",
    "def tokenize(data, map2num, non_aa_num=20):\n",
    "    seq = []\n",
    "    for count, i in enumerate(data):\n",
    "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
    "    return seq\n",
    "\n",
    "\n",
    "def build_seq_array(lines, num_steps, non_aa_num=20):\n",
    "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines])\n",
    "\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps] # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691dad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2e38a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[10, 19,  0,  8, 14, 19,  3, 13, 15, 19],\n",
      "        [10, 13, 13, 17,  4,  2,  2, 14, 17,  4],\n",
      "        [10,  6, 13,  3,  7, 18,  1, 18,  3,  0],\n",
      "        [10, 19, 11, 18,  5, 18, 10,  3, 15, 13],\n",
      "        [10,  2,  5, 17, 14, 16,  9, 14, 12, 13]]), tensor([ True, False, False,  True, False])]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_steps = 10\n",
    "\n",
    "# Example for one of the simulated datasets\n",
    "datalist, labellist = read(\"len100_200_n1000.seq\", \"len100_200_n1000.pos\")\n",
    "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist)\n",
    "traindataset = [traindatalist, trainlabellist]\n",
    "testdataset = [testdatalist, testlabellist]\n",
    "\n",
    "# Set batch_size and num_steps (maximum sequence length)\n",
    "train_iter = load_data(batch_size, num_steps, traindataset)\n",
    "test_iter = load_data(batch_size, num_steps, testdataset)\n",
    "\n",
    "print(next(iter(train_iter)))\n",
    "\n",
    "# # Define MYMODEL yourself - we do not give details about it here\n",
    "# net = MYMODEL\n",
    "# # trainfunction will have additional arguments;\n",
    "# # This is yours to make - we do not give details about it\n",
    "# trainfunction(net, train_iter, test_iter, ....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c87fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5088\n",
      "5088\n",
      "1696\n",
      "1696\n"
     ]
    }
   ],
   "source": [
    "datalist, labellist = read('expr5Tseq_filtGO_100-1000.lis', 'GO_3A0005739.annotprot')\n",
    "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist)\n",
    "print(len(traindatalist))\n",
    "print(len(trainlabellist))\n",
    "print(len(testdatalist))\n",
    "print(len(testlabellist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
