{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QrywNfRlazm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92145e57-fecf-4d3d-f967-7db929a27944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grs34806-deep-learning-project-data' already exists and is not an empty directory.\n",
            "fatal: destination path 'GRS34806-project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "SEpH6j4dbJuO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "DzPLAugMwzCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    random.shuffle(datalist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal(reduced_datalist: list, compared_datalist: list):\n",
        "    random.shuffle(reduced_datalist)\n",
        "    random.shuffle(compared_datalist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load paired data"
      ],
      "metadata": {
        "id": "iFc0lo8vw291"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "# Example for one of the simulated datasets\n",
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0055085.annotprot\")\n",
        "# datalist, labellist = read(\"len200_500_n5000nr4.seq\", \"len200_500_n5000nr4.pos\")\n",
        "\n",
        "# Remove negatives\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.1)\n",
        "# neg_datalist = remove_sequences_equal(neg_datalist, pos_datalist)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.6)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(next(iter(train_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "08e74a12-8090-4e5f-ad9c-ee243796bb58"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10, 17,  9,  ..., 20, 20, 20],\n",
            "        [10,  0,  0,  ..., 20, 20, 20],\n",
            "        [10,  3,  7,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10,  9,  5,  ..., 20, 20, 20],\n",
            "        [10, 15, 17,  ..., 20, 20, 20],\n",
            "        [10, 15, 14,  ..., 20, 20, 20]]), tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for l in labellist:\n",
        "    if l:\n",
        "        p += 1\n",
        "    else:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "26FSv9_pGhWY",
        "outputId": "993e8055-f846-48b7-ecce-3e48d64cb365"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 226\n",
            "n = 656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train functions binary classifier"
      ],
      "metadata": {
        "id": "reETSGvLw6-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.train(True)\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "\n",
        "            inputs = inputs.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            result_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                l = l.item()\n",
        "                if o == 1 and l == 1:\n",
        "                    tpos += 1\n",
        "                elif o == 1 and l == 0:\n",
        "                    fpos += 1\n",
        "                elif o == 0 and l == 0:\n",
        "                    tneg += 1\n",
        "                elif o == 0 and l == 1:\n",
        "                    fneg += 1\n",
        "                else:\n",
        "                    raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                outputs = self.model(inputs).to('cpu')\n",
        "\n",
        "                loss = self.loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                for j, l in enumerate(labels):\n",
        "                    o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                    l = l.item()\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            train_acc, train_prec, train_rec, train_f, train_loss = self._train_one_epoch(train_iter)\n",
        "            test_acc, test_prec, test_rec, test_f, test_loss = self._test_one_epoch(test_iter)\n",
        "            print(f'{epoch = }\\t{train_loss=:.5f}\\t{test_loss=:.5f}\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{test_prec=:.5f}\\t{test_rec=:.5f}\\t{test_f=:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3Btdmdhj36zM"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimal model (does not work)"
      ],
      "metadata": {
        "id": "I2n78bgjw-uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MinimalGOClassifierCNN(nn.Module):\n",
        "    def __init__(self, input_length: int, vocab_size : int=21,  num_filters: int=32, kernel_size: int=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv_layer(x.transpose(1,2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        output = F.softmax(x, 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6Agj87Dpbf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Berry's model (works, go to for binary classification)"
      ],
      "metadata": {
        "id": "1wX4qCXZxCzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670133ec-aa1b-4eab-ff40-8371957ca58c",
        "id": "-kFRoPlYpeKe"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BerryCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "AMz0guzKptRZ",
        "outputId": "9a828106-b06e-48dc-f64c-e2129f347340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.59139\ttest_loss=0.55797\ttrain_acc=0.73157\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 1\ttrain_loss=0.56660\ttest_loss=0.56278\ttrain_acc=0.73724\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 2\ttrain_loss=0.56258\ttest_loss=0.55463\ttrain_acc=0.73724\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 3\ttrain_loss=0.54069\ttest_loss=0.54407\ttrain_acc=0.74669\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 4\ttrain_loss=0.52345\ttest_loss=0.54486\ttrain_acc=0.73724\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 5\ttrain_loss=0.51655\ttest_loss=0.57330\ttrain_acc=0.73913\ttest_acc=0.79037\ttest_prec=0.88235\ttest_rec=0.17241\ttest_f=0.28846\n",
            "epoch = 6\ttrain_loss=0.51245\ttest_loss=0.51653\ttrain_acc=0.78450\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 7\ttrain_loss=0.47873\ttest_loss=0.53008\ttrain_acc=0.77883\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 8\ttrain_loss=0.45053\ttest_loss=0.49675\ttrain_acc=0.77694\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 9\ttrain_loss=0.41333\ttest_loss=0.49908\ttrain_acc=0.79395\ttest_acc=0.75354\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 10\ttrain_loss=0.39641\ttest_loss=0.48046\ttrain_acc=0.82231\ttest_acc=0.76204\ttest_prec=1.00000\ttest_rec=0.03448\ttest_f=0.06667\n",
            "epoch = 11\ttrain_loss=0.36174\ttest_loss=0.48546\ttrain_acc=0.84688\ttest_acc=0.82720\ttest_prec=0.82500\ttest_rec=0.37931\ttest_f=0.51969\n",
            "epoch = 12\ttrain_loss=0.34788\ttest_loss=0.47390\ttrain_acc=0.86957\ttest_acc=0.76771\ttest_prec=0.85714\ttest_rec=0.06897\ttest_f=0.12766\n",
            "epoch = 13\ttrain_loss=0.31280\ttest_loss=0.46188\ttrain_acc=0.90170\ttest_acc=0.81020\ttest_prec=0.91667\ttest_rec=0.25287\ttest_f=0.39640\n",
            "epoch = 14\ttrain_loss=0.29650\ttest_loss=0.47666\ttrain_acc=0.90926\ttest_acc=0.76204\ttest_prec=1.00000\ttest_rec=0.03448\ttest_f=0.06667\n",
            "epoch = 15\ttrain_loss=0.26968\ttest_loss=0.45367\ttrain_acc=0.92628\ttest_acc=0.83286\ttest_prec=0.76923\ttest_rec=0.45977\ttest_f=0.57554\n",
            "epoch = 16\ttrain_loss=0.24919\ttest_loss=0.48458\ttrain_acc=0.94140\ttest_acc=0.76487\ttest_prec=1.00000\ttest_rec=0.04598\ttest_f=0.08791\n",
            "epoch = 17\ttrain_loss=0.24321\ttest_loss=0.44699\ttrain_acc=0.92628\ttest_acc=0.79603\ttest_prec=0.94118\ttest_rec=0.18391\ttest_f=0.30769\n",
            "epoch = 18\ttrain_loss=0.21201\ttest_loss=0.42957\ttrain_acc=0.95085\ttest_acc=0.83003\ttest_prec=0.75472\ttest_rec=0.45977\ttest_f=0.57143\n",
            "epoch = 19\ttrain_loss=0.18880\ttest_loss=0.43507\ttrain_acc=0.95841\ttest_acc=0.80453\ttest_prec=0.95000\ttest_rec=0.21839\ttest_f=0.35514\n",
            "epoch = 20\ttrain_loss=0.17758\ttest_loss=0.42143\ttrain_acc=0.96975\ttest_acc=0.82720\ttest_prec=0.74074\ttest_rec=0.45977\ttest_f=0.56738\n",
            "epoch = 21\ttrain_loss=0.16227\ttest_loss=0.42715\ttrain_acc=0.97732\ttest_acc=0.83569\ttest_prec=0.79592\ttest_rec=0.44828\ttest_f=0.57353\n",
            "epoch = 22\ttrain_loss=0.14817\ttest_loss=0.41158\ttrain_acc=0.98488\ttest_acc=0.83569\ttest_prec=0.79592\ttest_rec=0.44828\ttest_f=0.57353\n",
            "epoch = 23\ttrain_loss=0.14057\ttest_loss=0.40954\ttrain_acc=0.98110\ttest_acc=0.83569\ttest_prec=0.80851\ttest_rec=0.43678\ttest_f=0.56716\n",
            "epoch = 24\ttrain_loss=0.12259\ttest_loss=0.41269\ttrain_acc=0.98677\ttest_acc=0.82436\ttest_prec=0.72727\ttest_rec=0.45977\ttest_f=0.56338\n",
            "epoch = 25\ttrain_loss=0.11603\ttest_loss=0.41532\ttrain_acc=0.99622\ttest_acc=0.83003\ttest_prec=0.80000\ttest_rec=0.41379\ttest_f=0.54545\n",
            "epoch = 26\ttrain_loss=0.10453\ttest_loss=0.41346\ttrain_acc=0.99244\ttest_acc=0.83569\ttest_prec=0.80851\ttest_rec=0.43678\ttest_f=0.56716\n",
            "epoch = 27\ttrain_loss=0.09462\ttest_loss=0.42377\ttrain_acc=0.99811\ttest_acc=0.83003\ttest_prec=0.88571\ttest_rec=0.35632\ttest_f=0.50820\n",
            "epoch = 28\ttrain_loss=0.08658\ttest_loss=0.42765\ttrain_acc=0.99811\ttest_acc=0.84136\ttest_prec=0.86047\ttest_rec=0.42529\ttest_f=0.56923\n",
            "epoch = 29\ttrain_loss=0.08005\ttest_loss=0.41718\ttrain_acc=1.00000\ttest_acc=0.83003\ttest_prec=0.72881\ttest_rec=0.49425\ttest_f=0.58904\n",
            "epoch = 30\ttrain_loss=0.07473\ttest_loss=0.41656\ttrain_acc=1.00000\ttest_acc=0.83569\ttest_prec=0.85366\ttest_rec=0.40230\ttest_f=0.54688\n",
            "epoch = 31\ttrain_loss=0.06769\ttest_loss=0.40171\ttrain_acc=1.00000\ttest_acc=0.82720\ttest_prec=0.70968\ttest_rec=0.50575\ttest_f=0.59060\n",
            "epoch = 32\ttrain_loss=0.06448\ttest_loss=0.42349\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.78846\ttest_rec=0.47126\ttest_f=0.58993\n",
            "epoch = 33\ttrain_loss=0.05793\ttest_loss=0.41549\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.85714\ttest_rec=0.41379\ttest_f=0.55814\n",
            "epoch = 34\ttrain_loss=0.05436\ttest_loss=0.40301\ttrain_acc=1.00000\ttest_acc=0.83003\ttest_prec=0.72881\ttest_rec=0.49425\ttest_f=0.58904\n",
            "epoch = 35\ttrain_loss=0.05245\ttest_loss=0.41839\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.80000\ttest_rec=0.45977\ttest_f=0.58394\n",
            "epoch = 36\ttrain_loss=0.04913\ttest_loss=0.40499\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.78846\ttest_rec=0.47126\ttest_f=0.58993\n",
            "epoch = 37\ttrain_loss=0.04512\ttest_loss=0.39843\ttrain_acc=1.00000\ttest_acc=0.83003\ttest_prec=0.71429\ttest_rec=0.51724\ttest_f=0.60000\n",
            "epoch = 38\ttrain_loss=0.04252\ttest_loss=0.42084\ttrain_acc=1.00000\ttest_acc=0.84136\ttest_prec=0.86047\ttest_rec=0.42529\ttest_f=0.56923\n",
            "epoch = 39\ttrain_loss=0.03971\ttest_loss=0.40801\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.78846\ttest_rec=0.47126\ttest_f=0.58993\n",
            "epoch = 40\ttrain_loss=0.03775\ttest_loss=0.42309\ttrain_acc=1.00000\ttest_acc=0.84136\ttest_prec=0.79245\ttest_rec=0.48276\ttest_f=0.60000\n",
            "epoch = 41\ttrain_loss=0.03551\ttest_loss=0.45340\ttrain_acc=1.00000\ttest_acc=0.82720\ttest_prec=0.90625\ttest_rec=0.33333\ttest_f=0.48739\n",
            "epoch = 42\ttrain_loss=0.03501\ttest_loss=0.40439\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.78846\ttest_rec=0.47126\ttest_f=0.58993\n",
            "epoch = 43\ttrain_loss=0.03211\ttest_loss=0.44457\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.80000\ttest_rec=0.45977\ttest_f=0.58394\n",
            "epoch = 44\ttrain_loss=0.03017\ttest_loss=0.41275\ttrain_acc=1.00000\ttest_acc=0.84136\ttest_prec=0.79245\ttest_rec=0.48276\ttest_f=0.60000\n",
            "epoch = 45\ttrain_loss=0.02920\ttest_loss=0.41483\ttrain_acc=1.00000\ttest_acc=0.84136\ttest_prec=0.80392\ttest_rec=0.47126\ttest_f=0.59420\n",
            "epoch = 46\ttrain_loss=0.02739\ttest_loss=0.42618\ttrain_acc=1.00000\ttest_acc=0.84136\ttest_prec=0.84444\ttest_rec=0.43678\ttest_f=0.57576\n",
            "epoch = 47\ttrain_loss=0.02633\ttest_loss=0.40286\ttrain_acc=1.00000\ttest_acc=0.83003\ttest_prec=0.72881\ttest_rec=0.49425\ttest_f=0.58904\n",
            "epoch = 48\ttrain_loss=0.02520\ttest_loss=0.41104\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.78846\ttest_rec=0.47126\ttest_f=0.58993\n",
            "epoch = 49\ttrain_loss=0.02391\ttest_loss=0.41847\ttrain_acc=1.00000\ttest_acc=0.83853\ttest_prec=0.80000\ttest_rec=0.45977\ttest_f=0.58394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra convolutional layer (does not improve)"
      ],
      "metadata": {
        "id": "_dsG7ooLxI2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MoreCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "M6H_ib65yCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MoreCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBZC4GHeLUHz",
        "outputId": "4cb3b9e9-935f-47da-e0d0-d87df22ab1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MoreCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fh2DuxL8e7n",
        "outputId": "3f6296b1-1e39-4491-b330-d21c3136e2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.35404\ttest_loss=0.33095\n",
            "epoch = 1\ttrain_loss=0.33558\ttest_loss=0.32332\n",
            "epoch = 2\ttrain_loss=0.32925\ttest_loss=0.32346\n",
            "epoch = 3\ttrain_loss=0.31973\ttest_loss=0.31417\n",
            "epoch = 4\ttrain_loss=0.30916\ttest_loss=0.32241\n",
            "epoch = 5\ttrain_loss=0.30079\ttest_loss=0.30237\n",
            "epoch = 6\ttrain_loss=0.28817\ttest_loss=0.29379\n",
            "epoch = 7\ttrain_loss=0.27623\ttest_loss=0.28432\n",
            "epoch = 8\ttrain_loss=0.25552\ttest_loss=0.27249\n",
            "epoch = 9\ttrain_loss=0.23447\ttest_loss=0.29422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data multiple labels"
      ],
      "metadata": {
        "id": "i1r1FMrdxNj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled_multiple_pos(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    pos_labellist = []\n",
        "    neg_datalist = []\n",
        "    neg_labellist = []\n",
        "    for i, labels in enumerate(labellist):\n",
        "        is_pos = False\n",
        "        for label in labels:\n",
        "            if label:\n",
        "                is_pos = True\n",
        "        if is_pos:\n",
        "            pos_datalist.append(datalist[i])\n",
        "            pos_labellist.append(labels)\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "            neg_labellist.append(labels)\n",
        "    return pos_datalist, pos_labellist, neg_datalist, neg_labellist\n",
        "\n",
        "\n",
        "def zip_n_shuffle(list1: list, list2: list) -> tuple[list, list]:\n",
        "    assert len(list1) == len(list2)\n",
        "    combined = list(zip(list1, list2))\n",
        "    random.shuffle(combined)\n",
        "    list1, list2 = zip(*combined)\n",
        "    return list(list1), list(list2)\n",
        "\n",
        "\n",
        "def remove_sequences_multiple_pos(datalist: list, labellist, fraction=0.5):\n",
        "    datalist, labellist = zip_n_shuffle(datalist, labellist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i], labellist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal_multiple_pos(reduced_datalist: list, reduced_labellist: list, compared_datalist: list):\n",
        "    reduced_datalist, reduced_labellist = zip_n_shuffle(reduced_datalist, reduced_labellist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    reduced_labellist = reduced_labellist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist) or len(compared_datalist) != len(reduced_labellist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist, reduced_labellist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists_multiple_pos(pos_datalist: list, pos_labellist:list, neg_datalist: list, neg_labellist):\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labellist + neg_labellist\n",
        "    return datalist, labellist"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer multiple labels"
      ],
      "metadata": {
        "id": "o0TJEbhQxRLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class TrainerMultipleClasses:\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.train(True)\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "            labels = labels.type(torch.float32)\n",
        "\n",
        "            loss = loss_fn(input=outputs, target=labels)\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            for b, lab in enumerate(labels):\n",
        "                out = torch.round(torch.sigmoid(outputs[b]))\n",
        "\n",
        "                for j, o in enumerate(out):\n",
        "                    print(f'{o=}\\t{l=}')\n",
        "                    l = lab[j]\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "                    print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels\n",
        "                outputs = self.model(inputs).to('cpu')\n",
        "                labels = labels.type(torch.float32)\n",
        "                loss = loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                for b, lab in enumerate(labels):\n",
        "                    out = torch.round(torch.sigmoid(outputs[b]))\n",
        "                    for j, o in enumerate(out):\n",
        "                        l = lab[j]\n",
        "                        if o == 1 and l == 1:\n",
        "                            tpos += 1\n",
        "                        elif o == 1 and l == 0:\n",
        "                            fpos += 1\n",
        "                        elif o == 0 and l == 0:\n",
        "                            tneg += 1\n",
        "                        elif o == 0 and l == 1:\n",
        "                            fneg += 1\n",
        "                        else:\n",
        "                            raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        # print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            train_acc, train_prec, train_rec, train_f, train_loss = self._train_one_epoch(train_iter)\n",
        "            test_acc, test_prec, test_rec, test_f, test_loss = self._test_one_epoch(test_iter)\n",
        "            print(f'{epoch = }\\t{train_loss=:.5f}\\t{test_loss=:.5f}\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{test_prec=:.5f}\\t{test_rec=:.5f}\\t{test_f=:.5f}')"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model multiple labels"
      ],
      "metadata": {
        "id": "xsJ8Xb1zxVYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, num_classes: int, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=64, bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.LazyLinear(out_features=num_classes, bias=use_bias)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load GO data multiple labels"
      ],
      "metadata": {
        "id": "5H-PP8bUxpCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "dl, ll, _, _ = split_labelled_multiple_pos(dl, ll)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.6)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "624f2ffe-f0ea-457f-84f5-03e4790c3e88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0,  4,  ..., 20, 20, 20],\n",
            "        [10,  5, 12,  ..., 20, 20, 20],\n",
            "        [10, 16,  3,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10, 18, 14,  ..., 20, 20, 20],\n",
            "        [10,  5,  9,  ..., 20, 20, 20],\n",
            "        [10,  8, 17,  ..., 20, 20, 20]]), tensor([[0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 1, 0],\n",
            "        [0, 0, 0, 1, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "a707928f-eb43-4782-b7ab-6e5bbbfccfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 1454\n",
            "n = 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model multiple labels"
      ],
      "metadata": {
        "id": "bcZoEI7-xuop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(num_classes=5, context_size=num_steps, conv_channels=256)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "a9f79755-e257-4a56-f98f-90650d74d09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=64, bias=False)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=5, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer, device)\n",
        "trainer.train(epochs=10, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "4b5689da-0450-4552-e39d-46c5568a8039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.56036\ttest_loss=0.53180\ttrain_acc=0.01399\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 1\ttrain_loss=0.52445\ttest_loss=0.53029\ttrain_acc=0.00252\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 2\ttrain_loss=0.52029\ttest_loss=0.52733\ttrain_acc=0.00183\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 3\ttrain_loss=0.52325\ttest_loss=0.52901\ttrain_acc=0.00046\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 4\ttrain_loss=0.52498\ttest_loss=0.52555\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 5\ttrain_loss=0.52082\ttest_loss=0.52643\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 6\ttrain_loss=0.52187\ttest_loss=0.52682\ttrain_acc=0.00069\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 7\ttrain_loss=0.51927\ttest_loss=0.53007\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 8\ttrain_loss=0.52084\ttest_loss=0.52788\ttrain_acc=0.00000\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 9\ttrain_loss=0.52192\ttest_loss=0.52884\ttrain_acc=0.00046\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n"
          ]
        }
      ]
    }
  ]
}