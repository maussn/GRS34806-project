{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QrywNfRlazm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1940bc3e-c742-4475-c802-966d0bf1d038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grs34806-deep-learning-project-data' already exists and is not an empty directory.\n",
            "fatal: destination path 'GRS34806-project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "SEpH6j4dbJuO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    random.shuffle(datalist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal(reduced_datalist: list, compared_datalist: list):\n",
        "    random.shuffle(reduced_datalist)\n",
        "    random.shuffle(compared_datalist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 500\n",
        "\n",
        "# Example for one of the simulated datasets\n",
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0055085.annotprot\")\n",
        "# datalist, labellist = read(\"len200_500_n5000nr4.seq\", \"len200_500_n5000nr4.pos\")\n",
        "\n",
        "# Remove negatives\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.1)\n",
        "# neg_datalist = remove_sequences_equal(neg_datalist, pos_datalist)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.6)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(next(iter(train_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "681ac541-2e74-4b0e-8a5a-95dd6af7ba90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0,  0,  ..., 20, 20, 20],\n",
            "        [10, 15, 10,  ..., 14, 12,  0],\n",
            "        [10, 11,  5,  ..., 19, 16, 14],\n",
            "        ...,\n",
            "        [10, 17,  5,  ..., 20, 20, 20],\n",
            "        [10,  4,  3,  ..., 20, 20, 20],\n",
            "        [10,  3, 14,  ...,  3, 14,  8]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for l in labellist:\n",
        "    if l:\n",
        "        p += 1\n",
        "    else:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "26FSv9_pGhWY",
        "outputId": "34c78d53-c957-4f9f-8cff-a9c6bcc73ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 226\n",
            "n = 656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, epoch_index, train_iter):\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        result_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            result_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                if o == l:\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "        return correct_predictions / total_predictions, result_loss / (i + 1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_acc, train_loss = self._train_one_epoch(epoch, train_iter)\n",
        "            self.model.eval()\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "            result_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(test_iter):\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.loss_fn(outputs, labels)\n",
        "                    result_loss += loss.item()\n",
        "                    # print(f'{loss = }\\t{test_outputs = }\\t{test_labels = }')\n",
        "                    # print(f'{outputs = }')\n",
        "                    # print(f'{labels = }')\n",
        "                    for j, l in enumerate(labels):\n",
        "                        o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                        if o == l:\n",
        "                            correct_predictions += 1\n",
        "                        total_predictions += 1\n",
        "            test_acc = correct_predictions / total_predictions\n",
        "            test_loss = result_loss / (i + 1)\n",
        "            print(f'{epoch = }\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{train_loss=:.5f}\\t{test_loss=:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3Btdmdhj36zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MinimalGOClassifierCNN(nn.Module):\n",
        "    def __init__(self, input_length: int, vocab_size : int=21,  num_filters: int=32, kernel_size: int=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv_layer(x.transpose(1,2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        output = F.softmax(x, 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6Agj87Dpbf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf9552d-d6cc-4ea3-e6e0-60c66118a4fd",
        "id": "-kFRoPlYpeKe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BerryCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "AMz0guzKptRZ",
        "outputId": "129befb4-d659-4e51-ed73-15ff9a64f442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_acc=0.74102\ttest_acc=0.71671\ttrain_loss=0.59123\ttest_loss=0.60524\n",
            "epoch = 1\ttrain_acc=0.76181\ttest_acc=0.71955\ttrain_loss=0.54158\ttest_loss=0.63385\n",
            "epoch = 2\ttrain_acc=0.76371\ttest_acc=0.71671\ttrain_loss=0.55572\ttest_loss=0.58998\n",
            "epoch = 3\ttrain_acc=0.76181\ttest_acc=0.71671\ttrain_loss=0.51166\ttest_loss=0.62685\n",
            "epoch = 4\ttrain_acc=0.76181\ttest_acc=0.71671\ttrain_loss=0.50419\ttest_loss=0.55958\n",
            "epoch = 5\ttrain_acc=0.76560\ttest_acc=0.71671\ttrain_loss=0.47833\ttest_loss=0.54834\n",
            "epoch = 6\ttrain_acc=0.76938\ttest_acc=0.71671\ttrain_loss=0.46290\ttest_loss=0.53659\n",
            "epoch = 7\ttrain_acc=0.79206\ttest_acc=0.71671\ttrain_loss=0.45262\ttest_loss=0.58852\n",
            "epoch = 8\ttrain_acc=0.81096\ttest_acc=0.75071\ttrain_loss=0.43852\ttest_loss=0.51546\n",
            "epoch = 9\ttrain_acc=0.83932\ttest_acc=0.71671\ttrain_loss=0.40894\ttest_loss=0.55372\n",
            "epoch = 10\ttrain_acc=0.83176\ttest_acc=0.75921\ttrain_loss=0.39325\ttest_loss=0.50513\n",
            "epoch = 11\ttrain_acc=0.86200\ttest_acc=0.72238\ttrain_loss=0.37021\ttest_loss=0.52007\n",
            "epoch = 12\ttrain_acc=0.85444\ttest_acc=0.79320\ttrain_loss=0.35412\ttest_loss=0.50812\n",
            "epoch = 13\ttrain_acc=0.88091\ttest_acc=0.79320\ttrain_loss=0.33304\ttest_loss=0.48538\n",
            "epoch = 14\ttrain_acc=0.89036\ttest_acc=0.74221\ttrain_loss=0.30866\ttest_loss=0.50351\n",
            "epoch = 15\ttrain_acc=0.90548\ttest_acc=0.80170\ttrain_loss=0.29183\ttest_loss=0.48260\n",
            "epoch = 16\ttrain_acc=0.91304\ttest_acc=0.79603\ttrain_loss=0.27021\ttest_loss=0.47485\n",
            "epoch = 17\ttrain_acc=0.93384\ttest_acc=0.78754\ttrain_loss=0.25483\ttest_loss=0.46939\n",
            "epoch = 18\ttrain_acc=0.93762\ttest_acc=0.75071\ttrain_loss=0.23448\ttest_loss=0.50017\n",
            "epoch = 19\ttrain_acc=0.94707\ttest_acc=0.77904\ttrain_loss=0.21742\ttest_loss=0.47437\n",
            "epoch = 20\ttrain_acc=0.96219\ttest_acc=0.79887\ttrain_loss=0.19573\ttest_loss=0.46194\n",
            "epoch = 21\ttrain_acc=0.96597\ttest_acc=0.79320\ttrain_loss=0.18044\ttest_loss=0.46087\n",
            "epoch = 22\ttrain_acc=0.96786\ttest_acc=0.79320\ttrain_loss=0.16498\ttest_loss=0.47017\n",
            "epoch = 23\ttrain_acc=0.97921\ttest_acc=0.79320\ttrain_loss=0.15421\ttest_loss=0.45717\n",
            "epoch = 24\ttrain_acc=0.99055\ttest_acc=0.80170\ttrain_loss=0.13838\ttest_loss=0.46064\n",
            "epoch = 25\ttrain_acc=0.98677\ttest_acc=0.83286\ttrain_loss=0.12866\ttest_loss=0.44524\n",
            "epoch = 26\ttrain_acc=0.99055\ttest_acc=0.79887\ttrain_loss=0.11820\ttest_loss=0.46843\n",
            "epoch = 27\ttrain_acc=0.99244\ttest_acc=0.77337\ttrain_loss=0.11239\ttest_loss=0.48471\n",
            "epoch = 28\ttrain_acc=0.99622\ttest_acc=0.79603\ttrain_loss=0.10033\ttest_loss=0.46397\n",
            "epoch = 29\ttrain_acc=0.99622\ttest_acc=0.81303\ttrain_loss=0.09045\ttest_loss=0.44550\n",
            "epoch = 30\ttrain_acc=0.99433\ttest_acc=0.79603\ttrain_loss=0.08614\ttest_loss=0.49389\n",
            "epoch = 31\ttrain_acc=1.00000\ttest_acc=0.77337\ttrain_loss=0.07609\ttest_loss=0.50280\n",
            "epoch = 32\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.07110\ttest_loss=0.47829\n",
            "epoch = 33\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.06514\ttest_loss=0.49028\n",
            "epoch = 34\ttrain_acc=1.00000\ttest_acc=0.81586\ttrain_loss=0.06231\ttest_loss=0.43858\n",
            "epoch = 35\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.05668\ttest_loss=0.46114\n",
            "epoch = 36\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.05303\ttest_loss=0.50351\n",
            "epoch = 37\ttrain_acc=1.00000\ttest_acc=0.79037\ttrain_loss=0.04975\ttest_loss=0.52841\n",
            "epoch = 38\ttrain_acc=1.00000\ttest_acc=0.77904\ttrain_loss=0.04782\ttest_loss=0.53135\n",
            "epoch = 39\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.04560\ttest_loss=0.48594\n",
            "epoch = 40\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.04155\ttest_loss=0.47314\n",
            "epoch = 41\ttrain_acc=1.00000\ttest_acc=0.78754\ttrain_loss=0.03971\ttest_loss=0.51459\n",
            "epoch = 42\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.03820\ttest_loss=0.48397\n",
            "epoch = 43\ttrain_acc=1.00000\ttest_acc=0.77904\ttrain_loss=0.03468\ttest_loss=0.53154\n",
            "epoch = 44\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.03361\ttest_loss=0.50026\n",
            "epoch = 45\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.03217\ttest_loss=0.50132\n",
            "epoch = 46\ttrain_acc=1.00000\ttest_acc=0.77054\ttrain_loss=0.03038\ttest_loss=0.59049\n",
            "epoch = 47\ttrain_acc=1.00000\ttest_acc=0.80170\ttrain_loss=0.03026\ttest_loss=0.48170\n",
            "epoch = 48\ttrain_acc=1.00000\ttest_acc=0.82153\ttrain_loss=0.02817\ttest_loss=0.44801\n",
            "epoch = 49\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.02793\ttest_loss=0.49406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MoreCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "M6H_ib65yCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MoreCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBZC4GHeLUHz",
        "outputId": "4cb3b9e9-935f-47da-e0d0-d87df22ab1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MoreCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fh2DuxL8e7n",
        "outputId": "3f6296b1-1e39-4491-b330-d21c3136e2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.35404\ttest_loss=0.33095\n",
            "epoch = 1\ttrain_loss=0.33558\ttest_loss=0.32332\n",
            "epoch = 2\ttrain_loss=0.32925\ttest_loss=0.32346\n",
            "epoch = 3\ttrain_loss=0.31973\ttest_loss=0.31417\n",
            "epoch = 4\ttrain_loss=0.30916\ttest_loss=0.32241\n",
            "epoch = 5\ttrain_loss=0.30079\ttest_loss=0.30237\n",
            "epoch = 6\ttrain_loss=0.28817\ttest_loss=0.29379\n",
            "epoch = 7\ttrain_loss=0.27623\ttest_loss=0.28432\n",
            "epoch = 8\ttrain_loss=0.25552\ttest_loss=0.27249\n",
            "epoch = 9\ttrain_loss=0.23447\ttest_loss=0.29422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerMultipleClasses:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "            labels = labels.type(torch.float32)\n",
        "\n",
        "            loss = loss_fn(input=outputs, target=labels)\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for b, l in enumerate(labels):\n",
        "                o = torch.round(torch.sigmoid(outputs[b]))\n",
        "                if torch.equal(o, l):\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "        return correct_predictions / total_predictions, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                outputs = self.model(inputs)\n",
        "                labels = labels.type(torch.float32)\n",
        "                loss = loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                for b, l in enumerate(labels):\n",
        "                    o = torch.round(torch.sigmoid(outputs[b]))\n",
        "                    if torch.equal(o, l):\n",
        "                        correct_predictions += 1\n",
        "                    total_predictions += 1\n",
        "        return correct_predictions / total_predictions, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_acc, train_loss = self._train_one_epoch(train_iter)\n",
        "            self.model.eval()\n",
        "            test_acc, test_loss = self._test_one_epoch(test_iter)\n",
        "            print(f'{epoch = }\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{train_loss=:.5f}\\t{test_loss=:.5f}')"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, num_classes: int, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=64, bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.LazyLinear(out_features=num_classes, bias=use_bias)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.6)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "49c63056-2e4e-4c70-af78-fcd942c6e632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0, 16,  ..., 20, 20, 20],\n",
            "        [10,  5,  5,  ..., 20, 20, 20],\n",
            "        [10,  8,  5,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10,  9, 15,  ..., 20, 20, 20],\n",
            "        [10, 16, 15,  ..., 20, 20, 20],\n",
            "        [10, 16, 12,  ..., 20, 20, 20]]), tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "fa14ab0b-f371-4309-be9f-1c79fde55d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 1454\n",
            "n = 5330\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(num_classes=5, context_size=num_steps, conv_channels=256)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "59e37738-d2b1-420e-cef3-685f2d004145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=64, bias=False)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=5, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "4cf6a38a-51f6-44b0-9d02-9b40b806ff69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_acc=0.76290\ttest_acc=0.78224\ttrain_loss=0.23516\ttest_loss=0.20711\n",
            "epoch = 1\ttrain_acc=0.78796\ttest_acc=0.78224\ttrain_loss=0.20366\ttest_loss=0.20688\n",
            "epoch = 2\ttrain_acc=0.78796\ttest_acc=0.78224\ttrain_loss=0.19897\ttest_loss=0.20441\n",
            "epoch = 3\ttrain_acc=0.78796\ttest_acc=0.78224\ttrain_loss=0.19990\ttest_loss=0.20521\n",
            "epoch = 4\ttrain_acc=0.78796\ttest_acc=0.78224\ttrain_loss=0.19875\ttest_loss=0.20420\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-1341ef3fd603>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerMultipleClasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-92977f18831e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_iter, test_iter)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-92977f18831e>\u001b[0m in \u001b[0;36m_train_one_epoch\u001b[0;34m(self, train_iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mresult_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}