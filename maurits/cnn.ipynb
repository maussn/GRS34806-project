{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV1GfzY+VOI4cyHVINM2cB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrywNfRlazm-",
        "outputId": "d5c29932-3841-463c-a2fd-1667b2d5fb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'grs34806-deep-learning-project-data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (21/21), 8.74 MiB | 5.77 MiB/s, done.\n",
            "Cloning into 'GRS34806-project'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 58 (delta 21), reused 31 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (58/58), 94.53 KiB | 4.73 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "SEpH6j4dbJuO"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    random.shuffle(datalist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i]\n",
        "\n",
        "\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 500\n",
        "\n",
        "# Example for one of the simulated datasets\n",
        "datalist, labellist = read(\"len200_500_n5000nr4.seq\", \"len200_500_n5000nr4.pos\")\n",
        "\n",
        "# Remove negatives\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.5)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(next(iter(train_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "19e1f02b-33f2-48e7-82e2-1fbc521a42a7"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10, 18, 17,  ..., 20, 20, 20],\n",
            "        [10, 17, 17,  ..., 20, 20, 20],\n",
            "        [10,  3, 10,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10, 14,  1,  ..., 20, 20, 20],\n",
            "        [10, 19, 18,  ..., 20, 20, 20],\n",
            "        [10,  2,  9,  ..., 20, 20, 20]]), tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "26FSv9_pGhWY",
        "outputId": "f8e6714b-b0ef-4249-81db-b6073048199e"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Count'>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0\n",
        "n = 0\n",
        "for l in labellist:\n",
        "    if l:\n",
        "        p += 1\n",
        "    else:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hMgfQJIFjb5",
        "outputId": "78a93e6c-dbc9-42ed-830d-93106593a6ba"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 2490\n",
            "n = 1255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(datalist[5:10])\n",
        "print(labellist[5:10])\n",
        "\n",
        "split_labelled(datalist[5:10], labellist[5:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWMqDhH7KG3o",
        "outputId": "cd033d76-b454-4c00-b740-70823333ac16"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MPKKLLLLPPPSASSAFRVPRARPVPPPAMNAARTGYRVFSANSTAACTELAKRITERLGAELGKSVVYQETNGETRVEIKESVRGQDIFIIQTIPRDVNTAVMELLIMAYALKTACARNIIGVIPYFPYSKQSKMRKRGSIVCKLLASMLAKAGLTHIITMDLHQKEIQGFFSFPVDNLRASPFLLQYIQEEIPNYRNAVIVAKSPDAAKRAQSYAERLRLGLAVIHGEAQCTELDMDDGRHSPPMVKNATVHPGLELPLMMAKEKPPITVVGDVGGRIAIIVDDIIDDVESFVAAAEILKERGAYKIYVMATHGILSAEAPRLIEESSVDEVVVTNTVPHEVQKLQCPKIKTVDISLILSEAIRRIHNGESMAYLFRNITVDD', 'MPRGSRSRTSRMAPPASRAPQMRAAPRPAPVAQPPAAAPPSAVGSSAAAPRQPGLMAQMATTAAGVAVGSAVGHTLGHAITGGFSGGSNAEPARPDITYQEPQGTQPAQQQQPCLYEIKQFLECAQNQGDIKLCEGFNEVLKQCRLANGLA', 'MWFMYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPGDDVVSNYFTKGKRGKRLGILVVFSFIKEAILPSRQKIY', 'MEDSMDMDMSPLRPQNYLFGCELKADKDYHFKVDNDENEHQLSLRTVSLGAGAKDELHIVEAEAMNYEGSPIKVTLATLKMSVQPTVSLGGFEITPPVVLRLKCGSGPVHISGQHLVAVEEDAESEDEEEEDVKLLSISGKRSAPGGGSKVPQKKVKLAADEDDDDDDEEDDDEDDDDDDFDDEEAEEKAPVKKSIRDTPAKNAQKSNQNGKDSKPSSTPRSKGQESFKKQEKTPKTPKGPSSVEDIKAKMQASIEKGGSLPKVEAKFINYVKNCFRMTDQEAIQDLWQWRKSL', 'MGDEKDSWKVKTLDEILQEKKRRKEQEEKAEIKRLKNSDDRDSKRDSLEEGELRDHCMEITIRNSPYRREDSMEDRGEEDDSLAIKPPQQMSRKEKVHHRKDEKRKEKWKHARVKEREHERRKRHREEQDKARREWERQKRREMAREHSRRERDRLEQLERKRERERKMREQQKEQREQKERERRAEERRKEREARREVSAHHRTMREDYSDKVKASHWSRSPPRPPRERFELGDGRKPGEARPAPAQKPAQLKEEKMEERDLLSDLQDISDSERKTSSAESSSAESGSGSEEEEEEEEEEEEEGSTSEESEEEEEEEEEEEEETGSNSEEASEQSAEEVSEEEMSEDEERENENHLLVVPESRFDRDSGESEEAEEEVGEGTPQSSALTEGDYVPDSPALLPIELKQELPKYLPALQGCRSVEEFQCLNRIEEGTYGVVYRAKDKKTDEIVALKRLKMEKEKEGFPITSLREINTILKAQHPNIVTVREIVVGSNMDKIYIVMNYVEHDLKSLMETMKQPFLPGEVKTLMIQLLRGVKHLHDNWILHRDLKTSNLLLSHAGILKVGDFGLAREYGSPLKAYTPVVVTQWYRAPELLLGAKEYSTAVDMWSVGCIFGELLTQKPLFPGNSEIDQINKVFKELGTPSEKIWPGYSELPVVKKMTFSEHPYNNLRKRFGALLSDQGFDLMNKFLTYFPGRRISAEDGLKHEYFRETPLPIDPSMFPTWPAKSEQQRVKRGTSPRPPEGGLGYSQLGDDDLKETGFHLTTTNQGASAAGPGFSLKF']\n",
            "[False, True, False, False, False]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['MPRGSRSRTSRMAPPASRAPQMRAAPRPAPVAQPPAAAPPSAVGSSAAAPRQPGLMAQMATTAAGVAVGSAVGHTLGHAITGGFSGGSNAEPARPDITYQEPQGTQPAQQQQPCLYEIKQFLECAQNQGDIKLCEGFNEVLKQCRLANGLA'],\n",
              " ['MPKKLLLLPPPSASSAFRVPRARPVPPPAMNAARTGYRVFSANSTAACTELAKRITERLGAELGKSVVYQETNGETRVEIKESVRGQDIFIIQTIPRDVNTAVMELLIMAYALKTACARNIIGVIPYFPYSKQSKMRKRGSIVCKLLASMLAKAGLTHIITMDLHQKEIQGFFSFPVDNLRASPFLLQYIQEEIPNYRNAVIVAKSPDAAKRAQSYAERLRLGLAVIHGEAQCTELDMDDGRHSPPMVKNATVHPGLELPLMMAKEKPPITVVGDVGGRIAIIVDDIIDDVESFVAAAEILKERGAYKIYVMATHGILSAEAPRLIEESSVDEVVVTNTVPHEVQKLQCPKIKTVDISLILSEAIRRIHNGESMAYLFRNITVDD',\n",
              "  'MWFMYLLSWLSLFIQVAFITLAVAAGLYYLAELIEEYTVATSRIIKYMIWFSTAVLIGLYVFERFPTSMIGVGLFTNLVYFGLLQTFPFIMLTSPNFILSCGLVVVNHYLAFQFFAEEYYPFSEVLAYFTFCLWIIPFAFFVSLSAGENVLPSTMQPGDDVVSNYFTKGKRGKRLGILVVFSFIKEAILPSRQKIY',\n",
              "  'MEDSMDMDMSPLRPQNYLFGCELKADKDYHFKVDNDENEHQLSLRTVSLGAGAKDELHIVEAEAMNYEGSPIKVTLATLKMSVQPTVSLGGFEITPPVVLRLKCGSGPVHISGQHLVAVEEDAESEDEEEEDVKLLSISGKRSAPGGGSKVPQKKVKLAADEDDDDDDEEDDDEDDDDDDFDDEEAEEKAPVKKSIRDTPAKNAQKSNQNGKDSKPSSTPRSKGQESFKKQEKTPKTPKGPSSVEDIKAKMQASIEKGGSLPKVEAKFINYVKNCFRMTDQEAIQDLWQWRKSL',\n",
              "  'MGDEKDSWKVKTLDEILQEKKRRKEQEEKAEIKRLKNSDDRDSKRDSLEEGELRDHCMEITIRNSPYRREDSMEDRGEEDDSLAIKPPQQMSRKEKVHHRKDEKRKEKWKHARVKEREHERRKRHREEQDKARREWERQKRREMAREHSRRERDRLEQLERKRERERKMREQQKEQREQKERERRAEERRKEREARREVSAHHRTMREDYSDKVKASHWSRSPPRPPRERFELGDGRKPGEARPAPAQKPAQLKEEKMEERDLLSDLQDISDSERKTSSAESSSAESGSGSEEEEEEEEEEEEEGSTSEESEEEEEEEEEEEEETGSNSEEASEQSAEEVSEEEMSEDEERENENHLLVVPESRFDRDSGESEEAEEEVGEGTPQSSALTEGDYVPDSPALLPIELKQELPKYLPALQGCRSVEEFQCLNRIEEGTYGVVYRAKDKKTDEIVALKRLKMEKEKEGFPITSLREINTILKAQHPNIVTVREIVVGSNMDKIYIVMNYVEHDLKSLMETMKQPFLPGEVKTLMIQLLRGVKHLHDNWILHRDLKTSNLLLSHAGILKVGDFGLAREYGSPLKAYTPVVVTQWYRAPELLLGAKEYSTAVDMWSVGCIFGELLTQKPLFPGNSEIDQINKVFKELGTPSEKIWPGYSELPVVKKMTFSEHPYNNLRKRFGALLSDQGFDLMNKFLTYFPGRRISAEDGLKHEYFRETPLPIDPSMFPTWPAKSEQQRVKRGTSPRPPEGGLGYSQLGDDDLKETGFHLTTTNQGASAAGPGFSLKF'])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, epoch_index, train_iter):\n",
        "        result_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            result_loss += loss.item()\n",
        "        return result_loss / (i + 1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_loss = self._train_one_epoch(epoch, train_iter)\n",
        "            self.model.eval()\n",
        "            result_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, (test_inputs, test_labels) in enumerate(test_iter):\n",
        "                    test_outputs = self.model(test_inputs)\n",
        "                    loss = self.loss_fn(test_outputs, test_labels)\n",
        "                    # print(f'{loss = }\\t{test_outputs = }\\t{test_labels = }')\n",
        "                    result_loss += loss.item()\n",
        "            test_loss = result_loss / (i + 1)\n",
        "            print(f'{epoch = }\\t{train_loss=:.5f}\\t{test_loss=:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3Btdmdhj36zM"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MinimalGOClassifierCNN(nn.Module):\n",
        "    def __init__(self, input_length: int, vocab_size : int=21,  num_filters: int=32, kernel_size: int=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv_layer(x.transpose(1,2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        output = F.softmax(x, 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6Agj87Dpbf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.fc(x)\n",
        ""
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "M6H_ib65yCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBZC4GHeLUHz",
        "outputId": "f65af717-6580-4cb9-c0bf-900599c91cf3"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BerryCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fh2DuxL8e7n",
        "outputId": "a85460fb-7807-46f9-c12f-3d0e2eee21f3"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.66353\ttest_loss=0.62359\n",
            "epoch = 1\ttrain_loss=0.61548\ttest_loss=0.58779\n",
            "epoch = 2\ttrain_loss=0.44076\ttest_loss=0.26884\n",
            "epoch = 3\ttrain_loss=0.15181\ttest_loss=0.08044\n",
            "epoch = 4\ttrain_loss=0.05801\ttest_loss=0.03982\n",
            "epoch = 5\ttrain_loss=0.03467\ttest_loss=0.03949\n",
            "epoch = 6\ttrain_loss=0.02399\ttest_loss=0.02052\n",
            "epoch = 7\ttrain_loss=0.01860\ttest_loss=0.01459\n",
            "epoch = 8\ttrain_loss=0.01421\ttest_loss=0.01229\n",
            "epoch = 9\ttrain_loss=0.01173\ttest_loss=0.01094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G57lnNJ2xKmf",
        "outputId": "537f85a2-3a64-4041-e976-ab2179a4e098"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        }
      ]
    }
  ]
}