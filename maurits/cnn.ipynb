{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QrywNfRlazm-"
      },
      "outputs": [],
      "source": [
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "SEpH6j4dbJuO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    random.shuffle(datalist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal(reduced_datalist: list, compared_datalist: list):\n",
        "    random.shuffle(reduced_datalist)\n",
        "    random.shuffle(compared_datalist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 500\n",
        "\n",
        "# Example for one of the simulated datasets\n",
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0055085.annotprot\")\n",
        "# datalist, labellist = read(\"len200_500_n5000nr4.seq\", \"len200_500_n5000nr4.pos\")\n",
        "\n",
        "# Remove negatives\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.1)\n",
        "# neg_datalist = remove_sequences_equal(neg_datalist, pos_datalist)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.6)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(next(iter(train_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "681ac541-2e74-4b0e-8a5a-95dd6af7ba90"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0,  0,  ..., 20, 20, 20],\n",
            "        [10, 15, 10,  ..., 14, 12,  0],\n",
            "        [10, 11,  5,  ..., 19, 16, 14],\n",
            "        ...,\n",
            "        [10, 17,  5,  ..., 20, 20, 20],\n",
            "        [10,  4,  3,  ..., 20, 20, 20],\n",
            "        [10,  3, 14,  ...,  3, 14,  8]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for l in labellist:\n",
        "    if l:\n",
        "        p += 1\n",
        "    else:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "26FSv9_pGhWY",
        "outputId": "34c78d53-c957-4f9f-8cff-a9c6bcc73ffd"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 226\n",
            "n = 656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, epoch_index, train_iter):\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        result_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            result_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                if o == l:\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "        return correct_predictions / total_predictions, result_loss / (i + 1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_acc, train_loss = self._train_one_epoch(epoch, train_iter)\n",
        "            self.model.eval()\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "            result_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(test_iter):\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.loss_fn(outputs, labels)\n",
        "                    result_loss += loss.item()\n",
        "                    # print(f'{loss = }\\t{test_outputs = }\\t{test_labels = }')\n",
        "                    # print(f'{outputs = }')\n",
        "                    # print(f'{labels = }')\n",
        "                    for j, l in enumerate(labels):\n",
        "                        o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                        if o == l:\n",
        "                            correct_predictions += 1\n",
        "                        total_predictions += 1\n",
        "            test_acc = correct_predictions / total_predictions\n",
        "            test_loss = result_loss / (i + 1)\n",
        "            print(f'{epoch = }\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{train_loss=:.5f}\\t{test_loss=:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3Btdmdhj36zM"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MinimalGOClassifierCNN(nn.Module):\n",
        "    def __init__(self, input_length: int, vocab_size : int=21,  num_filters: int=32, kernel_size: int=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv_layer(x.transpose(1,2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        output = F.softmax(x, 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6Agj87Dpbf-Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf9552d-d6cc-4ea3-e6e0-60c66118a4fd",
        "id": "-kFRoPlYpeKe"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BerryCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "AMz0guzKptRZ",
        "outputId": "129befb4-d659-4e51-ed73-15ff9a64f442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_acc=0.74102\ttest_acc=0.71671\ttrain_loss=0.59123\ttest_loss=0.60524\n",
            "epoch = 1\ttrain_acc=0.76181\ttest_acc=0.71955\ttrain_loss=0.54158\ttest_loss=0.63385\n",
            "epoch = 2\ttrain_acc=0.76371\ttest_acc=0.71671\ttrain_loss=0.55572\ttest_loss=0.58998\n",
            "epoch = 3\ttrain_acc=0.76181\ttest_acc=0.71671\ttrain_loss=0.51166\ttest_loss=0.62685\n",
            "epoch = 4\ttrain_acc=0.76181\ttest_acc=0.71671\ttrain_loss=0.50419\ttest_loss=0.55958\n",
            "epoch = 5\ttrain_acc=0.76560\ttest_acc=0.71671\ttrain_loss=0.47833\ttest_loss=0.54834\n",
            "epoch = 6\ttrain_acc=0.76938\ttest_acc=0.71671\ttrain_loss=0.46290\ttest_loss=0.53659\n",
            "epoch = 7\ttrain_acc=0.79206\ttest_acc=0.71671\ttrain_loss=0.45262\ttest_loss=0.58852\n",
            "epoch = 8\ttrain_acc=0.81096\ttest_acc=0.75071\ttrain_loss=0.43852\ttest_loss=0.51546\n",
            "epoch = 9\ttrain_acc=0.83932\ttest_acc=0.71671\ttrain_loss=0.40894\ttest_loss=0.55372\n",
            "epoch = 10\ttrain_acc=0.83176\ttest_acc=0.75921\ttrain_loss=0.39325\ttest_loss=0.50513\n",
            "epoch = 11\ttrain_acc=0.86200\ttest_acc=0.72238\ttrain_loss=0.37021\ttest_loss=0.52007\n",
            "epoch = 12\ttrain_acc=0.85444\ttest_acc=0.79320\ttrain_loss=0.35412\ttest_loss=0.50812\n",
            "epoch = 13\ttrain_acc=0.88091\ttest_acc=0.79320\ttrain_loss=0.33304\ttest_loss=0.48538\n",
            "epoch = 14\ttrain_acc=0.89036\ttest_acc=0.74221\ttrain_loss=0.30866\ttest_loss=0.50351\n",
            "epoch = 15\ttrain_acc=0.90548\ttest_acc=0.80170\ttrain_loss=0.29183\ttest_loss=0.48260\n",
            "epoch = 16\ttrain_acc=0.91304\ttest_acc=0.79603\ttrain_loss=0.27021\ttest_loss=0.47485\n",
            "epoch = 17\ttrain_acc=0.93384\ttest_acc=0.78754\ttrain_loss=0.25483\ttest_loss=0.46939\n",
            "epoch = 18\ttrain_acc=0.93762\ttest_acc=0.75071\ttrain_loss=0.23448\ttest_loss=0.50017\n",
            "epoch = 19\ttrain_acc=0.94707\ttest_acc=0.77904\ttrain_loss=0.21742\ttest_loss=0.47437\n",
            "epoch = 20\ttrain_acc=0.96219\ttest_acc=0.79887\ttrain_loss=0.19573\ttest_loss=0.46194\n",
            "epoch = 21\ttrain_acc=0.96597\ttest_acc=0.79320\ttrain_loss=0.18044\ttest_loss=0.46087\n",
            "epoch = 22\ttrain_acc=0.96786\ttest_acc=0.79320\ttrain_loss=0.16498\ttest_loss=0.47017\n",
            "epoch = 23\ttrain_acc=0.97921\ttest_acc=0.79320\ttrain_loss=0.15421\ttest_loss=0.45717\n",
            "epoch = 24\ttrain_acc=0.99055\ttest_acc=0.80170\ttrain_loss=0.13838\ttest_loss=0.46064\n",
            "epoch = 25\ttrain_acc=0.98677\ttest_acc=0.83286\ttrain_loss=0.12866\ttest_loss=0.44524\n",
            "epoch = 26\ttrain_acc=0.99055\ttest_acc=0.79887\ttrain_loss=0.11820\ttest_loss=0.46843\n",
            "epoch = 27\ttrain_acc=0.99244\ttest_acc=0.77337\ttrain_loss=0.11239\ttest_loss=0.48471\n",
            "epoch = 28\ttrain_acc=0.99622\ttest_acc=0.79603\ttrain_loss=0.10033\ttest_loss=0.46397\n",
            "epoch = 29\ttrain_acc=0.99622\ttest_acc=0.81303\ttrain_loss=0.09045\ttest_loss=0.44550\n",
            "epoch = 30\ttrain_acc=0.99433\ttest_acc=0.79603\ttrain_loss=0.08614\ttest_loss=0.49389\n",
            "epoch = 31\ttrain_acc=1.00000\ttest_acc=0.77337\ttrain_loss=0.07609\ttest_loss=0.50280\n",
            "epoch = 32\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.07110\ttest_loss=0.47829\n",
            "epoch = 33\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.06514\ttest_loss=0.49028\n",
            "epoch = 34\ttrain_acc=1.00000\ttest_acc=0.81586\ttrain_loss=0.06231\ttest_loss=0.43858\n",
            "epoch = 35\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.05668\ttest_loss=0.46114\n",
            "epoch = 36\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.05303\ttest_loss=0.50351\n",
            "epoch = 37\ttrain_acc=1.00000\ttest_acc=0.79037\ttrain_loss=0.04975\ttest_loss=0.52841\n",
            "epoch = 38\ttrain_acc=1.00000\ttest_acc=0.77904\ttrain_loss=0.04782\ttest_loss=0.53135\n",
            "epoch = 39\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.04560\ttest_loss=0.48594\n",
            "epoch = 40\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.04155\ttest_loss=0.47314\n",
            "epoch = 41\ttrain_acc=1.00000\ttest_acc=0.78754\ttrain_loss=0.03971\ttest_loss=0.51459\n",
            "epoch = 42\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.03820\ttest_loss=0.48397\n",
            "epoch = 43\ttrain_acc=1.00000\ttest_acc=0.77904\ttrain_loss=0.03468\ttest_loss=0.53154\n",
            "epoch = 44\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.03361\ttest_loss=0.50026\n",
            "epoch = 45\ttrain_acc=1.00000\ttest_acc=0.79320\ttrain_loss=0.03217\ttest_loss=0.50132\n",
            "epoch = 46\ttrain_acc=1.00000\ttest_acc=0.77054\ttrain_loss=0.03038\ttest_loss=0.59049\n",
            "epoch = 47\ttrain_acc=1.00000\ttest_acc=0.80170\ttrain_loss=0.03026\ttest_loss=0.48170\n",
            "epoch = 48\ttrain_acc=1.00000\ttest_acc=0.82153\ttrain_loss=0.02817\ttest_loss=0.44801\n",
            "epoch = 49\ttrain_acc=1.00000\ttest_acc=0.79887\ttrain_loss=0.02793\ttest_loss=0.49406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MoreCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "M6H_ib65yCPk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MoreCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBZC4GHeLUHz",
        "outputId": "4cb3b9e9-935f-47da-e0d0-d87df22ab1e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MoreCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fh2DuxL8e7n",
        "outputId": "3f6296b1-1e39-4491-b330-d21c3136e2ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.35404\ttest_loss=0.33095\n",
            "epoch = 1\ttrain_loss=0.33558\ttest_loss=0.32332\n",
            "epoch = 2\ttrain_loss=0.32925\ttest_loss=0.32346\n",
            "epoch = 3\ttrain_loss=0.31973\ttest_loss=0.31417\n",
            "epoch = 4\ttrain_loss=0.30916\ttest_loss=0.32241\n",
            "epoch = 5\ttrain_loss=0.30079\ttest_loss=0.30237\n",
            "epoch = 6\ttrain_loss=0.28817\ttest_loss=0.29379\n",
            "epoch = 7\ttrain_loss=0.27623\ttest_loss=0.28432\n",
            "epoch = 8\ttrain_loss=0.25552\ttest_loss=0.27249\n",
            "epoch = 9\ttrain_loss=0.23447\ttest_loss=0.29422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerMultipleClasses:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, epoch_index, train_iter):\n",
        "        result_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            loss = 0\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "            print(outputs)\n",
        "            print(labels)\n",
        "            print(labels.transpose(0,1))\n",
        "\n",
        "            for j, output in enumerate(outputs):\n",
        "                loss += self.loss_fn(output, labels.transpose(0,1)[j])\n",
        "            print(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            result_loss += loss.item()\n",
        "        return result_loss / (i + 1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_loss = self._train_one_epoch(epoch, train_iter)\n",
        "            self.model.eval()\n",
        "            result_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, (test_inputs, test_labels) in enumerate(test_iter):\n",
        "                    loss = 0\n",
        "                    test_outputs = self.model(test_inputs)\n",
        "                    for j, test_output in enumerate(test_outputs):\n",
        "                        loss += self.loss_fn(test_output, test_labels.transpose(0,1)[j])\n",
        "                    # print(f'{loss = }\\t{test_outputs = }\\t{test_labels = }')\n",
        "                    result_loss += loss.item()\n",
        "            test_loss = result_loss / (i + 1)\n",
        "            print(f'{epoch = }\\t{train_loss=:.5f}\\t{test_loss=:.5f}')"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.class1 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "        self.class2 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "        self.class3 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "        self.class4 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "        self.class5 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        output1 = self.class1(x)\n",
        "        output2 = self.class2(x)\n",
        "        output3 = self.class3(x)\n",
        "        output4 = self.class4(x)\n",
        "        output5 = self.class5(x)\n",
        "        return (output1, output2, output3, output4, output5)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.8)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "7951519f-a02f-4025-def3-b8f4890192f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  5,  0,  ..., 20, 20, 20],\n",
            "        [10,  0,  2,  ..., 20, 20, 20],\n",
            "        [10,  0, 15,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10,  0,  0,  ..., 20, 20, 20],\n",
            "        [10,  8,  9,  ..., 20, 20, 20],\n",
            "        [10, 15, 10,  ..., 20, 20, 20]]), tensor([[0, 1, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "e1c6ff90-609f-463f-fa90-87981bec4f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 1454\n",
            "n = 5330\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "9e5301c4-c3ed-4630-8362-76515fc6d037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (class1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              "  (class2): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              "  (class3): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              "  (class4): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              "  (class5): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "ff8aa710-27c5-43cb-8364-7384c416a4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.6932, -0.5751],\n",
            "        [-0.7959, -0.4558],\n",
            "        [-0.8411, -0.5704],\n",
            "        [-0.8404, -0.6092],\n",
            "        [-0.7687, -0.5759],\n",
            "        [-0.8019, -0.5907],\n",
            "        [-0.7817, -0.2925],\n",
            "        [-0.8002, -0.5861],\n",
            "        [-0.7678, -0.4509],\n",
            "        [-0.8792, -0.5567]], grad_fn=<MmBackward0>), tensor([[0.1818, 0.2575],\n",
            "        [0.0502, 0.2654],\n",
            "        [0.1853, 0.0960],\n",
            "        [0.2021, 0.1617],\n",
            "        [0.0339, 0.1970],\n",
            "        [0.2182, 0.0090],\n",
            "        [0.1453, 0.0147],\n",
            "        [0.0567, 0.1309],\n",
            "        [0.1952, 0.0795],\n",
            "        [0.1513, 0.2137]], grad_fn=<MmBackward0>), tensor([[-0.6321, -0.3476],\n",
            "        [-1.0862, -0.3964],\n",
            "        [-1.0918, -0.5397],\n",
            "        [-1.1602, -0.3414],\n",
            "        [-1.0010, -0.4421],\n",
            "        [-0.9831, -0.3296],\n",
            "        [-1.0167, -0.3429],\n",
            "        [-1.0230, -0.3638],\n",
            "        [-0.9404, -0.4119],\n",
            "        [-1.0165, -0.3270]], grad_fn=<MmBackward0>), tensor([[0.4835, 0.7603],\n",
            "        [0.7434, 0.7367],\n",
            "        [0.8498, 0.8377],\n",
            "        [0.6856, 0.9179],\n",
            "        [0.6265, 0.7075],\n",
            "        [0.5512, 0.6980],\n",
            "        [0.4000, 0.6347],\n",
            "        [0.6395, 0.7621],\n",
            "        [0.5010, 0.7121],\n",
            "        [0.6079, 0.8739]], grad_fn=<MmBackward0>), tensor([[-0.3059,  0.9589],\n",
            "        [-0.3036,  1.1690],\n",
            "        [-0.4398,  1.1934],\n",
            "        [-0.4243,  1.2294],\n",
            "        [-0.5004,  1.2486],\n",
            "        [-0.2493,  1.2363],\n",
            "        [-0.4798,  1.0603],\n",
            "        [-0.4226,  1.2037],\n",
            "        [-0.2424,  1.0337],\n",
            "        [-0.4237,  1.3138]], grad_fn=<MmBackward0>))\n",
            "tensor([[1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(4.9093, grad_fn=<AddBackward0>)\n",
            "(tensor([[-0.8690, -0.5519],\n",
            "        [-0.7031, -0.5191],\n",
            "        [-0.7810, -0.6546],\n",
            "        [-0.7391, -0.6416],\n",
            "        [-0.7088, -0.5741],\n",
            "        [-0.7224, -0.4912],\n",
            "        [-0.6672, -0.6016],\n",
            "        [-0.7585, -0.5788],\n",
            "        [-0.8136, -0.6141],\n",
            "        [-0.7495, -0.6009]], grad_fn=<MmBackward0>), tensor([[ 0.2061, -0.0621],\n",
            "        [ 0.4192,  0.0780],\n",
            "        [ 0.0900,  0.0943],\n",
            "        [ 0.1579,  0.1157],\n",
            "        [ 0.2322, -0.0036],\n",
            "        [ 0.2075,  0.0159],\n",
            "        [ 0.0996,  0.1082],\n",
            "        [ 0.2524,  0.1674],\n",
            "        [ 0.1020,  0.1246],\n",
            "        [ 0.2622,  0.1022]], grad_fn=<MmBackward0>), tensor([[-0.9837, -0.4330],\n",
            "        [-1.0228, -0.6464],\n",
            "        [-0.9366, -0.5037],\n",
            "        [-0.9124, -0.5850],\n",
            "        [-0.9657, -0.4893],\n",
            "        [-0.8461, -0.2621],\n",
            "        [-0.8963, -0.5579],\n",
            "        [-1.0384, -0.5795],\n",
            "        [-1.1340, -0.3984],\n",
            "        [-1.1728, -0.4254]], grad_fn=<MmBackward0>), tensor([[0.7374, 0.5767],\n",
            "        [0.7709, 0.7056],\n",
            "        [0.6171, 0.5519],\n",
            "        [0.7707, 0.6707],\n",
            "        [0.7435, 0.7082],\n",
            "        [0.5922, 0.6361],\n",
            "        [0.8092, 0.5777],\n",
            "        [0.7630, 0.6298],\n",
            "        [0.7394, 0.7075],\n",
            "        [0.7198, 0.7754]], grad_fn=<MmBackward0>), tensor([[-0.2160,  1.0416],\n",
            "        [-0.3013,  1.1798],\n",
            "        [-0.3034,  1.0100],\n",
            "        [-0.2198,  1.2064],\n",
            "        [-0.3228,  1.2095],\n",
            "        [-0.3189,  0.8085],\n",
            "        [-0.3194,  1.2181],\n",
            "        [-0.3305,  1.2267],\n",
            "        [-0.2212,  1.1846],\n",
            "        [-0.3174,  1.1762]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(4.6249, grad_fn=<AddBackward0>)\n",
            "(tensor([[-0.6351, -0.7452],\n",
            "        [-0.5466, -0.6689],\n",
            "        [-0.5486, -0.6418],\n",
            "        [-0.5107, -0.7136],\n",
            "        [-0.4040, -0.6720],\n",
            "        [-0.6412, -0.6272],\n",
            "        [-0.5828, -0.6111],\n",
            "        [-0.6024, -0.8199],\n",
            "        [-0.4553, -0.7711],\n",
            "        [-0.5465, -0.5831]], grad_fn=<MmBackward0>), tensor([[ 0.4483, -0.0255],\n",
            "        [ 0.4226, -0.1031],\n",
            "        [ 0.2555,  0.0319],\n",
            "        [ 0.3551,  0.0078],\n",
            "        [ 0.3903,  0.0488],\n",
            "        [ 0.2072, -0.0536],\n",
            "        [ 0.3132,  0.1508],\n",
            "        [ 0.3808, -0.0192],\n",
            "        [ 0.2940,  0.0982],\n",
            "        [ 0.3043, -0.1855]], grad_fn=<MmBackward0>), tensor([[-0.7469, -0.7108],\n",
            "        [-0.8709, -0.7263],\n",
            "        [-0.6648, -0.6040],\n",
            "        [-0.7801, -0.6190],\n",
            "        [-0.7397, -0.7342],\n",
            "        [-0.5577, -0.5700],\n",
            "        [-0.6907, -0.5911],\n",
            "        [-0.9382, -0.7257],\n",
            "        [-0.6494, -0.4928],\n",
            "        [-0.7458, -0.6780]], grad_fn=<MmBackward0>), tensor([[1.0498, 0.6275],\n",
            "        [1.0303, 0.5233],\n",
            "        [0.7894, 0.4721],\n",
            "        [0.9511, 0.3742],\n",
            "        [0.8781, 0.5257],\n",
            "        [0.8207, 0.5758],\n",
            "        [0.8286, 0.1918],\n",
            "        [0.9537, 0.3915],\n",
            "        [0.8072, 0.4728],\n",
            "        [0.8896, 0.4225]], grad_fn=<MmBackward0>), tensor([[-0.1772,  0.9815],\n",
            "        [ 0.0345,  0.9136],\n",
            "        [-0.0789,  0.8702],\n",
            "        [ 0.0533,  0.8583],\n",
            "        [ 0.0680,  0.9293],\n",
            "        [-0.1217,  0.8880],\n",
            "        [-0.1303,  0.6932],\n",
            "        [ 0.0248,  1.0486],\n",
            "        [-0.0813,  0.7865],\n",
            "        [ 0.0270,  0.9308]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor(3.6496, grad_fn=<AddBackward0>)\n",
            "(tensor([[-0.4016, -0.9765],\n",
            "        [-0.3494, -0.9926],\n",
            "        [-0.4259, -0.8463],\n",
            "        [-0.4273, -0.9060],\n",
            "        [-0.4301, -0.9422],\n",
            "        [-0.2924, -1.0244],\n",
            "        [-0.4321, -0.8396],\n",
            "        [-0.3541, -0.8471],\n",
            "        [-0.3743, -0.9828],\n",
            "        [-0.4622, -0.7584]], grad_fn=<MmBackward0>), tensor([[ 0.5212, -0.2383],\n",
            "        [ 0.4534, -0.1797],\n",
            "        [ 0.5076, -0.2081],\n",
            "        [ 0.5364, -0.2232],\n",
            "        [ 0.4806, -0.1372],\n",
            "        [ 0.5390, -0.1742],\n",
            "        [ 0.4301, -0.0601],\n",
            "        [ 0.3758, -0.0957],\n",
            "        [ 0.6380, -0.2864],\n",
            "        [ 0.6149, -0.2515]], grad_fn=<MmBackward0>), tensor([[-0.4969, -0.8789],\n",
            "        [-0.6043, -0.8613],\n",
            "        [-0.6044, -1.0876],\n",
            "        [-0.4886, -0.6570],\n",
            "        [-0.6143, -0.9877],\n",
            "        [-0.6345, -0.9408],\n",
            "        [-0.5579, -0.6898],\n",
            "        [-0.6222, -0.8723],\n",
            "        [-0.6611, -0.8478],\n",
            "        [-0.6174, -0.9279]], grad_fn=<MmBackward0>), tensor([[0.9023, 0.3654],\n",
            "        [1.2157, 0.2647],\n",
            "        [1.0858, 0.3294],\n",
            "        [0.9010, 0.3111],\n",
            "        [1.1571, 0.4385],\n",
            "        [1.1305, 0.3283],\n",
            "        [0.9146, 0.2869],\n",
            "        [0.9824, 0.2958],\n",
            "        [1.1674, 0.3840],\n",
            "        [1.0212, 0.3419]], grad_fn=<MmBackward0>), tensor([[0.1674, 0.5652],\n",
            "        [0.3838, 0.5443],\n",
            "        [0.2955, 0.6115],\n",
            "        [0.2074, 0.4876],\n",
            "        [0.3027, 0.7305],\n",
            "        [0.3870, 0.5892],\n",
            "        [0.1094, 0.5933],\n",
            "        [0.3742, 0.5182],\n",
            "        [0.3285, 0.6308],\n",
            "        [0.3891, 0.5766]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor(2.7564, grad_fn=<AddBackward0>)\n",
            "(tensor([[-0.1627, -1.0112],\n",
            "        [-0.1903, -1.1870],\n",
            "        [-0.2057, -1.0270],\n",
            "        [-0.2776, -1.0716],\n",
            "        [-0.2432, -1.1715],\n",
            "        [-0.0679, -1.3228],\n",
            "        [-0.0922, -1.0896],\n",
            "        [-0.2774, -1.1046],\n",
            "        [-0.1896, -1.0110],\n",
            "        [-0.0180, -0.9688]], grad_fn=<MmBackward0>), tensor([[ 0.7270, -0.3453],\n",
            "        [ 1.0266, -0.4260],\n",
            "        [ 0.8541, -0.4360],\n",
            "        [ 0.6751, -0.4455],\n",
            "        [ 0.8210, -0.4739],\n",
            "        [ 0.9360, -0.3147],\n",
            "        [ 0.6586, -0.3403],\n",
            "        [ 0.7221, -0.3212],\n",
            "        [ 0.8697, -0.5028],\n",
            "        [ 0.6941, -0.2725]], grad_fn=<MmBackward0>), tensor([[-0.2706, -0.9122],\n",
            "        [-0.3017, -1.1903],\n",
            "        [-0.2980, -1.2076],\n",
            "        [-0.3569, -1.1461],\n",
            "        [-0.3364, -1.1982],\n",
            "        [-0.4951, -1.3517],\n",
            "        [-0.2181, -1.1073],\n",
            "        [-0.3709, -1.2725],\n",
            "        [-0.3197, -1.1002],\n",
            "        [-0.2878, -0.9675]], grad_fn=<MmBackward0>), tensor([[1.0544, 0.1415],\n",
            "        [1.3092, 0.0983],\n",
            "        [1.1179, 0.1636],\n",
            "        [1.1546, 0.1334],\n",
            "        [1.2881, 0.2005],\n",
            "        [1.3589, 0.1072],\n",
            "        [1.3556, 0.2018],\n",
            "        [1.1910, 0.0593],\n",
            "        [1.2081, 0.0804],\n",
            "        [1.0576, 0.0866]], grad_fn=<MmBackward0>), tensor([[0.5591, 0.3853],\n",
            "        [0.3954, 0.2706],\n",
            "        [0.5080, 0.2050],\n",
            "        [0.5300, 0.2879],\n",
            "        [0.6311, 0.1351],\n",
            "        [0.6349, 0.4483],\n",
            "        [0.6538, 0.2126],\n",
            "        [0.6578, 0.2396],\n",
            "        [0.5729, 0.2627],\n",
            "        [0.5817, 0.2297]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.9898, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 0.1476, -1.4460],\n",
            "        [ 0.0936, -1.3221],\n",
            "        [ 0.2491, -1.2345],\n",
            "        [-0.0738, -1.3333],\n",
            "        [ 0.2431, -1.2571],\n",
            "        [ 0.1007, -1.3754],\n",
            "        [ 0.0251, -1.4210],\n",
            "        [ 0.1368, -1.3752],\n",
            "        [ 0.1032, -1.2071],\n",
            "        [ 0.1013, -1.4565]], grad_fn=<MmBackward0>), tensor([[ 1.1885, -0.6244],\n",
            "        [ 1.0985, -0.6236],\n",
            "        [ 0.8709, -0.3744],\n",
            "        [ 1.1713, -0.6643],\n",
            "        [ 0.9737, -0.5582],\n",
            "        [ 0.9688, -0.5949],\n",
            "        [ 1.1271, -0.6502],\n",
            "        [ 1.0936, -0.6362],\n",
            "        [ 0.9715, -0.7220],\n",
            "        [ 1.0479, -0.6705]], grad_fn=<MmBackward0>), tensor([[ 0.0302, -1.5100],\n",
            "        [ 0.0186, -1.5264],\n",
            "        [-0.0103, -1.2501],\n",
            "        [-0.1127, -1.4489],\n",
            "        [ 0.0068, -1.4230],\n",
            "        [-0.1083, -1.4815],\n",
            "        [-0.0997, -1.4834],\n",
            "        [-0.0564, -1.3204],\n",
            "        [ 0.1549, -1.5091],\n",
            "        [-0.0047, -1.5272]], grad_fn=<MmBackward0>), tensor([[ 1.6369, -0.0963],\n",
            "        [ 1.6047, -0.0599],\n",
            "        [ 1.5061, -0.2550],\n",
            "        [ 1.4646, -0.0507],\n",
            "        [ 1.5007, -0.1716],\n",
            "        [ 1.5270, -0.0655],\n",
            "        [ 1.6860, -0.0463],\n",
            "        [ 1.6777, -0.2131],\n",
            "        [ 1.4473, -0.0607],\n",
            "        [ 1.5890, -0.0971]], grad_fn=<MmBackward0>), tensor([[ 0.9440, -0.1002],\n",
            "        [ 1.0445, -0.1278],\n",
            "        [ 0.8838, -0.0112],\n",
            "        [ 1.0399, -0.1232],\n",
            "        [ 0.8615, -0.0250],\n",
            "        [ 0.8883, -0.1132],\n",
            "        [ 1.1131, -0.0100],\n",
            "        [ 0.9251,  0.0233],\n",
            "        [ 0.8677, -0.0558],\n",
            "        [ 0.9158,  0.0631]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.2563, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 0.3652, -1.3748],\n",
            "        [ 0.3527, -1.4880],\n",
            "        [ 0.3670, -1.7270],\n",
            "        [ 0.2906, -1.6532],\n",
            "        [ 0.3188, -1.6589],\n",
            "        [ 0.2929, -1.3745],\n",
            "        [ 0.3576, -1.5226],\n",
            "        [ 0.3329, -1.5678],\n",
            "        [ 0.3106, -1.4563],\n",
            "        [ 0.3391, -1.5204]], grad_fn=<MmBackward0>), tensor([[ 1.2090, -0.8930],\n",
            "        [ 1.1021, -0.9040],\n",
            "        [ 1.3450, -0.8884],\n",
            "        [ 1.3456, -0.9512],\n",
            "        [ 1.3565, -0.9128],\n",
            "        [ 1.1176, -0.8717],\n",
            "        [ 1.2376, -0.9006],\n",
            "        [ 1.2830, -0.8983],\n",
            "        [ 1.2148, -0.7785],\n",
            "        [ 0.9338, -0.8037]], grad_fn=<MmBackward0>), tensor([[ 0.3768, -1.6665],\n",
            "        [ 0.2278, -1.5440],\n",
            "        [ 0.2119, -1.9771],\n",
            "        [ 0.2727, -1.7769],\n",
            "        [ 0.2553, -1.8458],\n",
            "        [ 0.2128, -1.4774],\n",
            "        [ 0.3567, -1.8009],\n",
            "        [ 0.1809, -1.5772],\n",
            "        [ 0.2459, -1.6912],\n",
            "        [ 0.3407, -1.5068]], grad_fn=<MmBackward0>), tensor([[ 1.7106, -0.2376],\n",
            "        [ 1.7570, -0.3137],\n",
            "        [ 1.8910, -0.2401],\n",
            "        [ 1.7711, -0.2519],\n",
            "        [ 1.7626, -0.3324],\n",
            "        [ 1.5951, -0.3458],\n",
            "        [ 1.8609, -0.2553],\n",
            "        [ 1.6457, -0.1998],\n",
            "        [ 1.7551, -0.3715],\n",
            "        [ 1.4723, -0.2123]], grad_fn=<MmBackward0>), tensor([[ 1.1993, -0.3903],\n",
            "        [ 1.2172, -0.3275],\n",
            "        [ 1.3826, -0.4338],\n",
            "        [ 1.2730, -0.4007],\n",
            "        [ 1.4120, -0.4608],\n",
            "        [ 1.1100, -0.4750],\n",
            "        [ 1.3584, -0.4638],\n",
            "        [ 1.4052, -0.4159],\n",
            "        [ 1.2715, -0.4420],\n",
            "        [ 1.0716, -0.1875]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]])\n",
            "tensor(1.0495, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 0.4869, -1.6743],\n",
            "        [ 0.5990, -1.7964],\n",
            "        [ 0.5658, -1.7645],\n",
            "        [ 0.6512, -2.0369],\n",
            "        [ 0.6193, -1.8118],\n",
            "        [ 0.5906, -1.6383],\n",
            "        [ 0.5441, -1.8218],\n",
            "        [ 0.5099, -1.7431],\n",
            "        [ 0.3816, -1.6498],\n",
            "        [ 0.6792, -1.6825]], grad_fn=<MmBackward0>), tensor([[ 1.4347, -1.0822],\n",
            "        [ 1.5170, -1.2830],\n",
            "        [ 1.4989, -1.0120],\n",
            "        [ 1.6815, -1.1383],\n",
            "        [ 1.5185, -1.1993],\n",
            "        [ 1.3168, -0.9664],\n",
            "        [ 1.5484, -1.0791],\n",
            "        [ 1.5591, -1.0718],\n",
            "        [ 1.4093, -1.2204],\n",
            "        [ 1.4519, -1.0706]], grad_fn=<MmBackward0>), tensor([[ 0.3878, -1.8018],\n",
            "        [ 0.5562, -2.1253],\n",
            "        [ 0.4803, -2.1170],\n",
            "        [ 0.5341, -2.0728],\n",
            "        [ 0.5492, -2.0289],\n",
            "        [ 0.4564, -1.8008],\n",
            "        [ 0.6171, -2.0929],\n",
            "        [ 0.5517, -2.1800],\n",
            "        [ 0.3879, -2.0420],\n",
            "        [ 0.4216, -2.1012]], grad_fn=<MmBackward0>), tensor([[ 1.7789, -0.4700],\n",
            "        [ 1.8172, -0.5705],\n",
            "        [ 1.8694, -0.4311],\n",
            "        [ 2.0618, -0.5224],\n",
            "        [ 2.0620, -0.6188],\n",
            "        [ 1.7796, -0.5286],\n",
            "        [ 2.0053, -0.5562],\n",
            "        [ 2.0664, -0.4338],\n",
            "        [ 1.6732, -0.3836],\n",
            "        [ 2.0817, -0.5549]], grad_fn=<MmBackward0>), tensor([[ 1.5834, -0.8661],\n",
            "        [ 1.7499, -0.6959],\n",
            "        [ 1.5939, -0.6174],\n",
            "        [ 1.9229, -0.8491],\n",
            "        [ 1.7428, -0.8076],\n",
            "        [ 1.5579, -0.8135],\n",
            "        [ 1.7558, -0.8993],\n",
            "        [ 1.7560, -0.8935],\n",
            "        [ 1.6104, -0.7526],\n",
            "        [ 1.6722, -0.8470]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor(1.6483, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 0.6961, -1.7536],\n",
            "        [ 0.7802, -1.8557],\n",
            "        [ 0.8207, -2.0484],\n",
            "        [ 0.8237, -2.0801],\n",
            "        [ 0.7246, -1.7777],\n",
            "        [ 0.8529, -1.8994],\n",
            "        [ 0.8225, -2.0505],\n",
            "        [ 0.7841, -1.9878],\n",
            "        [ 0.7723, -1.9088],\n",
            "        [ 0.8446, -2.2023]], grad_fn=<MmBackward0>), tensor([[ 1.6218, -1.1170],\n",
            "        [ 1.7049, -1.2274],\n",
            "        [ 1.7317, -1.2978],\n",
            "        [ 1.6679, -1.3443],\n",
            "        [ 1.5114, -1.1459],\n",
            "        [ 1.7072, -1.2532],\n",
            "        [ 1.7312, -1.3442],\n",
            "        [ 1.8750, -1.3822],\n",
            "        [ 1.7852, -1.2022],\n",
            "        [ 1.9506, -1.3878]], grad_fn=<MmBackward0>), tensor([[ 0.7119, -2.0777],\n",
            "        [ 0.7030, -2.1819],\n",
            "        [ 0.8091, -2.4154],\n",
            "        [ 0.8114, -2.2832],\n",
            "        [ 0.7415, -2.0736],\n",
            "        [ 0.7612, -2.4024],\n",
            "        [ 0.8481, -2.3692],\n",
            "        [ 0.7374, -2.3109],\n",
            "        [ 0.6048, -2.0829],\n",
            "        [ 0.9666, -2.3619]], grad_fn=<MmBackward0>), tensor([[ 1.8850, -0.4071],\n",
            "        [ 2.3451, -0.5407],\n",
            "        [ 2.1630, -0.6195],\n",
            "        [ 2.1175, -0.7058],\n",
            "        [ 2.0098, -0.5155],\n",
            "        [ 2.0644, -0.7594],\n",
            "        [ 2.0409, -0.5621],\n",
            "        [ 2.1571, -0.7134],\n",
            "        [ 2.1691, -0.5914],\n",
            "        [ 2.3464, -0.6688]], grad_fn=<MmBackward0>), tensor([[ 1.8450, -0.9853],\n",
            "        [ 1.9174, -1.2239],\n",
            "        [ 2.0731, -1.2148],\n",
            "        [ 2.0670, -1.0762],\n",
            "        [ 1.7728, -1.0534],\n",
            "        [ 2.0679, -1.1261],\n",
            "        [ 2.0595, -1.0833],\n",
            "        [ 2.0339, -1.1720],\n",
            "        [ 2.0159, -1.1236],\n",
            "        [ 2.1315, -1.1456]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]])\n",
            "tensor(1.2294, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 0.8824, -2.0373],\n",
            "        [ 0.9730, -2.0961],\n",
            "        [ 1.0744, -2.2236],\n",
            "        [ 1.0033, -2.1539],\n",
            "        [ 1.1380, -2.1154],\n",
            "        [ 0.9668, -2.1406],\n",
            "        [ 1.1296, -2.3145],\n",
            "        [ 1.0588, -2.0899],\n",
            "        [ 1.0681, -2.2312],\n",
            "        [ 0.9372, -2.1509]], grad_fn=<MmBackward0>), tensor([[ 1.8069, -1.3371],\n",
            "        [ 1.5794, -1.3432],\n",
            "        [ 1.8766, -1.3957],\n",
            "        [ 1.8172, -1.2650],\n",
            "        [ 1.7480, -1.2822],\n",
            "        [ 1.9606, -1.4520],\n",
            "        [ 1.9329, -1.4148],\n",
            "        [ 1.8922, -1.4259],\n",
            "        [ 1.9393, -1.3890],\n",
            "        [ 1.7339, -1.1921]], grad_fn=<MmBackward0>), tensor([[ 0.9489, -2.2646],\n",
            "        [ 0.8352, -2.2147],\n",
            "        [ 0.9435, -2.5581],\n",
            "        [ 0.8866, -2.3934],\n",
            "        [ 1.0894, -2.5664],\n",
            "        [ 1.0330, -2.4494],\n",
            "        [ 0.8624, -2.5387],\n",
            "        [ 0.9768, -2.5148],\n",
            "        [ 1.0309, -2.4920],\n",
            "        [ 0.8415, -2.3606]], grad_fn=<MmBackward0>), tensor([[ 2.1593, -0.8639],\n",
            "        [ 2.1726, -0.7157],\n",
            "        [ 2.3286, -0.8009],\n",
            "        [ 2.1146, -0.8894],\n",
            "        [ 2.3633, -0.8512],\n",
            "        [ 2.2474, -0.7212],\n",
            "        [ 2.2661, -0.8523],\n",
            "        [ 2.0552, -0.8255],\n",
            "        [ 2.3575, -0.9138],\n",
            "        [ 2.2041, -0.8631]], grad_fn=<MmBackward0>), tensor([[ 2.0190, -1.3344],\n",
            "        [ 2.1234, -1.1617],\n",
            "        [ 2.3149, -1.4518],\n",
            "        [ 2.1316, -1.1768],\n",
            "        [ 2.3680, -1.3517],\n",
            "        [ 2.2752, -1.3834],\n",
            "        [ 2.3118, -1.3662],\n",
            "        [ 2.2679, -1.3246],\n",
            "        [ 2.3354, -1.2079],\n",
            "        [ 2.3052, -1.3756]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.1913, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.1880, -2.5064],\n",
            "        [ 1.2838, -2.4287],\n",
            "        [ 1.3331, -2.5008],\n",
            "        [ 1.1307, -2.2103],\n",
            "        [ 1.1784, -2.2969],\n",
            "        [ 1.0437, -2.2901],\n",
            "        [ 1.2665, -2.4201],\n",
            "        [ 1.2493, -2.4966],\n",
            "        [ 1.2950, -2.3169],\n",
            "        [ 1.1320, -2.1977]], grad_fn=<MmBackward0>), tensor([[ 2.1648, -1.5781],\n",
            "        [ 2.0812, -1.6002],\n",
            "        [ 2.2288, -1.6518],\n",
            "        [ 2.0155, -1.6616],\n",
            "        [ 2.0967, -1.6481],\n",
            "        [ 2.0660, -1.4794],\n",
            "        [ 2.2022, -1.7124],\n",
            "        [ 2.2437, -1.6220],\n",
            "        [ 2.0354, -1.5327],\n",
            "        [ 1.9976, -1.4553]], grad_fn=<MmBackward0>), tensor([[ 1.0881, -2.9771],\n",
            "        [ 1.3578, -2.7577],\n",
            "        [ 1.0731, -2.8819],\n",
            "        [ 1.2853, -2.7581],\n",
            "        [ 1.1821, -2.6025],\n",
            "        [ 1.2003, -2.5285],\n",
            "        [ 1.2861, -2.8090],\n",
            "        [ 1.2885, -2.8431],\n",
            "        [ 1.0646, -2.6817],\n",
            "        [ 1.0393, -2.7875]], grad_fn=<MmBackward0>), tensor([[ 2.7316, -1.1450],\n",
            "        [ 2.7113, -0.9904],\n",
            "        [ 2.3701, -0.9727],\n",
            "        [ 2.4852, -0.9923],\n",
            "        [ 2.4105, -1.0154],\n",
            "        [ 2.4892, -1.0079],\n",
            "        [ 2.6362, -1.0415],\n",
            "        [ 2.5302, -0.9777],\n",
            "        [ 2.5668, -1.1012],\n",
            "        [ 2.3360, -0.7946]], grad_fn=<MmBackward0>), tensor([[ 2.6837, -1.7470],\n",
            "        [ 2.5904, -1.6212],\n",
            "        [ 2.6121, -1.6155],\n",
            "        [ 2.5348, -1.7152],\n",
            "        [ 2.5926, -1.5615],\n",
            "        [ 2.4007, -1.5414],\n",
            "        [ 2.5790, -1.7736],\n",
            "        [ 2.7170, -1.6878],\n",
            "        [ 2.6503, -1.6355],\n",
            "        [ 2.5207, -1.4866]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.1159, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.4734, -2.4180],\n",
            "        [ 1.3924, -2.4050],\n",
            "        [ 1.4522, -2.4424],\n",
            "        [ 1.3629, -2.6756],\n",
            "        [ 1.2898, -2.2756],\n",
            "        [ 1.4223, -2.6740],\n",
            "        [ 1.4975, -2.8653],\n",
            "        [ 1.3229, -2.5460],\n",
            "        [ 1.2757, -2.3186],\n",
            "        [ 1.5873, -2.6961]], grad_fn=<MmBackward0>), tensor([[ 2.0377, -1.7169],\n",
            "        [ 2.0631, -1.4908],\n",
            "        [ 2.0830, -1.4674],\n",
            "        [ 2.3019, -1.7168],\n",
            "        [ 1.9520, -1.6150],\n",
            "        [ 2.4062, -1.8645],\n",
            "        [ 2.3308, -1.8329],\n",
            "        [ 2.2615, -1.7187],\n",
            "        [ 1.9869, -1.6601],\n",
            "        [ 2.3310, -1.8262]], grad_fn=<MmBackward0>), tensor([[ 1.2339, -2.7216],\n",
            "        [ 1.2755, -2.8905],\n",
            "        [ 1.3450, -2.7805],\n",
            "        [ 1.2646, -3.0078],\n",
            "        [ 1.1905, -2.7267],\n",
            "        [ 1.3391, -2.9419],\n",
            "        [ 1.4781, -3.0649],\n",
            "        [ 1.3050, -2.9194],\n",
            "        [ 1.1369, -2.7108],\n",
            "        [ 1.3538, -3.0261]], grad_fn=<MmBackward0>), tensor([[ 2.6139, -1.0678],\n",
            "        [ 2.4745, -1.1559],\n",
            "        [ 2.5060, -1.1005],\n",
            "        [ 2.8317, -1.2036],\n",
            "        [ 2.4284, -0.9993],\n",
            "        [ 2.6717, -1.2463],\n",
            "        [ 2.8107, -1.2478],\n",
            "        [ 2.5793, -1.2524],\n",
            "        [ 2.5002, -0.9358],\n",
            "        [ 2.7481, -1.2571]], grad_fn=<MmBackward0>), tensor([[ 2.6885, -1.7526],\n",
            "        [ 2.7252, -1.8237],\n",
            "        [ 2.7807, -1.7526],\n",
            "        [ 2.9070, -1.9368],\n",
            "        [ 2.5767, -1.4850],\n",
            "        [ 2.8612, -1.8268],\n",
            "        [ 2.8628, -2.0220],\n",
            "        [ 2.9296, -1.8054],\n",
            "        [ 2.4821, -1.7044],\n",
            "        [ 2.9598, -1.9411]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.3021, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.6498, -2.6968],\n",
            "        [ 1.5063, -2.3938],\n",
            "        [ 1.4521, -2.5939],\n",
            "        [ 1.4831, -2.4979],\n",
            "        [ 1.5083, -2.7156],\n",
            "        [ 1.6499, -2.6119],\n",
            "        [ 1.6651, -2.5342],\n",
            "        [ 1.4833, -2.6369],\n",
            "        [ 1.5606, -2.6628],\n",
            "        [ 1.7616, -2.9002]], grad_fn=<MmBackward0>), tensor([[ 2.3590, -1.8104],\n",
            "        [ 2.1798, -1.7991],\n",
            "        [ 2.3833, -1.8784],\n",
            "        [ 2.1847, -1.6179],\n",
            "        [ 2.3979, -1.8239],\n",
            "        [ 2.2716, -1.6516],\n",
            "        [ 2.1714, -1.7207],\n",
            "        [ 2.4001, -1.7814],\n",
            "        [ 2.5225, -1.9036],\n",
            "        [ 2.5204, -1.9290]], grad_fn=<MmBackward0>), tensor([[ 1.5648, -3.2044],\n",
            "        [ 1.3195, -2.7709],\n",
            "        [ 1.3571, -2.8985],\n",
            "        [ 1.5284, -2.8399],\n",
            "        [ 1.4665, -3.1365],\n",
            "        [ 1.3980, -2.9094],\n",
            "        [ 1.5647, -2.9374],\n",
            "        [ 1.3966, -3.1790],\n",
            "        [ 1.4502, -3.2362],\n",
            "        [ 1.4017, -3.2865]], grad_fn=<MmBackward0>), tensor([[ 2.7566, -1.2733],\n",
            "        [ 2.6415, -1.0553],\n",
            "        [ 2.5786, -1.2107],\n",
            "        [ 2.4088, -1.3768],\n",
            "        [ 2.7787, -1.2182],\n",
            "        [ 2.6671, -1.2137],\n",
            "        [ 2.7996, -1.3824],\n",
            "        [ 2.6413, -1.2472],\n",
            "        [ 2.8064, -1.2891],\n",
            "        [ 2.9802, -1.4324]], grad_fn=<MmBackward0>), tensor([[ 3.0790, -2.1494],\n",
            "        [ 2.8866, -1.9444],\n",
            "        [ 2.9896, -2.0934],\n",
            "        [ 2.8329, -1.8686],\n",
            "        [ 2.9584, -1.9720],\n",
            "        [ 2.9578, -1.9458],\n",
            "        [ 3.0150, -1.9213],\n",
            "        [ 3.2429, -2.1951],\n",
            "        [ 3.0593, -2.0174],\n",
            "        [ 3.2492, -2.2553]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.0684, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.6175, -2.9502],\n",
            "        [ 1.5894, -2.6450],\n",
            "        [ 1.6649, -2.7332],\n",
            "        [ 1.8338, -2.8997],\n",
            "        [ 1.6729, -2.9048],\n",
            "        [ 1.7949, -2.7651],\n",
            "        [ 1.7263, -3.0287],\n",
            "        [ 1.6634, -2.8024],\n",
            "        [ 1.7437, -2.6346],\n",
            "        [ 1.5405, -2.5789]], grad_fn=<MmBackward0>), tensor([[ 2.4066, -2.0534],\n",
            "        [ 2.1625, -1.7670],\n",
            "        [ 2.2332, -1.8960],\n",
            "        [ 2.5137, -2.1363],\n",
            "        [ 2.5626, -2.0172],\n",
            "        [ 2.5068, -1.8806],\n",
            "        [ 2.6114, -2.0793],\n",
            "        [ 2.5598, -1.9656],\n",
            "        [ 2.3096, -1.8086],\n",
            "        [ 2.2723, -1.8519]], grad_fn=<MmBackward0>), tensor([[ 1.4962, -3.2290],\n",
            "        [ 1.5265, -3.0354],\n",
            "        [ 1.6725, -3.2055],\n",
            "        [ 1.6459, -3.2992],\n",
            "        [ 1.6103, -3.3903],\n",
            "        [ 1.6367, -3.1510],\n",
            "        [ 1.5782, -3.3781],\n",
            "        [ 1.5681, -3.3609],\n",
            "        [ 1.5274, -2.8883],\n",
            "        [ 1.3389, -2.8787]], grad_fn=<MmBackward0>), tensor([[ 2.7967, -1.2594],\n",
            "        [ 2.5900, -1.1269],\n",
            "        [ 2.9485, -1.4186],\n",
            "        [ 2.9287, -1.3201],\n",
            "        [ 2.9637, -1.3977],\n",
            "        [ 2.8271, -1.2616],\n",
            "        [ 2.9154, -1.5325],\n",
            "        [ 2.8609, -1.2210],\n",
            "        [ 2.6539, -1.2513],\n",
            "        [ 2.5372, -1.1748]], grad_fn=<MmBackward0>), tensor([[ 3.1911, -2.3677],\n",
            "        [ 3.0590, -2.0080],\n",
            "        [ 3.1782, -2.1956],\n",
            "        [ 3.1882, -2.2460],\n",
            "        [ 3.3322, -2.3045],\n",
            "        [ 3.1762, -2.2191],\n",
            "        [ 3.2641, -2.2970],\n",
            "        [ 3.2573, -2.3131],\n",
            "        [ 2.9889, -2.0744],\n",
            "        [ 3.0431, -1.9735]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.0553, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.9373, -3.0505],\n",
            "        [ 1.7339, -2.5418],\n",
            "        [ 1.8502, -3.0748],\n",
            "        [ 1.7960, -2.7333],\n",
            "        [ 1.9818, -2.9391],\n",
            "        [ 1.8465, -2.9256],\n",
            "        [ 1.7801, -3.1141],\n",
            "        [ 1.8998, -2.9277],\n",
            "        [ 1.6230, -2.9226],\n",
            "        [ 1.7914, -2.7037]], grad_fn=<MmBackward0>), tensor([[ 2.5581, -1.9693],\n",
            "        [ 2.4724, -1.7677],\n",
            "        [ 2.7191, -2.2517],\n",
            "        [ 2.6265, -2.0078],\n",
            "        [ 2.6113, -2.0967],\n",
            "        [ 2.6502, -1.9606],\n",
            "        [ 2.7465, -2.0817],\n",
            "        [ 2.6225, -2.0076],\n",
            "        [ 2.3631, -1.8523],\n",
            "        [ 2.4430, -1.8144]], grad_fn=<MmBackward0>), tensor([[ 1.8209, -3.4037],\n",
            "        [ 1.4671, -3.2760],\n",
            "        [ 1.8875, -3.5675],\n",
            "        [ 1.5885, -3.1879],\n",
            "        [ 1.7044, -3.3775],\n",
            "        [ 1.7370, -3.3785],\n",
            "        [ 1.7510, -3.5801],\n",
            "        [ 1.7675, -3.4146],\n",
            "        [ 1.5809, -3.1152],\n",
            "        [ 1.5435, -3.1866]], grad_fn=<MmBackward0>), tensor([[ 3.1125, -1.4744],\n",
            "        [ 2.7189, -1.1827],\n",
            "        [ 3.1502, -1.5326],\n",
            "        [ 2.9254, -1.5099],\n",
            "        [ 2.9561, -1.3945],\n",
            "        [ 2.9306, -1.3598],\n",
            "        [ 3.0594, -1.5055],\n",
            "        [ 3.1187, -1.4199],\n",
            "        [ 2.6895, -1.3908],\n",
            "        [ 2.8537, -1.4413]], grad_fn=<MmBackward0>), tensor([[ 3.6321, -2.4863],\n",
            "        [ 3.0748, -2.1225],\n",
            "        [ 3.3970, -2.5360],\n",
            "        [ 3.2197, -2.1885],\n",
            "        [ 3.3148, -2.3462],\n",
            "        [ 3.3754, -2.3119],\n",
            "        [ 3.5387, -2.4233],\n",
            "        [ 3.4396, -2.5630],\n",
            "        [ 3.1847, -2.3002],\n",
            "        [ 3.1276, -2.2317]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.3952, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 1.7548, -2.8045],\n",
            "        [ 1.9337, -3.0900],\n",
            "        [ 1.9712, -2.9529],\n",
            "        [ 2.1567, -3.0274],\n",
            "        [ 2.0276, -3.1211],\n",
            "        [ 1.9297, -2.9570],\n",
            "        [ 1.9554, -3.1235],\n",
            "        [ 1.9675, -3.0101],\n",
            "        [ 2.1115, -3.2290],\n",
            "        [ 1.7110, -2.8133]], grad_fn=<MmBackward0>), tensor([[ 2.5019, -1.8136],\n",
            "        [ 2.6985, -2.0807],\n",
            "        [ 2.5673, -1.8874],\n",
            "        [ 2.6110, -2.0338],\n",
            "        [ 2.7520, -2.1501],\n",
            "        [ 2.6488, -2.0954],\n",
            "        [ 2.7549, -2.0368],\n",
            "        [ 2.4415, -1.8229],\n",
            "        [ 2.7451, -2.3673],\n",
            "        [ 2.3655, -1.8349]], grad_fn=<MmBackward0>), tensor([[ 1.5618, -3.3302],\n",
            "        [ 1.8185, -3.5474],\n",
            "        [ 1.9237, -3.4384],\n",
            "        [ 1.7054, -3.3021],\n",
            "        [ 1.9460, -3.5724],\n",
            "        [ 1.6854, -3.4452],\n",
            "        [ 1.8820, -3.6583],\n",
            "        [ 1.6659, -3.2669],\n",
            "        [ 1.9302, -3.6486],\n",
            "        [ 1.7167, -3.2386]], grad_fn=<MmBackward0>), tensor([[ 2.7315, -1.4081],\n",
            "        [ 3.1023, -1.5594],\n",
            "        [ 3.0175, -1.4766],\n",
            "        [ 3.0969, -1.4445],\n",
            "        [ 3.0050, -1.5185],\n",
            "        [ 2.9029, -1.5536],\n",
            "        [ 3.2297, -1.4979],\n",
            "        [ 2.9304, -1.4703],\n",
            "        [ 3.0918, -1.6125],\n",
            "        [ 2.6053, -1.3968]], grad_fn=<MmBackward0>), tensor([[ 3.2829, -2.2064],\n",
            "        [ 3.4447, -2.5741],\n",
            "        [ 3.4687, -2.4615],\n",
            "        [ 3.4665, -2.4556],\n",
            "        [ 3.5301, -2.6296],\n",
            "        [ 3.4168, -2.4544],\n",
            "        [ 3.7134, -2.6066],\n",
            "        [ 3.4064, -2.2400],\n",
            "        [ 3.6167, -2.7236],\n",
            "        [ 3.3004, -2.3428]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.4860, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.1957, -3.1075],\n",
            "        [ 1.9959, -2.9866],\n",
            "        [ 1.8945, -2.9393],\n",
            "        [ 2.2355, -3.3821],\n",
            "        [ 1.9355, -3.0303],\n",
            "        [ 1.9676, -2.9418],\n",
            "        [ 2.0462, -3.2909],\n",
            "        [ 2.1127, -3.0847],\n",
            "        [ 2.0328, -3.2232],\n",
            "        [ 1.7980, -2.9604]], grad_fn=<MmBackward0>), tensor([[ 2.6954, -2.0795],\n",
            "        [ 2.6840, -2.0170],\n",
            "        [ 2.4899, -1.9375],\n",
            "        [ 2.7607, -2.1386],\n",
            "        [ 2.5315, -1.7865],\n",
            "        [ 2.3802, -1.9137],\n",
            "        [ 2.7229, -2.0023],\n",
            "        [ 2.5461, -1.9749],\n",
            "        [ 2.7913, -2.1522],\n",
            "        [ 2.4183, -1.8350]], grad_fn=<MmBackward0>), tensor([[ 2.0477, -3.5159],\n",
            "        [ 1.8180, -3.4634],\n",
            "        [ 1.8028, -3.2044],\n",
            "        [ 1.9398, -3.7093],\n",
            "        [ 1.7511, -3.2628],\n",
            "        [ 1.6635, -3.2363],\n",
            "        [ 1.9746, -3.4960],\n",
            "        [ 1.9437, -3.5770],\n",
            "        [ 1.8454, -3.6115],\n",
            "        [ 1.8807, -3.0844]], grad_fn=<MmBackward0>), tensor([[ 3.1917, -1.6191],\n",
            "        [ 3.0845, -1.5162],\n",
            "        [ 2.8324, -1.2949],\n",
            "        [ 3.1892, -1.7107],\n",
            "        [ 2.8366, -1.5318],\n",
            "        [ 2.7479, -1.5923],\n",
            "        [ 3.1655, -1.5645],\n",
            "        [ 3.0704, -1.6757],\n",
            "        [ 2.9675, -1.5744],\n",
            "        [ 2.8371, -1.4612]], grad_fn=<MmBackward0>), tensor([[ 3.6291, -2.6969],\n",
            "        [ 3.5909, -2.5306],\n",
            "        [ 3.3221, -2.4159],\n",
            "        [ 3.7350, -2.6743],\n",
            "        [ 3.3157, -2.4172],\n",
            "        [ 3.5447, -2.4019],\n",
            "        [ 3.6613, -2.7957],\n",
            "        [ 3.6098, -2.5965],\n",
            "        [ 3.6918, -2.6362],\n",
            "        [ 3.3648, -2.4362]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.9515, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.2748, -3.3673],\n",
            "        [ 2.1335, -2.8943],\n",
            "        [ 2.1201, -3.1555],\n",
            "        [ 1.7743, -2.5486],\n",
            "        [ 2.3138, -3.1338],\n",
            "        [ 2.3931, -3.3666],\n",
            "        [ 2.1518, -3.1252],\n",
            "        [ 2.0999, -3.1183],\n",
            "        [ 2.2032, -3.2298],\n",
            "        [ 1.9244, -3.0462]], grad_fn=<MmBackward0>), tensor([[ 2.7072, -2.2304],\n",
            "        [ 2.5486, -1.9942],\n",
            "        [ 2.8331, -2.0755],\n",
            "        [ 2.2446, -1.7269],\n",
            "        [ 2.7139, -2.0443],\n",
            "        [ 2.7711, -2.1199],\n",
            "        [ 2.5508, -2.1710],\n",
            "        [ 2.5274, -1.8443],\n",
            "        [ 2.8829, -2.0291],\n",
            "        [ 2.5714, -1.9420]], grad_fn=<MmBackward0>), tensor([[ 1.9410, -3.9066],\n",
            "        [ 1.8480, -3.3147],\n",
            "        [ 2.1122, -3.6629],\n",
            "        [ 1.5539, -2.9564],\n",
            "        [ 1.9940, -3.6961],\n",
            "        [ 2.0815, -3.9481],\n",
            "        [ 1.9089, -3.4069],\n",
            "        [ 1.8097, -3.2535],\n",
            "        [ 1.9637, -3.7903],\n",
            "        [ 1.9473, -3.4494]], grad_fn=<MmBackward0>), tensor([[ 3.0995, -1.6860],\n",
            "        [ 3.0062, -1.4628],\n",
            "        [ 3.0969, -1.7906],\n",
            "        [ 2.4130, -1.3686],\n",
            "        [ 3.3919, -1.7207],\n",
            "        [ 3.4352, -1.7868],\n",
            "        [ 2.9880, -1.5651],\n",
            "        [ 2.8887, -1.4922],\n",
            "        [ 3.1911, -1.6877],\n",
            "        [ 3.0618, -1.6182]], grad_fn=<MmBackward0>), tensor([[ 3.9728, -2.8695],\n",
            "        [ 3.4051, -2.5036],\n",
            "        [ 3.6848, -2.6810],\n",
            "        [ 3.1659, -2.1747],\n",
            "        [ 3.7150, -2.7735],\n",
            "        [ 4.0720, -2.9063],\n",
            "        [ 3.7597, -2.7279],\n",
            "        [ 3.4604, -2.3860],\n",
            "        [ 3.9601, -2.8266],\n",
            "        [ 3.6874, -2.5508]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
            "tensor(2.2575, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.0247, -3.0386],\n",
            "        [ 2.0845, -3.1095],\n",
            "        [ 2.1773, -3.3130],\n",
            "        [ 2.2918, -3.2348],\n",
            "        [ 2.1187, -2.8637],\n",
            "        [ 2.2046, -3.1470],\n",
            "        [ 2.1067, -3.1595],\n",
            "        [ 2.2444, -3.4395],\n",
            "        [ 2.1902, -3.0760],\n",
            "        [ 1.9559, -2.9215]], grad_fn=<MmBackward0>), tensor([[ 2.5343, -1.8827],\n",
            "        [ 2.5129, -2.0299],\n",
            "        [ 2.6357, -2.2469],\n",
            "        [ 2.7452, -2.1301],\n",
            "        [ 2.3056, -1.6103],\n",
            "        [ 2.6645, -1.9467],\n",
            "        [ 2.6333, -1.9636],\n",
            "        [ 2.7038, -2.0985],\n",
            "        [ 2.7291, -2.2170],\n",
            "        [ 2.3813, -1.8305]], grad_fn=<MmBackward0>), tensor([[ 1.9790, -3.3825],\n",
            "        [ 1.9427, -3.4500],\n",
            "        [ 2.0855, -3.7603],\n",
            "        [ 1.9067, -3.8112],\n",
            "        [ 1.6845, -3.4037],\n",
            "        [ 1.8805, -3.7761],\n",
            "        [ 1.9002, -3.6823],\n",
            "        [ 1.9974, -3.7465],\n",
            "        [ 2.1372, -3.5599],\n",
            "        [ 1.8489, -3.3791]], grad_fn=<MmBackward0>), tensor([[ 2.9059, -1.6427],\n",
            "        [ 2.8824, -1.5663],\n",
            "        [ 3.2175, -1.6613],\n",
            "        [ 3.4277, -1.6956],\n",
            "        [ 2.9463, -1.5393],\n",
            "        [ 3.2052, -1.5782],\n",
            "        [ 3.2376, -1.5721],\n",
            "        [ 3.2587, -1.7883],\n",
            "        [ 3.1778, -1.8149],\n",
            "        [ 2.8925, -1.5051]], grad_fn=<MmBackward0>), tensor([[ 3.4940, -2.6884],\n",
            "        [ 3.5464, -2.6165],\n",
            "        [ 3.8988, -2.9435],\n",
            "        [ 3.9374, -2.8436],\n",
            "        [ 3.4963, -2.4640],\n",
            "        [ 3.8810, -2.8271],\n",
            "        [ 3.6658, -2.8033],\n",
            "        [ 4.0533, -2.8473],\n",
            "        [ 3.8435, -2.9146],\n",
            "        [ 3.5040, -2.6682]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.5667, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.3112, -3.2965],\n",
            "        [ 2.1892, -3.2480],\n",
            "        [ 2.4086, -3.4707],\n",
            "        [ 2.1531, -2.9698],\n",
            "        [ 2.1367, -3.0555],\n",
            "        [ 2.0128, -3.1915],\n",
            "        [ 2.1084, -3.0864],\n",
            "        [ 2.3679, -3.4943],\n",
            "        [ 2.1581, -3.1311],\n",
            "        [ 2.4045, -3.4155]], grad_fn=<MmBackward0>), tensor([[ 2.6193, -2.0820],\n",
            "        [ 2.6060, -1.8779],\n",
            "        [ 2.6645, -2.1374],\n",
            "        [ 2.4036, -1.8442],\n",
            "        [ 2.3712, -1.9596],\n",
            "        [ 2.5285, -2.0943],\n",
            "        [ 2.4432, -1.7717],\n",
            "        [ 2.9447, -2.1715],\n",
            "        [ 2.7702, -2.1427],\n",
            "        [ 2.8044, -2.1277]], grad_fn=<MmBackward0>), tensor([[ 1.9963, -3.7910],\n",
            "        [ 1.9902, -3.5231],\n",
            "        [ 2.1722, -3.8808],\n",
            "        [ 1.7986, -3.4489],\n",
            "        [ 2.0563, -3.3764],\n",
            "        [ 2.0182, -3.4888],\n",
            "        [ 1.8985, -3.6485],\n",
            "        [ 2.0406, -3.9060],\n",
            "        [ 1.8496, -3.7138],\n",
            "        [ 2.2614, -3.9089]], grad_fn=<MmBackward0>), tensor([[ 3.3967, -1.7230],\n",
            "        [ 3.2693, -1.6856],\n",
            "        [ 3.4485, -1.8152],\n",
            "        [ 2.9900, -1.6885],\n",
            "        [ 3.1851, -1.6992],\n",
            "        [ 2.9913, -1.6876],\n",
            "        [ 3.0573, -1.5633],\n",
            "        [ 3.4186, -1.9117],\n",
            "        [ 3.1281, -1.6865],\n",
            "        [ 3.3826, -1.8493]], grad_fn=<MmBackward0>), tensor([[ 3.8865, -2.8220],\n",
            "        [ 3.8754, -2.9533],\n",
            "        [ 4.2995, -2.9966],\n",
            "        [ 3.6735, -2.8464],\n",
            "        [ 3.5727, -2.7309],\n",
            "        [ 3.7637, -2.7361],\n",
            "        [ 3.8263, -2.7549],\n",
            "        [ 4.0638, -3.1499],\n",
            "        [ 3.8148, -2.7499],\n",
            "        [ 4.0571, -3.0808]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.0300, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.1014, -2.9685],\n",
            "        [ 2.2654, -3.2282],\n",
            "        [ 2.2159, -3.1944],\n",
            "        [ 2.3604, -3.5138],\n",
            "        [ 2.3474, -3.4163],\n",
            "        [ 2.4845, -3.5016],\n",
            "        [ 2.2816, -3.3715],\n",
            "        [ 2.2790, -3.1576],\n",
            "        [ 2.2246, -3.1847],\n",
            "        [ 2.2550, -3.2516]], grad_fn=<MmBackward0>), tensor([[ 2.4212, -1.7396],\n",
            "        [ 2.6255, -1.9615],\n",
            "        [ 2.6235, -2.0588],\n",
            "        [ 2.7034, -2.2074],\n",
            "        [ 2.6992, -2.1217],\n",
            "        [ 2.6035, -2.0314],\n",
            "        [ 2.7241, -2.1941],\n",
            "        [ 2.7215, -1.9910],\n",
            "        [ 2.3485, -1.9228],\n",
            "        [ 2.4754, -2.1352]], grad_fn=<MmBackward0>), tensor([[ 1.8494, -3.3514],\n",
            "        [ 1.9631, -3.7737],\n",
            "        [ 1.9824, -3.6584],\n",
            "        [ 2.0986, -3.6762],\n",
            "        [ 2.0803, -3.7237],\n",
            "        [ 2.0934, -3.7767],\n",
            "        [ 2.0540, -3.7904],\n",
            "        [ 1.9432, -3.4236],\n",
            "        [ 1.7494, -3.5710],\n",
            "        [ 2.0156, -3.5816]], grad_fn=<MmBackward0>), tensor([[ 2.9039, -1.7755],\n",
            "        [ 3.2963, -1.7716],\n",
            "        [ 3.1336, -1.6877],\n",
            "        [ 3.4428, -1.9612],\n",
            "        [ 3.2785, -1.7409],\n",
            "        [ 3.2912, -1.8704],\n",
            "        [ 3.4945, -1.6939],\n",
            "        [ 3.2784, -1.6912],\n",
            "        [ 3.2629, -1.6219],\n",
            "        [ 3.2201, -1.7405]], grad_fn=<MmBackward0>), tensor([[ 3.6072, -2.5976],\n",
            "        [ 4.1026, -3.0148],\n",
            "        [ 3.9247, -2.8492],\n",
            "        [ 4.1412, -3.1090],\n",
            "        [ 4.0980, -3.0294],\n",
            "        [ 4.1776, -2.9151],\n",
            "        [ 3.9440, -3.0963],\n",
            "        [ 3.7577, -2.8637],\n",
            "        [ 3.8392, -2.7095],\n",
            "        [ 3.9019, -3.0377]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.6030, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.1704, -3.0383],\n",
            "        [ 2.3086, -3.2820],\n",
            "        [ 2.4720, -3.3938],\n",
            "        [ 2.2754, -3.4946],\n",
            "        [ 2.4617, -3.5937],\n",
            "        [ 2.2950, -3.4696],\n",
            "        [ 2.2669, -3.0594],\n",
            "        [ 2.1301, -3.0460],\n",
            "        [ 2.1090, -3.1569],\n",
            "        [ 2.4037, -3.4479]], grad_fn=<MmBackward0>), tensor([[ 2.1744, -1.5579],\n",
            "        [ 2.6778, -1.9357],\n",
            "        [ 2.6460, -2.0002],\n",
            "        [ 2.5960, -1.9966],\n",
            "        [ 2.6504, -2.0458],\n",
            "        [ 2.6119, -1.9212],\n",
            "        [ 2.4980, -1.9815],\n",
            "        [ 2.4002, -1.8274],\n",
            "        [ 2.4178, -1.9092],\n",
            "        [ 2.7921, -2.1292]], grad_fn=<MmBackward0>), tensor([[ 1.8487, -3.2810],\n",
            "        [ 2.0481, -3.5484],\n",
            "        [ 1.9839, -3.6259],\n",
            "        [ 1.9863, -3.5930],\n",
            "        [ 2.2027, -3.8570],\n",
            "        [ 1.9957, -3.6543],\n",
            "        [ 1.8190, -3.4425],\n",
            "        [ 1.9501, -3.1147],\n",
            "        [ 1.9136, -3.4324],\n",
            "        [ 2.1253, -3.8718]], grad_fn=<MmBackward0>), tensor([[ 3.1116, -1.7211],\n",
            "        [ 3.2545, -1.8306],\n",
            "        [ 3.4271, -1.8852],\n",
            "        [ 3.1444, -1.8515],\n",
            "        [ 3.5557, -1.8077],\n",
            "        [ 3.2738, -1.8287],\n",
            "        [ 3.0263, -1.6223],\n",
            "        [ 2.9673, -1.5962],\n",
            "        [ 3.0057, -1.6881],\n",
            "        [ 3.4760, -1.8547]], grad_fn=<MmBackward0>), tensor([[ 3.7883, -2.8050],\n",
            "        [ 4.1886, -3.0981],\n",
            "        [ 4.1934, -3.1112],\n",
            "        [ 4.1037, -2.9865],\n",
            "        [ 4.2635, -3.2588],\n",
            "        [ 4.2320, -3.0583],\n",
            "        [ 3.7498, -2.7487],\n",
            "        [ 3.6416, -2.8291],\n",
            "        [ 3.7895, -2.7098],\n",
            "        [ 4.1424, -3.2826]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.5201, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.4384, -3.4519],\n",
            "        [ 2.4020, -3.4810],\n",
            "        [ 2.5088, -3.5445],\n",
            "        [ 2.3288, -3.2915],\n",
            "        [ 2.2859, -3.1897],\n",
            "        [ 2.4999, -3.4212],\n",
            "        [ 2.2705, -3.2686],\n",
            "        [ 2.0656, -3.1814],\n",
            "        [ 2.3999, -3.3107],\n",
            "        [ 2.3934, -3.5213]], grad_fn=<MmBackward0>), tensor([[ 2.5825, -1.9956],\n",
            "        [ 2.5535, -1.8877],\n",
            "        [ 2.7950, -2.0297],\n",
            "        [ 2.3748, -1.8797],\n",
            "        [ 2.4615, -1.8539],\n",
            "        [ 2.6237, -2.0045],\n",
            "        [ 2.4513, -1.8747],\n",
            "        [ 2.3228, -1.8580],\n",
            "        [ 2.4651, -1.8441],\n",
            "        [ 2.6456, -2.0233]], grad_fn=<MmBackward0>), tensor([[ 1.9890, -3.8482],\n",
            "        [ 1.9984, -3.6742],\n",
            "        [ 2.0619, -3.7673],\n",
            "        [ 1.9797, -3.2573],\n",
            "        [ 1.9865, -3.4452],\n",
            "        [ 2.1187, -3.7844],\n",
            "        [ 1.8602, -3.6204],\n",
            "        [ 1.8260, -3.3838],\n",
            "        [ 1.9939, -3.5791],\n",
            "        [ 2.1266, -3.7901]], grad_fn=<MmBackward0>), tensor([[ 3.4652, -1.8606],\n",
            "        [ 3.4102, -1.8924],\n",
            "        [ 3.3030, -1.7857],\n",
            "        [ 3.0356, -1.6058],\n",
            "        [ 3.3245, -1.7154],\n",
            "        [ 3.5747, -1.9273],\n",
            "        [ 3.1823, -1.8501],\n",
            "        [ 3.1012, -1.7790],\n",
            "        [ 3.2858, -1.8029],\n",
            "        [ 3.3883, -1.9530]], grad_fn=<MmBackward0>), tensor([[ 4.3331, -3.1582],\n",
            "        [ 4.2711, -3.1971],\n",
            "        [ 4.0869, -3.1597],\n",
            "        [ 3.8842, -2.6697],\n",
            "        [ 3.8873, -3.0332],\n",
            "        [ 4.2796, -3.2210],\n",
            "        [ 4.0624, -2.9470],\n",
            "        [ 3.9042, -2.8943],\n",
            "        [ 3.9490, -2.9521],\n",
            "        [ 4.1779, -3.2478]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(2.4658, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.5268, -3.3938],\n",
            "        [ 2.4043, -3.3426],\n",
            "        [ 2.4027, -3.5604],\n",
            "        [ 2.1593, -3.0142],\n",
            "        [ 2.2863, -3.2301],\n",
            "        [ 2.4116, -3.3496],\n",
            "        [ 2.6051, -3.5751],\n",
            "        [ 2.4620, -3.5543],\n",
            "        [ 2.2185, -3.1800],\n",
            "        [ 2.2831, -3.0328]], grad_fn=<MmBackward0>), tensor([[ 2.6151, -1.8331],\n",
            "        [ 2.4047, -1.9421],\n",
            "        [ 2.5249, -1.9679],\n",
            "        [ 2.2500, -1.7194],\n",
            "        [ 2.5596, -1.7140],\n",
            "        [ 2.4833, -1.8500],\n",
            "        [ 2.6045, -1.9971],\n",
            "        [ 2.3877, -1.9553],\n",
            "        [ 2.4230, -1.7568],\n",
            "        [ 2.2161, -1.6786]], grad_fn=<MmBackward0>), tensor([[ 1.9963, -3.6535],\n",
            "        [ 2.1103, -3.6512],\n",
            "        [ 2.0876, -3.8557],\n",
            "        [ 1.8019, -3.2576],\n",
            "        [ 2.0814, -3.5052],\n",
            "        [ 2.0114, -3.4455],\n",
            "        [ 2.0587, -3.9088],\n",
            "        [ 2.2406, -3.7040],\n",
            "        [ 1.8668, -3.5169],\n",
            "        [ 1.7437, -3.2023]], grad_fn=<MmBackward0>), tensor([[ 3.2391, -1.8816],\n",
            "        [ 3.3377, -1.8109],\n",
            "        [ 3.6029, -1.8920],\n",
            "        [ 2.9638, -1.7679],\n",
            "        [ 3.1588, -1.8412],\n",
            "        [ 3.2721, -1.7476],\n",
            "        [ 3.5065, -2.0285],\n",
            "        [ 3.4323, -2.0212],\n",
            "        [ 3.2083, -1.8195],\n",
            "        [ 2.9223, -1.5788]], grad_fn=<MmBackward0>), tensor([[ 4.0634, -3.0377],\n",
            "        [ 4.0387, -3.0620],\n",
            "        [ 4.3558, -3.3420],\n",
            "        [ 3.7257, -2.7877],\n",
            "        [ 4.0126, -2.8666],\n",
            "        [ 3.8996, -2.8480],\n",
            "        [ 4.3634, -3.2256],\n",
            "        [ 4.2565, -3.3114],\n",
            "        [ 4.0550, -2.8825],\n",
            "        [ 3.8029, -2.6707]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.4183, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.3983, -3.5101],\n",
            "        [ 2.5438, -3.7719],\n",
            "        [ 2.1217, -2.9521],\n",
            "        [ 2.4466, -3.4692],\n",
            "        [ 2.3259, -3.1086],\n",
            "        [ 2.2904, -3.1589],\n",
            "        [ 2.3499, -3.1277],\n",
            "        [ 2.4903, -3.6269],\n",
            "        [ 2.6136, -3.6030],\n",
            "        [ 2.3357, -3.3391]], grad_fn=<MmBackward0>), tensor([[ 2.5450, -1.9379],\n",
            "        [ 2.6740, -1.8862],\n",
            "        [ 2.1287, -1.7207],\n",
            "        [ 2.5463, -1.8252],\n",
            "        [ 2.1728, -1.5361],\n",
            "        [ 2.2479, -1.7850],\n",
            "        [ 2.4424, -1.8156],\n",
            "        [ 2.5548, -1.9088],\n",
            "        [ 2.6239, -1.8580],\n",
            "        [ 2.4901, -1.7848]], grad_fn=<MmBackward0>), tensor([[ 1.9281, -3.8103],\n",
            "        [ 1.9392, -3.8054],\n",
            "        [ 1.8047, -3.2800],\n",
            "        [ 1.8854, -3.6174],\n",
            "        [ 1.8484, -3.1341],\n",
            "        [ 2.0205, -3.2791],\n",
            "        [ 1.7780, -3.3654],\n",
            "        [ 2.0447, -3.7138],\n",
            "        [ 2.0134, -3.8821],\n",
            "        [ 1.9383, -3.5032]], grad_fn=<MmBackward0>), tensor([[ 3.6378, -1.9966],\n",
            "        [ 3.6385, -2.1149],\n",
            "        [ 3.0007, -1.6772],\n",
            "        [ 3.2111, -1.9196],\n",
            "        [ 2.9872, -1.7879],\n",
            "        [ 3.1603, -1.8291],\n",
            "        [ 3.1958, -1.7283],\n",
            "        [ 3.6130, -2.0796],\n",
            "        [ 3.5539, -2.0563],\n",
            "        [ 3.2665, -1.8762]], grad_fn=<MmBackward0>), tensor([[ 4.3528, -3.2030],\n",
            "        [ 4.4729, -3.2563],\n",
            "        [ 3.7312, -2.6944],\n",
            "        [ 4.2180, -3.0480],\n",
            "        [ 3.8698, -2.8251],\n",
            "        [ 3.8781, -3.0272],\n",
            "        [ 4.0222, -2.9322],\n",
            "        [ 4.2422, -3.3382],\n",
            "        [ 4.3537, -3.3354],\n",
            "        [ 4.1034, -2.9850]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.5274, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.3899, -3.3461],\n",
            "        [ 2.2172, -3.1468],\n",
            "        [ 2.5235, -3.5351],\n",
            "        [ 2.6180, -3.5011],\n",
            "        [ 2.4521, -3.6211],\n",
            "        [ 2.0509, -3.0878],\n",
            "        [ 2.5420, -3.5689],\n",
            "        [ 2.5878, -3.3723],\n",
            "        [ 2.4149, -3.3920],\n",
            "        [ 2.3106, -3.4138]], grad_fn=<MmBackward0>), tensor([[ 2.4332, -1.8122],\n",
            "        [ 2.0543, -1.5091],\n",
            "        [ 2.4208, -1.8543],\n",
            "        [ 2.5511, -1.7723],\n",
            "        [ 2.5435, -1.8303],\n",
            "        [ 2.4235, -1.7696],\n",
            "        [ 2.5753, -1.9117],\n",
            "        [ 2.4198, -1.7735],\n",
            "        [ 2.4427, -1.6541],\n",
            "        [ 2.3866, -1.6969]], grad_fn=<MmBackward0>), tensor([[ 2.0047, -3.7146],\n",
            "        [ 1.8283, -3.1089],\n",
            "        [ 2.1317, -3.6301],\n",
            "        [ 2.0583, -3.8651],\n",
            "        [ 2.0632, -3.6481],\n",
            "        [ 1.6422, -3.3737],\n",
            "        [ 1.9690, -3.8756],\n",
            "        [ 1.7837, -3.5794],\n",
            "        [ 1.9337, -3.5809],\n",
            "        [ 2.0177, -3.5263]], grad_fn=<MmBackward0>), tensor([[ 3.4185, -1.9648],\n",
            "        [ 2.9960, -1.6968],\n",
            "        [ 3.3882, -2.0696],\n",
            "        [ 3.6339, -2.0894],\n",
            "        [ 3.3741, -1.8833],\n",
            "        [ 3.1506, -1.7905],\n",
            "        [ 3.6104, -2.0226],\n",
            "        [ 3.4420, -1.9744],\n",
            "        [ 3.4065, -1.8061],\n",
            "        [ 3.3558, -1.9516]], grad_fn=<MmBackward0>), tensor([[ 4.1553, -3.0909],\n",
            "        [ 3.6792, -2.6215],\n",
            "        [ 4.0847, -3.1929],\n",
            "        [ 4.4939, -3.1882],\n",
            "        [ 4.2240, -3.2272],\n",
            "        [ 3.9490, -2.9307],\n",
            "        [ 4.5826, -3.2387],\n",
            "        [ 4.1949, -3.1118],\n",
            "        [ 4.1419, -3.0487],\n",
            "        [ 4.0653, -3.1022]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(2.6437, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.4992, -3.4898],\n",
            "        [ 2.2389, -3.2459],\n",
            "        [ 2.2460, -3.1053],\n",
            "        [ 2.4934, -3.4520],\n",
            "        [ 2.2384, -3.0166],\n",
            "        [ 2.5626, -3.4770],\n",
            "        [ 2.4313, -3.5340],\n",
            "        [ 2.6116, -3.5572],\n",
            "        [ 2.3759, -3.0895],\n",
            "        [ 2.3435, -3.1797]], grad_fn=<MmBackward0>), tensor([[ 2.3087, -1.8474],\n",
            "        [ 2.1363, -1.5283],\n",
            "        [ 1.9779, -1.6131],\n",
            "        [ 2.4461, -1.7311],\n",
            "        [ 2.0930, -1.4828],\n",
            "        [ 2.2568, -1.4796],\n",
            "        [ 2.4037, -1.8763],\n",
            "        [ 2.5487, -1.9415],\n",
            "        [ 2.0490, -1.5347],\n",
            "        [ 2.3276, -1.6667]], grad_fn=<MmBackward0>), tensor([[ 2.0193, -3.5980],\n",
            "        [ 1.7797, -3.2554],\n",
            "        [ 1.8865, -3.2540],\n",
            "        [ 1.7953, -3.4788],\n",
            "        [ 1.6276, -3.1014],\n",
            "        [ 1.9699, -3.4260],\n",
            "        [ 1.9961, -3.5594],\n",
            "        [ 1.9195, -3.6677],\n",
            "        [ 1.7494, -3.2949],\n",
            "        [ 1.7796, -3.3538]], grad_fn=<MmBackward0>), tensor([[ 3.5363, -2.1255],\n",
            "        [ 3.1676, -1.7117],\n",
            "        [ 3.1257, -1.7529],\n",
            "        [ 3.4451, -1.8929],\n",
            "        [ 3.1931, -1.6597],\n",
            "        [ 3.3991, -1.9496],\n",
            "        [ 3.5837, -1.9967],\n",
            "        [ 3.5546, -1.9735],\n",
            "        [ 3.2212, -1.9481],\n",
            "        [ 3.1981, -1.8570]], grad_fn=<MmBackward0>), tensor([[ 4.2175, -3.2465],\n",
            "        [ 4.1158, -2.8033],\n",
            "        [ 3.7323, -2.8111],\n",
            "        [ 4.2055, -3.1175],\n",
            "        [ 3.5682, -2.6696],\n",
            "        [ 4.1723, -2.9723],\n",
            "        [ 4.3134, -3.2172],\n",
            "        [ 4.3013, -3.3796],\n",
            "        [ 3.9134, -2.8842],\n",
            "        [ 3.9490, -3.0044]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.3074, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.3797, -3.4762],\n",
            "        [ 2.3793, -3.2479],\n",
            "        [ 2.4475, -3.5254],\n",
            "        [ 2.5047, -3.4286],\n",
            "        [ 2.4821, -3.4856],\n",
            "        [ 2.3544, -3.3411],\n",
            "        [ 2.2028, -2.9972],\n",
            "        [ 2.2678, -3.3000],\n",
            "        [ 2.2519, -3.2973],\n",
            "        [ 2.5528, -3.5436]], grad_fn=<MmBackward0>), tensor([[ 2.4731, -1.5992],\n",
            "        [ 2.2644, -1.5366],\n",
            "        [ 2.3369, -1.8496],\n",
            "        [ 2.2448, -1.6367],\n",
            "        [ 2.3497, -1.6887],\n",
            "        [ 2.2288, -1.6309],\n",
            "        [ 2.0039, -1.4771],\n",
            "        [ 2.1315, -1.7021],\n",
            "        [ 2.1941, -1.5653],\n",
            "        [ 2.2914, -1.7665]], grad_fn=<MmBackward0>), tensor([[ 1.8535, -3.5165],\n",
            "        [ 1.7518, -3.3246],\n",
            "        [ 1.9818, -3.4731],\n",
            "        [ 1.8143, -3.5620],\n",
            "        [ 1.9350, -3.4411],\n",
            "        [ 1.7425, -3.4904],\n",
            "        [ 1.6662, -3.0244],\n",
            "        [ 1.6274, -3.3231],\n",
            "        [ 1.8179, -3.4374],\n",
            "        [ 1.7991, -3.6623]], grad_fn=<MmBackward0>), tensor([[ 3.3538, -1.9751],\n",
            "        [ 3.2625, -1.8319],\n",
            "        [ 3.4492, -2.0464],\n",
            "        [ 3.4008, -1.9485],\n",
            "        [ 3.5128, -2.1407],\n",
            "        [ 3.4683, -1.9951],\n",
            "        [ 3.1628, -1.7461],\n",
            "        [ 3.2198, -1.8935],\n",
            "        [ 3.3570, -1.8060],\n",
            "        [ 3.6509, -2.0896]], grad_fn=<MmBackward0>), tensor([[ 4.1361, -3.0863],\n",
            "        [ 4.0793, -3.0029],\n",
            "        [ 4.1520, -3.2185],\n",
            "        [ 4.2467, -3.0734],\n",
            "        [ 4.3002, -3.1732],\n",
            "        [ 4.2424, -3.0407],\n",
            "        [ 3.7494, -2.8003],\n",
            "        [ 3.9885, -2.9863],\n",
            "        [ 4.1390, -3.0477],\n",
            "        [ 4.4557, -3.3547]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.4110, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.5321, -3.5678],\n",
            "        [ 2.2736, -3.3984],\n",
            "        [ 2.4611, -3.7167],\n",
            "        [ 2.2194, -2.9931],\n",
            "        [ 2.4622, -3.3781],\n",
            "        [ 2.3045, -3.3557],\n",
            "        [ 2.1473, -3.0424],\n",
            "        [ 2.2533, -3.1479],\n",
            "        [ 2.3185, -3.1588],\n",
            "        [ 2.3190, -3.1233]], grad_fn=<MmBackward0>), tensor([[ 2.2385, -1.5694],\n",
            "        [ 2.2453, -1.5399],\n",
            "        [ 2.2100, -1.5611],\n",
            "        [ 1.9579, -1.1996],\n",
            "        [ 2.1619, -1.5717],\n",
            "        [ 2.0854, -1.5685],\n",
            "        [ 1.9800, -1.4165],\n",
            "        [ 2.0476, -1.4046],\n",
            "        [ 2.0503, -1.3631],\n",
            "        [ 2.1176, -1.3460]], grad_fn=<MmBackward0>), tensor([[ 1.8410, -3.6360],\n",
            "        [ 1.7050, -3.4237],\n",
            "        [ 1.8734, -3.6062],\n",
            "        [ 1.5348, -2.8685],\n",
            "        [ 1.6775, -3.3878],\n",
            "        [ 1.8251, -3.2634],\n",
            "        [ 1.5694, -2.9796],\n",
            "        [ 1.5236, -3.2152],\n",
            "        [ 1.6439, -3.2083],\n",
            "        [ 1.7489, -2.9325]], grad_fn=<MmBackward0>), tensor([[ 3.5784, -2.0396],\n",
            "        [ 3.5646, -2.0031],\n",
            "        [ 3.6164, -2.1087],\n",
            "        [ 3.0286, -1.7182],\n",
            "        [ 3.5026, -1.9495],\n",
            "        [ 3.3962, -2.0012],\n",
            "        [ 3.0751, -1.7686],\n",
            "        [ 3.1404, -1.8451],\n",
            "        [ 3.4003, -1.9982],\n",
            "        [ 3.1272, -1.8338]], grad_fn=<MmBackward0>), tensor([[ 4.2731, -3.3928],\n",
            "        [ 4.1664, -2.9823],\n",
            "        [ 4.4394, -3.2226],\n",
            "        [ 3.6812, -2.7431],\n",
            "        [ 4.1598, -3.2195],\n",
            "        [ 4.1162, -3.1333],\n",
            "        [ 3.7279, -2.6077],\n",
            "        [ 4.0953, -2.9617],\n",
            "        [ 4.0487, -2.9929],\n",
            "        [ 3.8249, -2.9796]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.1337, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.7702, -3.6603],\n",
            "        [ 2.3775, -3.2177],\n",
            "        [ 2.4218, -3.2658],\n",
            "        [ 2.2949, -3.0199],\n",
            "        [ 2.4446, -3.2908],\n",
            "        [ 2.3093, -2.8698],\n",
            "        [ 2.4653, -3.5452],\n",
            "        [ 2.5402, -3.5619],\n",
            "        [ 2.5103, -3.3329],\n",
            "        [ 2.5193, -3.3104]], grad_fn=<MmBackward0>), tensor([[ 2.1863, -1.4863],\n",
            "        [ 1.9841, -1.2916],\n",
            "        [ 2.0560, -1.4996],\n",
            "        [ 1.7454, -1.1809],\n",
            "        [ 2.0951, -1.4006],\n",
            "        [ 1.8630, -1.3738],\n",
            "        [ 2.1287, -1.5424],\n",
            "        [ 2.1683, -1.6008],\n",
            "        [ 1.9068, -1.3554],\n",
            "        [ 2.0545, -1.5558]], grad_fn=<MmBackward0>), tensor([[ 1.7406, -3.5832],\n",
            "        [ 1.5195, -3.0937],\n",
            "        [ 1.8223, -3.3052],\n",
            "        [ 1.3855, -2.8536],\n",
            "        [ 1.7782, -3.1696],\n",
            "        [ 1.4311, -2.8130],\n",
            "        [ 1.7510, -3.3781],\n",
            "        [ 1.7824, -3.4297],\n",
            "        [ 1.6315, -3.3186],\n",
            "        [ 1.6902, -3.2262]], grad_fn=<MmBackward0>), tensor([[ 3.7620, -2.2395],\n",
            "        [ 3.2363, -1.8125],\n",
            "        [ 3.4122, -1.8725],\n",
            "        [ 3.0223, -1.8033],\n",
            "        [ 3.4726, -1.9910],\n",
            "        [ 3.1607, -1.7303],\n",
            "        [ 3.5734, -1.8937],\n",
            "        [ 3.7074, -2.1371],\n",
            "        [ 3.5206, -1.9726],\n",
            "        [ 3.4891, -1.9677]], grad_fn=<MmBackward0>), tensor([[ 4.4078, -3.2009],\n",
            "        [ 4.1319, -3.0159],\n",
            "        [ 4.0937, -3.2123],\n",
            "        [ 3.8108, -2.7582],\n",
            "        [ 3.9663, -3.0713],\n",
            "        [ 3.8131, -2.8080],\n",
            "        [ 4.1137, -3.1876],\n",
            "        [ 4.1001, -3.2869],\n",
            "        [ 4.2499, -3.0995],\n",
            "        [ 4.1887, -3.1199]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.8035, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.5145, -3.4888],\n",
            "        [ 2.4346, -3.5801],\n",
            "        [ 2.2411, -3.0853],\n",
            "        [ 2.2627, -3.1753],\n",
            "        [ 2.6622, -3.5295],\n",
            "        [ 2.2041, -2.9107],\n",
            "        [ 2.3725, -3.3606],\n",
            "        [ 2.5928, -3.2123],\n",
            "        [ 2.3681, -3.3292],\n",
            "        [ 2.5202, -3.4818]], grad_fn=<MmBackward0>), tensor([[ 2.0751, -1.4523],\n",
            "        [ 1.9668, -1.4833],\n",
            "        [ 1.7443, -1.1396],\n",
            "        [ 1.8643, -1.4472],\n",
            "        [ 2.1145, -1.5545],\n",
            "        [ 1.6896, -1.1121],\n",
            "        [ 1.9376, -1.3479],\n",
            "        [ 1.8505, -1.2696],\n",
            "        [ 1.8620, -1.2436],\n",
            "        [ 2.0074, -1.4948]], grad_fn=<MmBackward0>), tensor([[ 1.5599, -3.2840],\n",
            "        [ 1.7072, -3.1149],\n",
            "        [ 1.5330, -2.6903],\n",
            "        [ 1.7055, -3.0066],\n",
            "        [ 1.5721, -3.4784],\n",
            "        [ 1.3960, -2.7573],\n",
            "        [ 1.4649, -2.9151],\n",
            "        [ 1.6125, -3.0065],\n",
            "        [ 1.5484, -2.9968],\n",
            "        [ 1.4736, -3.3509]], grad_fn=<MmBackward0>), tensor([[ 3.4337, -2.0977],\n",
            "        [ 3.3868, -2.1218],\n",
            "        [ 2.9636, -1.8204],\n",
            "        [ 3.3483, -1.8869],\n",
            "        [ 3.7114, -2.0669],\n",
            "        [ 3.0487, -1.7261],\n",
            "        [ 3.2667, -1.9712],\n",
            "        [ 3.2392, -1.9791],\n",
            "        [ 3.3559, -1.9313],\n",
            "        [ 3.4577, -2.0713]], grad_fn=<MmBackward0>), tensor([[ 4.3486, -3.2037],\n",
            "        [ 4.2334, -3.2878],\n",
            "        [ 3.7647, -2.6937],\n",
            "        [ 4.0774, -2.9899],\n",
            "        [ 4.4310, -3.2820],\n",
            "        [ 3.5028, -2.5850],\n",
            "        [ 3.9228, -2.9568],\n",
            "        [ 3.9895, -3.0001],\n",
            "        [ 4.0074, -2.9885],\n",
            "        [ 4.2243, -3.2941]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.9107, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.2496, -3.1368],\n",
            "        [ 2.4773, -3.5078],\n",
            "        [ 2.4407, -3.1935],\n",
            "        [ 2.6452, -3.4363],\n",
            "        [ 2.6091, -3.5486],\n",
            "        [ 2.3188, -3.1496],\n",
            "        [ 2.1953, -3.0405],\n",
            "        [ 2.0670, -2.9565],\n",
            "        [ 2.3939, -3.4667],\n",
            "        [ 2.6037, -3.6508]], grad_fn=<MmBackward0>), tensor([[ 1.7563, -1.3777],\n",
            "        [ 1.8021, -1.4175],\n",
            "        [ 1.8388, -1.1844],\n",
            "        [ 2.1688, -1.3916],\n",
            "        [ 2.0405, -1.2972],\n",
            "        [ 1.8569, -1.5217],\n",
            "        [ 1.5441, -1.1483],\n",
            "        [ 1.5096, -1.1557],\n",
            "        [ 2.1666, -1.3649],\n",
            "        [ 1.9103, -1.2741]], grad_fn=<MmBackward0>), tensor([[ 1.5334, -2.9168],\n",
            "        [ 1.6274, -3.0763],\n",
            "        [ 1.4698, -2.9917],\n",
            "        [ 1.6566, -3.2041],\n",
            "        [ 1.5587, -3.3466],\n",
            "        [ 1.3420, -2.9003],\n",
            "        [ 1.2916, -2.6252],\n",
            "        [ 1.3796, -2.7857],\n",
            "        [ 1.5404, -3.1938],\n",
            "        [ 1.5084, -3.3112]], grad_fn=<MmBackward0>), tensor([[ 3.2746, -1.8841],\n",
            "        [ 3.5841, -2.0100],\n",
            "        [ 3.3185, -1.8898],\n",
            "        [ 3.6420, -2.0860],\n",
            "        [ 3.6371, -2.1183],\n",
            "        [ 3.3392, -1.9059],\n",
            "        [ 2.8653, -1.7519],\n",
            "        [ 3.0010, -1.7111],\n",
            "        [ 3.3866, -2.0771],\n",
            "        [ 3.7079, -2.1173]], grad_fn=<MmBackward0>), tensor([[ 4.0233, -2.9405],\n",
            "        [ 4.1570, -3.3006],\n",
            "        [ 4.0268, -3.0906],\n",
            "        [ 4.2846, -3.1940],\n",
            "        [ 4.2831, -3.2836],\n",
            "        [ 3.9096, -2.9849],\n",
            "        [ 3.5230, -2.5821],\n",
            "        [ 3.5671, -2.7399],\n",
            "        [ 4.3224, -3.2521],\n",
            "        [ 4.3675, -3.2648]], grad_fn=<MmBackward0>))\n",
            "tensor([[1, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
            "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]])\n",
            "tensor(2.8797, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.5136, -3.5038],\n",
            "        [ 2.3216, -3.3111],\n",
            "        [ 2.1087, -2.9366],\n",
            "        [ 2.5198, -3.4788],\n",
            "        [ 2.4425, -3.5751],\n",
            "        [ 2.4332, -3.5050],\n",
            "        [ 2.4120, -3.0859],\n",
            "        [ 2.3688, -2.9752],\n",
            "        [ 2.1448, -3.0850],\n",
            "        [ 2.0477, -2.8188]], grad_fn=<MmBackward0>), tensor([[ 1.9385, -1.2613],\n",
            "        [ 1.7419, -1.3038],\n",
            "        [ 1.5334, -0.9671],\n",
            "        [ 1.9320, -1.3183],\n",
            "        [ 1.9090, -1.2711],\n",
            "        [ 1.9945, -1.2341],\n",
            "        [ 1.7513, -1.0197],\n",
            "        [ 1.7113, -1.0307],\n",
            "        [ 1.5101, -0.9038],\n",
            "        [ 1.6135, -1.0054]], grad_fn=<MmBackward0>), tensor([[ 1.4778, -3.1934],\n",
            "        [ 1.2409, -3.0333],\n",
            "        [ 1.2637, -2.6318],\n",
            "        [ 1.4747, -3.2381],\n",
            "        [ 1.4309, -3.0868],\n",
            "        [ 1.4965, -3.0776],\n",
            "        [ 1.3015, -2.9316],\n",
            "        [ 1.3649, -2.8145],\n",
            "        [ 1.3424, -2.6185],\n",
            "        [ 1.0948, -2.6994]], grad_fn=<MmBackward0>), tensor([[ 3.6778, -2.0422],\n",
            "        [ 3.3700, -1.7882],\n",
            "        [ 3.0318, -1.6019],\n",
            "        [ 3.7073, -2.1489],\n",
            "        [ 3.5607, -2.1700],\n",
            "        [ 3.5544, -1.9718],\n",
            "        [ 3.2174, -1.9069],\n",
            "        [ 3.0936, -1.8449],\n",
            "        [ 2.9708, -1.7082],\n",
            "        [ 3.1866, -1.8084]], grad_fn=<MmBackward0>), tensor([[ 4.3460, -3.1080],\n",
            "        [ 4.0006, -3.1128],\n",
            "        [ 3.8063, -2.6698],\n",
            "        [ 4.2789, -3.2354],\n",
            "        [ 4.1635, -3.2552],\n",
            "        [ 4.1796, -3.1586],\n",
            "        [ 4.1403, -2.7848],\n",
            "        [ 3.9064, -2.7792],\n",
            "        [ 3.8480, -2.7273],\n",
            "        [ 3.6959, -2.7477]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.1026, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.3748, -3.2304],\n",
            "        [ 2.4439, -3.5326],\n",
            "        [ 2.3698, -3.4892],\n",
            "        [ 2.0643, -2.8758],\n",
            "        [ 2.0762, -2.8228],\n",
            "        [ 2.5239, -3.3666],\n",
            "        [ 2.3891, -3.5195],\n",
            "        [ 2.4563, -3.2384],\n",
            "        [ 2.4627, -3.4393],\n",
            "        [ 2.3293, -3.3348]], grad_fn=<MmBackward0>), tensor([[ 1.5871, -1.0537],\n",
            "        [ 1.7999, -1.2631],\n",
            "        [ 1.7706, -1.3333],\n",
            "        [ 1.6580, -0.9879],\n",
            "        [ 1.5189, -1.0485],\n",
            "        [ 1.8012, -1.2353],\n",
            "        [ 1.7028, -1.3306],\n",
            "        [ 1.8481, -1.1755],\n",
            "        [ 1.8559, -1.2426],\n",
            "        [ 1.5351, -1.1986]], grad_fn=<MmBackward0>), tensor([[ 1.2631, -2.9482],\n",
            "        [ 1.4620, -3.0944],\n",
            "        [ 1.3850, -3.1416],\n",
            "        [ 1.1754, -2.4915],\n",
            "        [ 1.1274, -2.4950],\n",
            "        [ 1.3930, -3.0408],\n",
            "        [ 1.6947, -3.0462],\n",
            "        [ 1.1698, -2.9050],\n",
            "        [ 1.3287, -3.0211],\n",
            "        [ 1.3509, -2.8631]], grad_fn=<MmBackward0>), tensor([[ 3.3553, -1.9992],\n",
            "        [ 3.5791, -2.0597],\n",
            "        [ 3.5982, -2.0384],\n",
            "        [ 2.8336, -1.7509],\n",
            "        [ 2.9287, -1.7320],\n",
            "        [ 3.4694, -1.9252],\n",
            "        [ 3.4739, -2.0036],\n",
            "        [ 3.2767, -1.9901],\n",
            "        [ 3.5019, -2.0664],\n",
            "        [ 3.3453, -1.8366]], grad_fn=<MmBackward0>), tensor([[ 4.1510, -3.1250],\n",
            "        [ 4.2455, -3.3010],\n",
            "        [ 4.1631, -3.2585],\n",
            "        [ 3.6997, -2.5931],\n",
            "        [ 3.4993, -2.7610],\n",
            "        [ 4.1889, -3.0814],\n",
            "        [ 4.3236, -3.3299],\n",
            "        [ 4.1768, -3.0143],\n",
            "        [ 4.2144, -3.1151],\n",
            "        [ 4.1566, -3.1617]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])\n",
            "tensor(0.8074, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.4701, -3.3581],\n",
            "        [ 2.1816, -3.1200],\n",
            "        [ 2.2982, -3.3258],\n",
            "        [ 2.1966, -3.1422],\n",
            "        [ 1.9542, -2.7616],\n",
            "        [ 2.4219, -3.4207],\n",
            "        [ 2.5647, -3.3711],\n",
            "        [ 2.3302, -3.3758],\n",
            "        [ 2.4081, -3.3107],\n",
            "        [ 2.2256, -3.0486]], grad_fn=<MmBackward0>), tensor([[ 1.6149, -0.9727],\n",
            "        [ 1.4695, -0.8949],\n",
            "        [ 1.7541, -1.1251],\n",
            "        [ 1.4341, -1.0179],\n",
            "        [ 1.3794, -0.8032],\n",
            "        [ 1.8309, -1.2269],\n",
            "        [ 1.6848, -1.1976],\n",
            "        [ 1.6689, -1.0220],\n",
            "        [ 1.6732, -1.1347],\n",
            "        [ 1.6547, -0.9568]], grad_fn=<MmBackward0>), tensor([[ 1.2504, -2.8456],\n",
            "        [ 1.1178, -2.6026],\n",
            "        [ 1.4195, -2.9427],\n",
            "        [ 1.1295, -2.4915],\n",
            "        [ 0.9985, -2.1805],\n",
            "        [ 1.2634, -2.9583],\n",
            "        [ 1.3686, -2.8947],\n",
            "        [ 1.3696, -2.8629],\n",
            "        [ 1.4320, -2.7387],\n",
            "        [ 1.3484, -2.7334]], grad_fn=<MmBackward0>), tensor([[ 3.3543, -1.9753],\n",
            "        [ 3.1026, -1.8500],\n",
            "        [ 3.4673, -1.8752],\n",
            "        [ 3.2845, -1.7845],\n",
            "        [ 2.7766, -1.6625],\n",
            "        [ 3.5642, -2.0438],\n",
            "        [ 3.5106, -2.0822],\n",
            "        [ 3.4230, -2.0918],\n",
            "        [ 3.3972, -2.0030],\n",
            "        [ 3.1705, -1.7281]], grad_fn=<MmBackward0>), tensor([[ 4.2408, -2.9887],\n",
            "        [ 3.8352, -2.7911],\n",
            "        [ 4.1905, -2.9945],\n",
            "        [ 3.7747, -2.8509],\n",
            "        [ 3.1946, -2.2985],\n",
            "        [ 4.3077, -3.1762],\n",
            "        [ 4.2280, -3.0894],\n",
            "        [ 4.0802, -3.2054],\n",
            "        [ 4.1937, -3.1702],\n",
            "        [ 3.8441, -3.0118]], grad_fn=<MmBackward0>))\n",
            "tensor([[1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.7228, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.2722, -3.1121],\n",
            "        [ 1.9891, -2.6993],\n",
            "        [ 2.2661, -3.2982],\n",
            "        [ 2.3649, -3.4377],\n",
            "        [ 2.5269, -3.4401],\n",
            "        [ 2.3436, -3.1421],\n",
            "        [ 2.3208, -3.0743],\n",
            "        [ 1.9966, -2.9802],\n",
            "        [ 2.4724, -3.2243],\n",
            "        [ 2.1796, -3.1040]], grad_fn=<MmBackward0>), tensor([[ 1.4564, -1.0733],\n",
            "        [ 1.3467, -0.5411],\n",
            "        [ 1.6779, -1.0371],\n",
            "        [ 1.6177, -0.8438],\n",
            "        [ 1.7244, -0.9936],\n",
            "        [ 1.6463, -0.8653],\n",
            "        [ 1.4607, -0.9407],\n",
            "        [ 1.3393, -1.0192],\n",
            "        [ 1.5928, -1.0445],\n",
            "        [ 1.5443, -0.9547]], grad_fn=<MmBackward0>), tensor([[ 1.3091, -2.7633],\n",
            "        [ 0.9736, -2.3275],\n",
            "        [ 1.1411, -2.8482],\n",
            "        [ 1.2209, -2.9281],\n",
            "        [ 1.2512, -2.9385],\n",
            "        [ 1.1846, -2.7604],\n",
            "        [ 1.1869, -2.4480],\n",
            "        [ 1.1245, -2.5321],\n",
            "        [ 1.2032, -2.9786],\n",
            "        [ 1.1375, -2.6045]], grad_fn=<MmBackward0>), tensor([[ 3.2063, -1.8115],\n",
            "        [ 2.9398, -1.4786],\n",
            "        [ 3.3483, -1.9094],\n",
            "        [ 3.4979, -1.8912],\n",
            "        [ 3.4137, -2.0730],\n",
            "        [ 3.2093, -1.9459],\n",
            "        [ 3.0757, -1.6728],\n",
            "        [ 3.2214, -1.8140],\n",
            "        [ 3.6500, -1.9800],\n",
            "        [ 3.0605, -1.7693]], grad_fn=<MmBackward0>), tensor([[ 4.0180, -3.0505],\n",
            "        [ 3.5274, -2.5125],\n",
            "        [ 4.0860, -3.0995],\n",
            "        [ 4.1140, -3.0823],\n",
            "        [ 4.3707, -3.0969],\n",
            "        [ 4.0066, -2.9291],\n",
            "        [ 3.8356, -2.6567],\n",
            "        [ 3.7931, -2.9282],\n",
            "        [ 4.2701, -3.1908],\n",
            "        [ 3.7634, -2.9257]], grad_fn=<MmBackward0>))\n",
            "tensor([[1, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0]])\n",
            "tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(1.6067, grad_fn=<AddBackward0>)\n",
            "(tensor([[ 2.1779, -3.0647],\n",
            "        [ 2.1916, -3.2340],\n",
            "        [ 2.2757, -3.2814],\n",
            "        [ 2.1402, -3.0993],\n",
            "        [ 2.2015, -3.1990],\n",
            "        [ 2.2868, -3.2276],\n",
            "        [ 2.1325, -3.0794],\n",
            "        [ 2.0577, -2.9094],\n",
            "        [ 2.4051, -3.2472],\n",
            "        [ 2.1614, -3.0942]], grad_fn=<MmBackward0>), tensor([[ 1.5371, -0.8538],\n",
            "        [ 1.6156, -1.0323],\n",
            "        [ 1.5018, -0.9398],\n",
            "        [ 1.4790, -0.9613],\n",
            "        [ 1.5336, -0.8522],\n",
            "        [ 1.4318, -0.9269],\n",
            "        [ 1.4767, -1.0049],\n",
            "        [ 1.5006, -0.8196],\n",
            "        [ 1.5587, -1.0374],\n",
            "        [ 1.4635, -0.8127]], grad_fn=<MmBackward0>), tensor([[ 1.1921, -2.6295],\n",
            "        [ 1.2048, -2.8254],\n",
            "        [ 1.2797, -2.8677],\n",
            "        [ 1.2436, -2.6540],\n",
            "        [ 1.0512, -2.8419],\n",
            "        [ 1.2281, -2.7954],\n",
            "        [ 1.1939, -2.6776],\n",
            "        [ 1.0354, -2.6575],\n",
            "        [ 1.2159, -2.8916],\n",
            "        [ 1.1623, -2.7611]], grad_fn=<MmBackward0>), tensor([[ 2.9941, -1.8225],\n",
            "        [ 3.3079, -1.7748],\n",
            "        [ 3.3226, -1.9951],\n",
            "        [ 3.4179, -1.8517],\n",
            "        [ 3.3734, -1.9206],\n",
            "        [ 3.5228, -1.8622],\n",
            "        [ 3.5316, -1.8891],\n",
            "        [ 3.1874, -1.8079],\n",
            "        [ 3.5030, -2.0124],\n",
            "        [ 3.4720, -1.9852]], grad_fn=<MmBackward0>), tensor([[ 3.8107, -2.8744],\n",
            "        [ 3.9946, -3.0137],\n",
            "        [ 4.1365, -3.0212],\n",
            "        [ 4.0797, -3.0556],\n",
            "        [ 4.0553, -3.0165],\n",
            "        [ 3.9682, -3.1009],\n",
            "        [ 3.9894, -3.0565],\n",
            "        [ 3.9268, -2.8548],\n",
            "        [ 4.1950, -3.0885],\n",
            "        [ 4.0071, -3.0149]], grad_fn=<MmBackward0>))\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor(0.1150, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-1341ef3fd603>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerMultipleClasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-ddc427cd449b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_iter, test_iter)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mresult_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-ddc427cd449b>\u001b[0m in \u001b[0;36m_train_one_epoch\u001b[0;34m(self, epoch_index, train_iter)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}