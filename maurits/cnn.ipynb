{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QrywNfRlazm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92145e57-fecf-4d3d-f967-7db929a27944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grs34806-deep-learning-project-data' already exists and is not an empty directory.\n",
            "fatal: destination path 'GRS34806-project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "from functools import total_ordering\n",
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "SEpH6j4dbJuO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "DzPLAugMwzCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    random.shuffle(datalist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal(reduced_datalist: list, compared_datalist: list):\n",
        "    random.shuffle(reduced_datalist)\n",
        "    random.shuffle(compared_datalist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load paired data"
      ],
      "metadata": {
        "id": "iFc0lo8vw291"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "# Example for one of the simulated datasets\n",
        "datalist, labellist = read(\"expr5Tseq_filtGO_100-1000.lis\", \"GO_3A0055085.annotprot\")\n",
        "# datalist, labellist = read(\"len200_500_n5000nr4.seq\", \"len200_500_n5000nr4.pos\")\n",
        "\n",
        "# Remove negatives\n",
        "pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "neg_datalist = remove_sequences(neg_datalist, 0.1)\n",
        "# neg_datalist = remove_sequences_equal(neg_datalist, pos_datalist)\n",
        "datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.6)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(next(iter(train_iter)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "f1c95394-7b3d-4437-dcf8-b24612711c9e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0,  5,  ..., 20, 20, 20],\n",
            "        [10, 12,  5,  ..., 20, 20, 20],\n",
            "        [10, 16,  0,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10, 15,  5,  ..., 20, 20, 20],\n",
            "        [10,  0,  0,  ..., 20, 20, 20],\n",
            "        [10, 14,  8,  ..., 20, 20, 20]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in datalist:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for l in labellist:\n",
        "    if l:\n",
        "        p += 1\n",
        "    else:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "26FSv9_pGhWY",
        "outputId": "e88452e7-3074-4da9-e214-0aaf4aaf0a9c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 226\n",
            "n = 656\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train functions binary classifier"
      ],
      "metadata": {
        "id": "reETSGvLw6-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, epoch_index, train_iter):\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        result_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            result_loss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                if o == l:\n",
        "                    correct_predictions += 1\n",
        "                total_predictions += 1\n",
        "        return correct_predictions / total_predictions, result_loss / (i + 1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_acc, train_loss = self._train_one_epoch(epoch, train_iter)\n",
        "            self.model.eval()\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "            result_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(test_iter):\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    outputs = self.model(inputs).to('cpu')\n",
        "                    loss = self.loss_fn(outputs, labels)\n",
        "                    result_loss += loss.item()\n",
        "                    # print(f'{loss = }\\t{test_outputs = }\\t{test_labels = }')\n",
        "                    # print(f'{outputs = }')\n",
        "                    # print(f'{labels = }')\n",
        "                    for j, l in enumerate(labels):\n",
        "                        o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                        if o == l:\n",
        "                            correct_predictions += 1\n",
        "                        total_predictions += 1\n",
        "            test_acc = correct_predictions / total_predictions\n",
        "            test_loss = result_loss / (i + 1)\n",
        "            print(f'{epoch = }\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{train_loss=:.5f}\\t{test_loss=:.5f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3Btdmdhj36zM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimal model (does not work)"
      ],
      "metadata": {
        "id": "I2n78bgjw-uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MinimalGOClassifierCNN(nn.Module):\n",
        "    def __init__(self, input_length: int, vocab_size : int=21,  num_filters: int=32, kernel_size: int=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=num_filters, kernel_size=kernel_size),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.conv_layer(x.transpose(1,2))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        output = F.softmax(x, 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6Agj87Dpbf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Berry's model (works, go to for binary classification)"
      ],
      "metadata": {
        "id": "1wX4qCXZxCzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BerryCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba7ab6f-35a9-40e8-f6bd-89a1375e8725",
        "id": "-kFRoPlYpeKe"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BerryCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "trainer.train(epochs=50, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "id": "AMz0guzKptRZ",
        "outputId": "5a0b0efe-175c-442f-8c86-9a6a968d9610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_acc=0.67486\ttest_acc=0.76771\ttrain_loss=0.67153\ttest_loss=0.55312\n",
            "epoch = 1\ttrain_acc=0.72779\ttest_acc=0.76771\ttrain_loss=0.58531\ttest_loss=0.55357\n",
            "epoch = 2\ttrain_acc=0.72779\ttest_acc=0.76771\ttrain_loss=0.57461\ttest_loss=0.53619\n",
            "epoch = 3\ttrain_acc=0.72779\ttest_acc=0.76771\ttrain_loss=0.55908\ttest_loss=0.54608\n",
            "epoch = 4\ttrain_acc=0.73346\ttest_acc=0.76771\ttrain_loss=0.53820\ttest_loss=0.54174\n",
            "epoch = 5\ttrain_acc=0.72779\ttest_acc=0.76771\ttrain_loss=0.52629\ttest_loss=0.53132\n",
            "epoch = 6\ttrain_acc=0.72968\ttest_acc=0.76771\ttrain_loss=0.51555\ttest_loss=0.51964\n",
            "epoch = 7\ttrain_acc=0.75425\ttest_acc=0.76771\ttrain_loss=0.49306\ttest_loss=0.51097\n",
            "epoch = 8\ttrain_acc=0.73535\ttest_acc=0.76771\ttrain_loss=0.47346\ttest_loss=0.52756\n",
            "epoch = 9\ttrain_acc=0.77505\ttest_acc=0.76771\ttrain_loss=0.46510\ttest_loss=0.50075\n",
            "epoch = 10\ttrain_acc=0.80907\ttest_acc=0.76771\ttrain_loss=0.43284\ttest_loss=0.49114\n",
            "epoch = 11\ttrain_acc=0.79773\ttest_acc=0.76771\ttrain_loss=0.40321\ttest_loss=0.47690\n",
            "epoch = 12\ttrain_acc=0.84499\ttest_acc=0.76771\ttrain_loss=0.38625\ttest_loss=0.49768\n",
            "epoch = 13\ttrain_acc=0.83554\ttest_acc=0.81870\ttrain_loss=0.35679\ttest_loss=0.54749\n",
            "epoch = 14\ttrain_acc=0.88280\ttest_acc=0.76771\ttrain_loss=0.35474\ttest_loss=0.46919\n",
            "epoch = 15\ttrain_acc=0.90548\ttest_acc=0.81303\ttrain_loss=0.30485\ttest_loss=0.45033\n",
            "epoch = 16\ttrain_acc=0.92628\ttest_acc=0.76771\ttrain_loss=0.28166\ttest_loss=0.46762\n",
            "epoch = 17\ttrain_acc=0.91682\ttest_acc=0.85552\ttrain_loss=0.27126\ttest_loss=0.45420\n",
            "epoch = 18\ttrain_acc=0.95085\ttest_acc=0.83569\ttrain_loss=0.24190\ttest_loss=0.44039\n",
            "epoch = 19\ttrain_acc=0.95841\ttest_acc=0.80737\ttrain_loss=0.21991\ttest_loss=0.42374\n",
            "epoch = 20\ttrain_acc=0.97164\ttest_acc=0.83853\ttrain_loss=0.20232\ttest_loss=0.41504\n",
            "epoch = 21\ttrain_acc=0.97732\ttest_acc=0.79887\ttrain_loss=0.18622\ttest_loss=0.42955\n",
            "epoch = 22\ttrain_acc=0.98866\ttest_acc=0.85269\ttrain_loss=0.16721\ttest_loss=0.44668\n",
            "epoch = 23\ttrain_acc=0.98677\ttest_acc=0.82720\ttrain_loss=0.15792\ttest_loss=0.41145\n",
            "epoch = 24\ttrain_acc=0.99055\ttest_acc=0.86402\ttrain_loss=0.15560\ttest_loss=0.41178\n",
            "epoch = 25\ttrain_acc=0.99811\ttest_acc=0.82720\ttrain_loss=0.12744\ttest_loss=0.40728\n",
            "epoch = 26\ttrain_acc=0.99811\ttest_acc=0.79887\ttrain_loss=0.12017\ttest_loss=0.44513\n",
            "epoch = 27\ttrain_acc=0.99622\ttest_acc=0.84986\ttrain_loss=0.10917\ttest_loss=0.40082\n",
            "epoch = 28\ttrain_acc=0.99811\ttest_acc=0.84136\ttrain_loss=0.09978\ttest_loss=0.40008\n",
            "epoch = 29\ttrain_acc=0.99811\ttest_acc=0.83569\ttrain_loss=0.08925\ttest_loss=0.41049\n",
            "epoch = 30\ttrain_acc=0.99811\ttest_acc=0.84136\ttrain_loss=0.08289\ttest_loss=0.39699\n",
            "epoch = 31\ttrain_acc=1.00000\ttest_acc=0.82436\ttrain_loss=0.07615\ttest_loss=0.42785\n",
            "epoch = 32\ttrain_acc=1.00000\ttest_acc=0.86686\ttrain_loss=0.07300\ttest_loss=0.41142\n",
            "epoch = 33\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.06695\ttest_loss=0.40223\n",
            "epoch = 34\ttrain_acc=1.00000\ttest_acc=0.84136\ttrain_loss=0.06335\ttest_loss=0.41025\n",
            "epoch = 35\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.05878\ttest_loss=0.40340\n",
            "epoch = 36\ttrain_acc=1.00000\ttest_acc=0.84136\ttrain_loss=0.05457\ttest_loss=0.40046\n",
            "epoch = 37\ttrain_acc=1.00000\ttest_acc=0.83569\ttrain_loss=0.05104\ttest_loss=0.41069\n",
            "epoch = 38\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.04823\ttest_loss=0.41450\n",
            "epoch = 39\ttrain_acc=1.00000\ttest_acc=0.86402\ttrain_loss=0.04412\ttest_loss=0.38575\n",
            "epoch = 40\ttrain_acc=1.00000\ttest_acc=0.84136\ttrain_loss=0.04231\ttest_loss=0.39306\n",
            "epoch = 41\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.03931\ttest_loss=0.40222\n",
            "epoch = 42\ttrain_acc=1.00000\ttest_acc=0.84136\ttrain_loss=0.03797\ttest_loss=0.39709\n",
            "epoch = 43\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.03521\ttest_loss=0.42329\n",
            "epoch = 44\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.03340\ttest_loss=0.42615\n",
            "epoch = 45\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.03248\ttest_loss=0.41769\n",
            "epoch = 46\ttrain_acc=1.00000\ttest_acc=0.84419\ttrain_loss=0.03038\ttest_loss=0.41408\n",
            "epoch = 47\ttrain_acc=1.00000\ttest_acc=0.83569\ttrain_loss=0.02862\ttest_loss=0.43617\n",
            "epoch = 48\ttrain_acc=1.00000\ttest_acc=0.83853\ttrain_loss=0.02936\ttest_loss=0.43802\n",
            "epoch = 49\ttrain_acc=1.00000\ttest_acc=0.84136\ttrain_loss=0.02637\ttest_loss=0.40474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra convolutional layer (does not improve)"
      ],
      "metadata": {
        "id": "_dsG7ooLxI2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MoreCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # conv block 3\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "M6H_ib65yCPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MoreCNN1D(context_size=num_steps, conv_channels=128)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBZC4GHeLUHz",
        "outputId": "4cb3b9e9-935f-47da-e0d0-d87df22ab1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MoreCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=2, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, loss_fn, optimizer)\n",
        "trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fh2DuxL8e7n",
        "outputId": "3f6296b1-1e39-4491-b330-d21c3136e2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.35404\ttest_loss=0.33095\n",
            "epoch = 1\ttrain_loss=0.33558\ttest_loss=0.32332\n",
            "epoch = 2\ttrain_loss=0.32925\ttest_loss=0.32346\n",
            "epoch = 3\ttrain_loss=0.31973\ttest_loss=0.31417\n",
            "epoch = 4\ttrain_loss=0.30916\ttest_loss=0.32241\n",
            "epoch = 5\ttrain_loss=0.30079\ttest_loss=0.30237\n",
            "epoch = 6\ttrain_loss=0.28817\ttest_loss=0.29379\n",
            "epoch = 7\ttrain_loss=0.27623\ttest_loss=0.28432\n",
            "epoch = 8\ttrain_loss=0.25552\ttest_loss=0.27249\n",
            "epoch = 9\ttrain_loss=0.23447\ttest_loss=0.29422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data multiple labels"
      ],
      "metadata": {
        "id": "i1r1FMrdxNj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_multiple_pos(seqfile: str, posfiles: list[str]) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfiles: files with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with integer labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append([0 for _ in posfiles])\n",
        "    for l, posfile in enumerate(posfiles):\n",
        "        with open(posfile, 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                id = line.rstrip()\n",
        "                try:\n",
        "                    i = idlist.index(id)\n",
        "                    # if labellist[i] != 0:\n",
        "                    #     raise Exception(f'Sequence with multiple labels. {id = }, {labellist[i] = }, {l = }')\n",
        "                    labellist[i][l] = 1\n",
        "                except ValueError:\n",
        "                    continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "def split_labelled_multiple_pos(datalist: list, labellist: list):\n",
        "    pos_datalist = []\n",
        "    pos_labellist = []\n",
        "    neg_datalist = []\n",
        "    neg_labellist = []\n",
        "    for i, labels in enumerate(labellist):\n",
        "        is_pos = False\n",
        "        for label in labels:\n",
        "            if label:\n",
        "                is_pos = True\n",
        "        if is_pos:\n",
        "            pos_datalist.append(datalist[i])\n",
        "            pos_labellist.append(labels)\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "            neg_labellist.append(labels)\n",
        "    return pos_datalist, pos_labellist, neg_datalist, neg_labellist\n",
        "\n",
        "\n",
        "def zip_n_shuffle(list1: list, list2: list) -> tuple[list, list]:\n",
        "    assert len(list1) == len(list2)\n",
        "    combined = list(zip(list1, list2))\n",
        "    random.shuffle(combined)\n",
        "    list1, list2 = zip(*combined)\n",
        "    return list(list1), list(list2)\n",
        "\n",
        "\n",
        "def remove_sequences_multiple_pos(datalist: list, labellist, fraction=0.5):\n",
        "    datalist, labellist = zip_n_shuffle(datalist, labellist)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    return datalist[:i], labellist[:i]\n",
        "\n",
        "\n",
        "def remove_sequences_equal_multiple_pos(reduced_datalist: list, reduced_labellist: list, compared_datalist: list):\n",
        "    reduced_datalist, reduced_labellist = zip_n_shuffle(reduced_datalist, reduced_labellist)\n",
        "    reduced_datalist = reduced_datalist[:len(compared_datalist)]\n",
        "    reduced_labellist = reduced_labellist[:len(compared_datalist)]\n",
        "    if len(compared_datalist) != len(reduced_datalist) or len(compared_datalist) != len(reduced_labellist):\n",
        "        raise ValueError\n",
        "    return reduced_datalist, reduced_labellist\n",
        "\n",
        "\n",
        "def fuse_sequence_lists_multiple_pos(pos_datalist: list, pos_labellist:list, neg_datalist: list, neg_labellist):\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labellist + neg_labellist\n",
        "    return datalist, labellist"
      ],
      "metadata": {
        "id": "g9TF3MfTr1o6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer multiple labels"
      ],
      "metadata": {
        "id": "o0TJEbhQxRLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "class TrainerMultipleClasses:\n",
        "    def __init__(self, model, loss_fn, optimizer, device):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            outputs = self.model(inputs).to('cpu')\n",
        "            labels = labels.type(torch.float32)\n",
        "\n",
        "            loss = loss_fn(input=outputs, target=labels)\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "            for b, lab in enumerate(labels):\n",
        "                out = torch.round(torch.sigmoid(outputs[b]))\n",
        "\n",
        "                for j, o in enumerate(out):\n",
        "                    print(f'{o=}\\t{l=}')\n",
        "                    l = lab[j]\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "                    print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = tpos / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = 0\n",
        "        fpos = 0\n",
        "        tneg = 0\n",
        "        fneg = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels\n",
        "                outputs = self.model(inputs).to('cpu')\n",
        "                labels = labels.type(torch.float32)\n",
        "                loss = loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "                for b, lab in enumerate(labels):\n",
        "                    out = torch.round(torch.sigmoid(outputs[b]))\n",
        "                    for j, o in enumerate(out):\n",
        "                        l = lab[j]\n",
        "                        if o == 1 and l == 1:\n",
        "                            tpos += 1\n",
        "                        elif o == 1 and l == 0:\n",
        "                            fpos += 1\n",
        "                        elif o == 0 and l == 0:\n",
        "                            tneg += 1\n",
        "                        elif o == 0 and l == 1:\n",
        "                            fneg += 1\n",
        "                        else:\n",
        "                            raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "        # print(f'{tpos=}\\t{fpos=}\\t{tneg=}\\t{fneg=}')\n",
        "        accuracy = tpos / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train(True)\n",
        "            train_acc, train_prec, train_rec, train_f, train_loss = self._train_one_epoch(train_iter)\n",
        "            self.model.eval()\n",
        "            test_acc, test_prec, test_rec, test_f, test_loss = self._test_one_epoch(test_iter)\n",
        "            print(f'{epoch = }\\t{train_loss=:.5f}\\t{test_loss=:.5f}\\t{train_acc=:.5f}\\t{test_acc=:.5f}\\t{test_prec=:.5f}\\t{test_rec=:.5f}\\t{test_f=:.5f}')"
      ],
      "metadata": {
        "id": "7xssSozK0uO3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model multiple labels"
      ],
      "metadata": {
        "id": "xsJ8Xb1zxVYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassifierCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, num_classes: int, context_size: int, vocab_size: int = 21,  conv_channels: int = 128, use_bias: bool = False):\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=64, bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.LazyLinear(out_features=num_classes, bias=use_bias)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "DvXk1P5yzsRZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load GO data multiple labels"
      ],
      "metadata": {
        "id": "5H-PP8bUxpCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot_files = [\n",
        "    \"GO_3A0005576.annotprot\",\n",
        "    \"GO_3A0005739.annotprot\",\n",
        "    \"GO_3A0007165.annotprot\",\n",
        "    \"GO_3A0043066.annotprot\",\n",
        "    \"GO_3A0055085.annotprot\"\n",
        "]\n",
        "\n",
        "batch_size = 10\n",
        "num_steps = 1000\n",
        "\n",
        "dl, ll = read_multiple_pos(\"expr5Tseq_filtGO_100-1000.lis\", annot_files)\n",
        "\n",
        "dl, ll, _, _ = split_labelled_multiple_pos(dl, ll)\n",
        "\n",
        "train_dl, train_ll, test_dl, test_ll = generate_train_test(dl, ll, 0.6)\n",
        "train_ds = [train_dl, train_ll]\n",
        "test_ds = [test_dl, test_ll]\n",
        "\n",
        "traindataloader = load_data(batch_size, num_steps, train_ds)\n",
        "testdataloader = load_data(batch_size, num_steps, test_ds)\n",
        "\n",
        "print(next(iter(traindataloader)))"
      ],
      "metadata": {
        "id": "CId5XjpFtW82",
        "outputId": "624f2ffe-f0ea-457f-84f5-03e4790c3e88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[10,  0,  4,  ..., 20, 20, 20],\n",
            "        [10,  5, 12,  ..., 20, 20, 20],\n",
            "        [10, 16,  3,  ..., 20, 20, 20],\n",
            "        ...,\n",
            "        [10, 18, 14,  ..., 20, 20, 20],\n",
            "        [10,  5,  9,  ..., 20, 20, 20],\n",
            "        [10,  8, 17,  ..., 20, 20, 20]]), tensor([[0, 0, 0, 0, 1],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 1, 0],\n",
            "        [0, 0, 0, 1, 1],\n",
            "        [1, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "for s in dl:\n",
        "    len_list.append(len(s))\n",
        "sns.histplot(len_list)\n",
        "\n",
        "p = 0\n",
        "n = 0\n",
        "for labels in ll:\n",
        "    found_pos = False\n",
        "    for l in labels:\n",
        "        if l:\n",
        "            p += 1\n",
        "            found_pos = True\n",
        "            break\n",
        "    if not found_pos:\n",
        "        n+=1\n",
        "print(f'{p = }\\n{n = }')"
      ],
      "metadata": {
        "id": "JrwN-K7Syzod",
        "outputId": "a707928f-eb43-4782-b7ab-6e5bbbfccfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 1454\n",
            "n = 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model multiple labels"
      ],
      "metadata": {
        "id": "bcZoEI7-xuop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassifierCNN1D(num_classes=5, context_size=num_steps, conv_channels=256)\n",
        "model.apply(init_weights)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "model"
      ],
      "metadata": {
        "id": "towK5DH_147q",
        "outputId": "a9f79755-e257-4a56-f98f-90650d74d09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassifierCNN1D(\n",
              "  (embedding): Embedding(21, 21)\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(21, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): AdaptiveMaxPool1d(output_size=1)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): LazyLinear(in_features=0, out_features=64, bias=False)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=5, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = TrainerMultipleClasses(model, loss_fn, optimizer, device)\n",
        "trainer.train(epochs=10, train_iter=traindataloader, test_iter=testdataloader)"
      ],
      "metadata": {
        "id": "xv-k3v3e2Afo",
        "outputId": "4b5689da-0450-4552-e39d-46c5568a8039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0\ttrain_loss=0.56036\ttest_loss=0.53180\ttrain_acc=0.01399\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 1\ttrain_loss=0.52445\ttest_loss=0.53029\ttrain_acc=0.00252\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 2\ttrain_loss=0.52029\ttest_loss=0.52733\ttrain_acc=0.00183\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 3\ttrain_loss=0.52325\ttest_loss=0.52901\ttrain_acc=0.00046\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 4\ttrain_loss=0.52498\ttest_loss=0.52555\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 5\ttrain_loss=0.52082\ttest_loss=0.52643\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 6\ttrain_loss=0.52187\ttest_loss=0.52682\ttrain_acc=0.00069\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 7\ttrain_loss=0.51927\ttest_loss=0.53007\ttrain_acc=0.00023\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 8\ttrain_loss=0.52084\ttest_loss=0.52788\ttrain_acc=0.00000\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n",
            "epoch = 9\ttrain_loss=0.52192\ttest_loss=0.52884\ttrain_acc=0.00046\ttest_acc=0.00000\ttest_prec=0.00000\ttest_rec=0.00000\ttest_f=0.00000\n"
          ]
        }
      ]
    }
  ]
}