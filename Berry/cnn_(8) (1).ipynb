{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bioinformatics Project 2025 - Motif CNN & GO Prediction\n",
        "\n",
        "**Course:** GRS34806 Deep Learning\n",
        "\n",
        "**Authors:** ............\n",
        "\n",
        "**Date:**\n",
        "\n"
      ],
      "metadata": {
        "id": "HuP5FaUF6YLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "YbtfKAzz6ct5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the code last time! also the redundant libraries."
      ],
      "metadata": {
        "id": "amk7R7B2kcma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "! git clone https://git.wur.nl/bioinformatics/grs34806-deep-learning-project-data.git -q\n",
        "! git clone https://github.com/maussn/GRS34806-project.git -q\n",
        "os.chdir(Path('grs34806-deep-learning-project-data'))"
      ],
      "metadata": {
        "id": "Emlqnf_rAIWr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3ctb6CE_bWXP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data I/O & Tokenisation"
      ],
      "metadata": {
        "id": "g96CRPCRCbdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. read() --------------------------------------------------------------------\n",
        "def read(seqfile: str, posfile: str) -> tuple[list, list]:\n",
        "    \"\"\"Read file with sequences and file with positive cases into lists.\n",
        "\n",
        "    :param seqfile: file with sequences\n",
        "    :type seqfile: str\n",
        "    :param posfile: file with positive cases (annotated with function)\n",
        "    :type posfile: str\n",
        "    :return: two lists, first with sequences and second with boolean labels\n",
        "    :rtype: tuple[list, list]\n",
        "    \"\"\"\n",
        "    idlist = []\n",
        "    datalist = []\n",
        "    labellist = []\n",
        "    with open(seqfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip().split('\\t')\n",
        "            idlist.append(line[0])\n",
        "            datalist.append(line[1])\n",
        "            labellist.append(False)\n",
        "    with open(posfile, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            id = line.rstrip()\n",
        "            try:\n",
        "                i = idlist.index(id)\n",
        "                labellist[i] = True\n",
        "            except ValueError:\n",
        "                continue\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 2. split_labelled() ----------------------------------------------------------\n",
        "def split_labelled(datalist: list, labellist: list):\n",
        "    \"\"\"Return two separate sequence lists: positives & negatives.\"\"\"\n",
        "    pos_datalist = []\n",
        "    neg_datalist = []\n",
        "    for i, label in enumerate(labellist):\n",
        "        if label:\n",
        "            pos_datalist.append(datalist[i])\n",
        "        else:\n",
        "            neg_datalist.append(datalist[i])\n",
        "    return pos_datalist, neg_datalist\n",
        "\n",
        "\n",
        "# 3. remove_sequences() -----\n",
        "def remove_sequences(datalist: list, fraction=0.5):\n",
        "    \"\"\"Randomly keeps half of the list\"\"\"\n",
        "    random.shuffle(datalist)\n",
        "    keep = round(len(datalist) * fraction)\n",
        "    return datalist[:keep]\n",
        "\n",
        "\n",
        "# 4. fuse_sequence_lists() ------------\n",
        "def fuse_sequence_lists(pos_datalist: list, neg_datalist: list):\n",
        "    \"\"\"Merge postives and negetaves into one list + label\"\"\"\n",
        "    pos_labels = [True for _ in pos_datalist]\n",
        "    neg_labels = [False for _ in neg_datalist]\n",
        "    datalist = pos_datalist + neg_datalist\n",
        "    labellist = pos_labels + neg_labels\n",
        "    return datalist, labellist\n",
        "\n",
        "\n",
        "# 5. generate_train_test() --------\n",
        "def generate_train_test(datalist: list, labellist: list, fraction: float=0.8):\n",
        "    \"\"\"Split up dataset in training set and test set\n",
        "\n",
        "    :param datalist: list with sequences\n",
        "    :type datalist: list\n",
        "    :param labellist: list with labels\n",
        "    :type labellist: list\n",
        "    :param ratio: fraction to be added to the training set, remainder is added to the test set, defaults to 0.8\n",
        "    :type ratio: float, optional\n",
        "    :return: four lists, first two the training data and labels, second two the test data and labels\n",
        "    :rtype: tuple[list, list, list, list]\n",
        "    \"\"\"\n",
        "    c = list(zip(datalist, labellist))\n",
        "    random.shuffle(c)\n",
        "    datalist[:], labellist[:] = zip(*c)\n",
        "    i = round(len(datalist) * fraction)\n",
        "    traindatalist = datalist[:i]\n",
        "    trainlabellist = labellist[:i]\n",
        "    testdatalist = datalist[i:]\n",
        "    testlabellist = labellist[i:]\n",
        "    return traindatalist, trainlabellist,testdatalist,testlabellist\n",
        "\n",
        "\n",
        "# 6. Tokenisation & Padding --------\n",
        "def tokenize(data: list, map2num: dict, non_aa_num: int=20) -> list:\n",
        "    \"\"\"Tokenize all sequences in a list\n",
        "\n",
        "    :param data: list of sequences to tokenize\n",
        "    :type data: list\n",
        "    :param map2num: ammino acid -> integer token mapping\n",
        "    :type map2num: dict\n",
        "    :param non_aa_num: token for non amino acid characters, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: list of tokenized sequences\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    seq = []\n",
        "    for count, i in enumerate(data):\n",
        "        seq.append([map2num.get(j,non_aa_num) for j in list(i)])\n",
        "    return seq\n",
        "\n",
        "\n",
        "def truncate_pad(line: list, num_steps: int, padding_token: int) -> list:\n",
        "    \"\"\"Truncate or pad a tokenized sequence\n",
        "\n",
        "    :param line: tokenized sequence\n",
        "    :type line: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param padding_token: token to be used for padding\n",
        "    :type padding_token: int\n",
        "    :return: truncated/padded sequence\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps] # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line)) # Pad\n",
        "\n",
        "\n",
        "def build_seq_array(lines: list, num_steps: int, non_aa_num: int=20) -> torch.tensor:\n",
        "    \"\"\"Truncate or pad tokenized sequences and convert to tensor\n",
        "\n",
        "    :param lines: tokenized sequences\n",
        "    :type lines: list\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param non_aa_num: token for padding, defaults to 20\n",
        "    :type non_aa_num: int, optional\n",
        "    :return: tensor with truncated/padded tokenized sequences\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    return torch.tensor([truncate_pad(l, num_steps, non_aa_num) for l in lines], dtype=torch.long)\n",
        "\n",
        "\n",
        "# 7. load_array() & load_data()\n",
        "def load_array(data_arrays: tuple[torch.tensor, torch.tensor], batch_size: int, is_train: bool=True) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Construct a PyTorch data iterator.\n",
        "\n",
        "    Taken from d2l package\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "\n",
        "def load_data(batch_size: int, num_steps: int, dataset: tuple[list, list]) -> torch.utils.data.DataLoader:\n",
        "    \"\"\"Tokenize sequence/label dataset and load into dataloader.\n",
        "\n",
        "    :param batch_size: size of each batch\n",
        "    :type batch_size: int\n",
        "    :param num_steps: maximum sequence length\n",
        "    :type num_steps: int\n",
        "    :param dataset: first list contains sequences, second labels\n",
        "    :type dataset: tuple[list, list]\n",
        "    :return: torch dataloader which gives a tensor of sequences in a batch and a tensor with their labels\n",
        "    :rtype: torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "    mapaa2num = {aa: i for (i, aa) in enumerate(list(\"ACDEFGHIKLMNPQRSTVWY\"))}\n",
        "    seq,lab = dataset\n",
        "    seq = tokenize(seq, mapaa2num)\n",
        "    seq_array = build_seq_array(seq, num_steps)\n",
        "    data_arrays = (seq_array, torch.tensor(lab, dtype=torch.long))\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter"
      ],
      "metadata": {
        "id": "eHpedW0hqx1V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset selector\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ChrVqNAqKXEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the GO dataset\n",
        "REMOVE = \"neg\"                   # None | \"neg\" | \"pos\"\n",
        "\n",
        "seq_path  = \"expr5Tseq_filtGO_100-1000.lis\"\n",
        "pos_path  = \"GO_3A0005739.annotprot\"\n",
        "datalist, labellist = read(seq_path, pos_path)\n",
        "\n",
        "# Removing half dataset\n",
        "if REMOVE is not None:\n",
        "    pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "    if REMOVE == \"neg\":\n",
        "        neg_datalist = remove_sequences(neg_datalist, 0.5)\n",
        "    elif REMOVE == \"pos\":\n",
        "        pos_datalist = remove_sequences(pos_datalist, 0.5)\n",
        "    datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)"
      ],
      "metadata": {
        "id": "yDEFWAwbK_s3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the synthetic dataset\n",
        "dataset_id = \"len100_200_n1000\"\n",
        "REMOVE = None                   # None | \"neg\" | \"pos\"\n",
        "\n",
        "seq_path  = f\"{dataset_id}.seq\"\n",
        "pos_path  = f\"{dataset_id}.pos\"\n",
        "datalist, labellist = read(seq_path, pos_path)\n",
        "\n",
        "# Removing half dataset\n",
        "if REMOVE is not None:\n",
        "    pos_datalist, neg_datalist = split_labelled(datalist, labellist)\n",
        "    if REMOVE == \"neg\":\n",
        "        neg_datalist = remove_sequences(neg_datalist, 0.8)\n",
        "    elif REMOVE == \"pos\":\n",
        "        pos_datalist = remove_sequences(pos_datalist, 0.8)\n",
        "    datalist, labellist = fuse_sequence_lists(pos_datalist, neg_datalist)"
      ],
      "metadata": {
        "id": "ick2N8sPGoDV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "id": "_b5Kq5jEKZwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_steps = 1000 # max sequence length\n",
        "\n",
        "traindatalist, trainlabellist, testdatalist, testlabellist = generate_train_test(datalist, labellist, 0.8)\n",
        "traindataset = [traindatalist, trainlabellist]\n",
        "testdataset = [testdatalist, testlabellist]\n",
        "\n",
        "# Set batch_size and num_steps (maximum sequence length)\n",
        "train_iter = load_data(batch_size, num_steps, traindataset)\n",
        "test_iter = load_data(batch_size, num_steps, testdataset)\n",
        "\n",
        "print(\"batch shape  :\", next(iter(train_iter))[0].shape)\n",
        "print(\"labels shape :\", next(iter(train_iter))[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRvhoyiwv_g",
        "outputId": "dfe7ab38-f1d5-425f-b058-96f8d73899ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch shape  : torch.Size([10, 1000])\n",
            "labels shape : torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training / Evaluation"
      ],
      "metadata": {
        "id": "BhuHUN6TRLun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "YwR8PJG9SYbo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(layer):\n",
        "    if type(layer) == nn.Linear or type(layer) == nn.Conv1d:\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loss_fn, optimizer, device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    # One training epoch -------------------------------------------------------\n",
        "    def _train_one_epoch(self, train_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.train(True)\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_iter):\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            result_loss += loss.item()\n",
        "\n",
        "            # Confusion matrix calculation\n",
        "            for j, l in enumerate(labels):\n",
        "                o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                l = l.item()\n",
        "                if o == 1 and l == 1:\n",
        "                    tpos += 1\n",
        "                elif o == 1 and l == 0:\n",
        "                    fpos += 1\n",
        "                elif o == 0 and l == 0:\n",
        "                    tneg += 1\n",
        "                elif o == 0 and l == 1:\n",
        "                    fneg += 1\n",
        "                else:\n",
        "                    raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "    # Evaluation epoch ---------------------------------------------------------\n",
        "    def _test_one_epoch(self, test_iter):\n",
        "        result_loss = 0\n",
        "        tpos = fpos = tneg = fneg = 0\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(test_iter, start=1):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.loss_fn(input=outputs, target=labels)\n",
        "                result_loss += loss.item()\n",
        "\n",
        "                # Confusion matrix calculation\n",
        "                for j, l in enumerate(labels):\n",
        "                    o = outputs[j].tolist().index(max(outputs[j]))\n",
        "                    l = l.item()\n",
        "                    if o == 1 and l == 1:\n",
        "                        tpos += 1\n",
        "                    elif o == 1 and l == 0:\n",
        "                        fpos += 1\n",
        "                    elif o == 0 and l == 0:\n",
        "                        tneg += 1\n",
        "                    elif o == 0 and l == 1:\n",
        "                        fneg += 1\n",
        "                    else:\n",
        "                        raise ValueError(f'Output or label is not rounded to zero: {o = } {l = }')\n",
        "\n",
        "        accuracy = (tpos + tneg) / (tpos + fpos + tneg + fneg)\n",
        "        precision = tpos / (tpos + fpos) if (tpos + fpos) > 0 else 0\n",
        "        recall = tpos / (tpos + fneg) if (tpos + fneg) > 0 else 0\n",
        "        fscore = 2 * tpos / (2*tpos + fpos + fneg) if (2*tpos + fpos + fneg) > 0 else 0\n",
        "\n",
        "        return accuracy, precision, recall, fscore, result_loss / (i+1)\n",
        "\n",
        "\n",
        "    def train(self, epochs, train_iter, test_iter):\n",
        "        best_acc = 0.0\n",
        "\n",
        "        print(\"Current hyper-parameters:\", params)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_acc, train_prec, train_rec, train_f, train_loss = self._train_one_epoch(train_iter)\n",
        "\n",
        "            test_acc, test_prec, test_rec, test_f, test_loss = self._test_one_epoch(test_iter)\n",
        "\n",
        "            print(f\"[epoch {epoch:02d}] \"\n",
        "                  f\"train-loss={train_loss:.4f} | \"\n",
        "                  f\"test-loss={test_loss:.4f} | \"\n",
        "                  f\"train-acc={train_acc:.4f} | \"\n",
        "                  f\"test-acc={test_acc:.4f} | \"\n",
        "                  f\"P={test_prec:.4f} | R={test_rec:.4f} | F1={test_f:.4f}\")\n",
        "\n",
        "            if test_acc >= best_acc:\n",
        "                best_acc = test_acc\n",
        "\n",
        "        return best_acc"
      ],
      "metadata": {
        "id": "C0xPrmp3jHjD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BerryCNN1D(nn.Module):\n",
        "    \"\"\"1D Convolutional Neural Network for protein function classification\"\"\"\n",
        "    def __init__(self, context_size: int, vocab_size: int = 21,\n",
        "                 dropout_rate = 0, conv_channels: int = 128,\n",
        "                 use_bias: bool = False):\n",
        "\n",
        "        super().__init__()\n",
        "        assert context_size % 2 == 0, f'Invalid context_size, {context_size} is not an even number'\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        # CNN model for binary classification\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # conv block 1\n",
        "            nn.Conv1d(in_channels=vocab_size, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # conv block 2\n",
        "            nn.Conv1d(in_channels=conv_channels, out_channels=conv_channels, kernel_size=3, padding='same', bias=use_bias),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Sequential(\n",
        "            # flatten + classification head\n",
        "            nn.Flatten(1, -1),\n",
        "            nn.LazyLinear(out_features=2, bias=use_bias)  # binary classification\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.tensor, targets: torch.tensor = None):\n",
        "        \"\"\"Predict protein function class (0 or 1)\"\"\"\n",
        "        x = self.embedding(x).permute(0,2,1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "2V5v63DoLaLr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the CNN\n",
        "net = BerryCNN1D(context_size=num_steps, vocab_size=21, conv_channels=128)"
      ],
      "metadata": {
        "id": "5Tq5vt3a_afn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "UeAeB8Wo79Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "param_grid = {\n",
        "    'dropout_rate': [0, 0.3],\n",
        "    'lr': [0.01, 0.001],\n",
        "    'momentum': [0, 0.5],\n",
        "    'conv_channels': [64, 128]\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "for params in grid:\n",
        "    model = BerryCNN1D(\n",
        "        context_size=num_steps,\n",
        "        vocab_size=21,\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        conv_channels=params['conv_channels']\n",
        "    )\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        momentum=params['momentum']\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "\n",
        "    acc = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    if acc >= best_acc:\n",
        "        best_acc = []\n",
        "        best_acc = acc\n",
        "        best_params = params\n",
        "        print(f\"New best accuracy {best_acc:.4f} with {best_params} \\n\")\n",
        "\n",
        "print(\"Best hyper‑parameters found:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HESI-RwU5o",
        "outputId": "b3da2ad4-b1ac-4c05-f3f3-fd14bb467388"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4010 | test-loss=0.4075 | train-acc=0.8660 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3852 | test-loss=0.3787 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3761 | test-loss=0.3909 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3665 | test-loss=0.3786 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3561 | test-loss=0.3770 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3490 | test-loss=0.3678 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3370 | test-loss=0.4362 | train-acc=0.8704 | test-acc=0.8664 | P=0.4000 | R=0.0860 | F1=0.1416\n",
            "[epoch 08] train-loss=0.3220 | test-loss=0.4064 | train-acc=0.8728 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3092 | test-loss=0.3937 | train-acc=0.8739 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.2984 | test-loss=0.3790 | train-acc=0.8784 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4029 | test-loss=0.3788 | train-acc=0.8666 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3823 | test-loss=0.3743 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3660 | test-loss=0.3686 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3538 | test-loss=0.4906 | train-acc=0.8697 | test-acc=0.8278 | P=0.2778 | R=0.2151 | F1=0.2424\n",
            "[epoch 05] train-loss=0.3352 | test-loss=0.3775 | train-acc=0.8715 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3166 | test-loss=0.3940 | train-acc=0.8749 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2886 | test-loss=0.6575 | train-acc=0.8866 | test-acc=0.5992 | P=0.1806 | R=0.6022 | F1=0.2779\n",
            "[epoch 08] train-loss=0.2656 | test-loss=0.3767 | train-acc=0.8935 | test-acc=0.8650 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.2404 | test-loss=1.2293 | train-acc=0.9073 | test-acc=0.2934 | P=0.1477 | R=0.9462 | F1=0.2554\n",
            "[epoch 10] train-loss=0.2231 | test-loss=0.4845 | train-acc=0.9114 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4071 | test-loss=0.3734 | train-acc=0.8542 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3813 | test-loss=0.3748 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3805 | test-loss=0.3710 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3798 | test-loss=0.3753 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3788 | test-loss=0.3701 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3807 | test-loss=0.3720 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3769 | test-loss=0.3733 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3759 | test-loss=0.3720 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3755 | test-loss=0.3691 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3745 | test-loss=0.3705 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4183 | test-loss=0.3752 | train-acc=0.8480 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3853 | test-loss=0.3757 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3874 | test-loss=0.3777 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3829 | test-loss=0.3738 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3848 | test-loss=0.3755 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3809 | test-loss=0.3783 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3799 | test-loss=0.3749 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3783 | test-loss=0.3726 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3772 | test-loss=0.3730 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3783 | test-loss=0.3774 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4090 | test-loss=0.4399 | train-acc=0.8660 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3947 | test-loss=0.3753 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3898 | test-loss=0.3998 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3882 | test-loss=0.3735 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3806 | test-loss=0.3782 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3789 | test-loss=0.3778 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3743 | test-loss=0.3798 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3719 | test-loss=0.3711 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3695 | test-loss=0.3824 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3617 | test-loss=0.4435 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4144 | test-loss=0.3953 | train-acc=0.8660 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3882 | test-loss=0.3816 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3901 | test-loss=0.3743 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3786 | test-loss=0.3913 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3671 | test-loss=0.3739 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3568 | test-loss=0.3796 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3491 | test-loss=0.3687 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3381 | test-loss=0.3772 | train-acc=0.8711 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3294 | test-loss=0.3677 | train-acc=0.8746 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3162 | test-loss=0.3671 | train-acc=0.8756 | test-acc=0.8691 | P=0.2500 | R=0.0108 | F1=0.0206\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4351 | test-loss=0.3778 | train-acc=0.8498 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4031 | test-loss=0.3833 | train-acc=0.8684 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.4020 | test-loss=0.3749 | train-acc=0.8677 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3961 | test-loss=0.3763 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3907 | test-loss=0.3751 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3950 | test-loss=0.3735 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3895 | test-loss=0.3758 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3961 | test-loss=0.3765 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3887 | test-loss=0.3739 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3832 | test-loss=0.3758 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4184 | test-loss=0.3767 | train-acc=0.8570 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4056 | test-loss=0.3730 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3945 | test-loss=0.3745 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3965 | test-loss=0.3808 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3926 | test-loss=0.3736 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3901 | test-loss=0.3731 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3883 | test-loss=0.3748 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3856 | test-loss=0.3740 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3823 | test-loss=0.3737 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3875 | test-loss=0.3761 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.3975 | test-loss=0.3881 | train-acc=0.8673 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3865 | test-loss=0.3898 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3830 | test-loss=0.4649 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3736 | test-loss=0.3772 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3615 | test-loss=0.3773 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3531 | test-loss=0.3921 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3404 | test-loss=0.3811 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3269 | test-loss=0.4006 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3113 | test-loss=0.4014 | train-acc=0.8701 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.2916 | test-loss=0.4242 | train-acc=0.8742 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.3958 | test-loss=0.3714 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3801 | test-loss=0.3725 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3644 | test-loss=0.3718 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3496 | test-loss=0.4596 | train-acc=0.8701 | test-acc=0.8581 | P=0.2727 | R=0.0645 | F1=0.1043\n",
            "[epoch 05] train-loss=0.3304 | test-loss=0.4095 | train-acc=0.8732 | test-acc=0.8609 | P=0.2500 | R=0.0430 | F1=0.0734\n",
            "[epoch 06] train-loss=0.3014 | test-loss=0.4164 | train-acc=0.8804 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2769 | test-loss=0.3784 | train-acc=0.8856 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.2436 | test-loss=0.4843 | train-acc=0.8939 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.2114 | test-loss=0.4151 | train-acc=0.9166 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.1749 | test-loss=0.3544 | train-acc=0.9325 | test-acc=0.8691 | P=0.4167 | R=0.0538 | F1=0.0952\n",
            "New best accuracy 0.8719 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.3952 | test-loss=0.3790 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3866 | test-loss=0.3788 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3854 | test-loss=0.3817 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3847 | test-loss=0.3798 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3863 | test-loss=0.3826 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3828 | test-loss=0.3795 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3827 | test-loss=0.3794 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3816 | test-loss=0.3789 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3808 | test-loss=0.3790 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3800 | test-loss=0.3802 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.3975 | test-loss=0.3788 | train-acc=0.8584 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3867 | test-loss=0.3757 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3816 | test-loss=0.3741 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3806 | test-loss=0.3752 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3781 | test-loss=0.3727 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3761 | test-loss=0.3757 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3747 | test-loss=0.3765 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3752 | test-loss=0.3760 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3720 | test-loss=0.3723 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3694 | test-loss=0.3703 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4092 | test-loss=0.4029 | train-acc=0.8660 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3950 | test-loss=0.3846 | train-acc=0.8691 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3884 | test-loss=0.3737 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3774 | test-loss=0.3783 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3762 | test-loss=0.3886 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3643 | test-loss=0.3758 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3561 | test-loss=0.3755 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3514 | test-loss=0.3869 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3433 | test-loss=0.3702 | train-acc=0.8687 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3316 | test-loss=0.3722 | train-acc=0.8708 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8719 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4191 | test-loss=0.3833 | train-acc=0.8663 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3982 | test-loss=0.3715 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3829 | test-loss=0.3786 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3694 | test-loss=0.3706 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3605 | test-loss=0.3678 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3430 | test-loss=0.3609 | train-acc=0.8701 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3352 | test-loss=0.3866 | train-acc=0.8697 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3129 | test-loss=0.3764 | train-acc=0.8746 | test-acc=0.8733 | P=0.6667 | R=0.0215 | F1=0.0417\n",
            "[epoch 09] train-loss=0.3002 | test-loss=0.3550 | train-acc=0.8742 | test-acc=0.8747 | P=1.0000 | R=0.0215 | F1=0.0421\n",
            "[epoch 10] train-loss=0.2785 | test-loss=0.3541 | train-acc=0.8873 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8747 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
            "[epoch 01] train-loss=0.4349 | test-loss=0.3774 | train-acc=0.8477 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.4041 | test-loss=0.3772 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.4028 | test-loss=0.3766 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3982 | test-loss=0.3786 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3907 | test-loss=0.3748 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3936 | test-loss=0.3771 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3901 | test-loss=0.3770 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3917 | test-loss=0.3767 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3853 | test-loss=0.3760 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3915 | test-loss=0.3754 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "Current hyper-parameters: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
            "[epoch 01] train-loss=0.4230 | test-loss=0.3788 | train-acc=0.8532 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3958 | test-loss=0.3792 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3920 | test-loss=0.3754 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3909 | test-loss=0.3762 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3910 | test-loss=0.3761 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3854 | test-loss=0.3741 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3865 | test-loss=0.3858 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3842 | test-loss=0.3751 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3797 | test-loss=0.3750 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3798 | test-loss=0.3746 | train-acc=0.8694 | test-acc=0.8719 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "Best hyper‑parameters found: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "param_grid = {\n",
        "    'dropout_rate': [0, 0.3],\n",
        "    'lr': [0.01, 0.001],\n",
        "    'momentum': [0, 0.5],\n",
        "    'conv_channels': [64, 128]\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "for params in grid:\n",
        "    model = BerryCNN1D(\n",
        "        context_size=num_steps,\n",
        "        vocab_size=21,\n",
        "        dropout_rate=params['dropout_rate'],\n",
        "        conv_channels=params['conv_channels']\n",
        "    )\n",
        "    model.apply(init_weights)\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=params['lr'],\n",
        "        momentum=params['momentum']\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    trainer = Trainer(model, loss_fn, optimizer, device)\n",
        "\n",
        "    acc = trainer.train(epochs=10, train_iter=train_iter, test_iter=test_iter)\n",
        "\n",
        "    if acc >= best_acc:\n",
        "        best_acc = []\n",
        "        best_acc = acc\n",
        "        best_params = params\n",
        "        print(f\"New best accuracy {best_acc:.4f} with {best_params} \\n\")\n",
        "\n",
        "print(\"Best hyper‑parameters found:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z2M-vmMR4EuP",
        "outputId": "cef96f7c-507c-4314-d40f-093df3c86250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[epoch 01] train-loss=0.3937 | test-loss=0.4786 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3839 | test-loss=0.3955 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3731 | test-loss=0.3956 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3697 | test-loss=0.4924 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3605 | test-loss=0.3861 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3504 | test-loss=0.3868 | train-acc=0.8725 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3407 | test-loss=0.4707 | train-acc=0.8728 | test-acc=0.8595 | P=0.4615 | R=0.0594 | F1=0.1053\n",
            "[epoch 08] train-loss=0.3281 | test-loss=0.4057 | train-acc=0.8725 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3155 | test-loss=0.4407 | train-acc=0.8739 | test-acc=0.8485 | P=0.2857 | R=0.0594 | F1=0.0984\n",
            "[epoch 10] train-loss=0.2991 | test-loss=0.3901 | train-acc=0.8766 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8609 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0} \n",
            "\n",
            "[epoch 01] train-loss=0.3933 | test-loss=0.4065 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3810 | test-loss=0.3965 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3688 | test-loss=0.3936 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3558 | test-loss=0.4553 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3416 | test-loss=0.3811 | train-acc=0.8735 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3192 | test-loss=0.4433 | train-acc=0.8749 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.2959 | test-loss=0.4243 | train-acc=0.8801 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.2637 | test-loss=0.4368 | train-acc=0.8928 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.2360 | test-loss=0.4126 | train-acc=0.9032 | test-acc=0.8595 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.2122 | test-loss=1.4455 | train-acc=0.9097 | test-acc=0.2135 | P=0.1482 | R=0.9802 | F1=0.2575\n",
            "New best accuracy 0.8609 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5} \n",
            "\n",
            "[epoch 01] train-loss=0.4091 | test-loss=0.3959 | train-acc=0.8529 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 02] train-loss=0.3833 | test-loss=0.3964 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 03] train-loss=0.3824 | test-loss=0.3973 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 04] train-loss=0.3807 | test-loss=0.3937 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 05] train-loss=0.3839 | test-loss=0.3946 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 06] train-loss=0.3808 | test-loss=0.3918 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 07] train-loss=0.3798 | test-loss=0.3942 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 08] train-loss=0.3794 | test-loss=0.3944 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 09] train-loss=0.3818 | test-loss=0.3923 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "[epoch 10] train-loss=0.3807 | test-loss=0.3938 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n",
            "New best accuracy 0.8609 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0} \n",
            "\n",
            "[epoch 01] train-loss=0.3842 | test-loss=0.3954 | train-acc=0.8722 | test-acc=0.8609 | P=0.0000 | R=0.0000 | F1=0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-256e1dbaa53d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-980fd08df8c5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_iter, test_iter)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-980fd08df8c5>\u001b[0m in \u001b[0;36m_train_one_epoch\u001b[0;34m(self, train_iter)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verander bovenstaande gegevens in een pandas dataframe\n",
        "\n",
        "\n",
        "\n",
        "len200_500_n5000nr4 = Best hyper‑parameters found: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}"
      ],
      "metadata": {
        "id": "aiodFhyizlh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "len200_500_n5000nr1\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.2816 | test‑loss=0.0206 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0108 | test‑loss=0.0062 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0044 | test‑loss=0.0034 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0027 | test‑loss=0.0023 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0019 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0015 | test‑loss=0.0014 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0012 | test‑loss=0.0012 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0010 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0008 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0007 | test‑loss=0.0008 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.6772 | test‑loss=0.1625 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0247 | test‑loss=0.0056 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0040 | test‑loss=0.0027 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0022 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0015 | test‑loss=0.0014 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0011 | test‑loss=0.0012 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0009 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0007 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0006 | test‑loss=0.0008 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0005 | test‑loss=0.0007 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.0577 | test‑loss=0.0006 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0004 | test‑loss=0.0003 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0002 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0002 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.7000 | test‑loss=0.6940 | test‑acc=0.5000 | P=0.5000 | R=0.5000 | F1=0.5000\n",
        "[epoch 02] train‑loss=0.6864 | test‑loss=0.6803 | test‑acc=0.5610 | P=0.5610 | R=0.5610 | F1=0.5610\n",
        "[epoch 03] train‑loss=0.6527 | test‑loss=0.6190 | test‑acc=0.7950 | P=0.7950 | R=0.7950 | F1=0.7950\n",
        "[epoch 04] train‑loss=0.5373 | test‑loss=0.4389 | test‑acc=0.9960 | P=0.9960 | R=0.9960 | F1=0.9960\n",
        "[epoch 05] train‑loss=0.3297 | test‑loss=0.2355 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 06] train‑loss=0.1719 | test‑loss=0.1253 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 07] train‑loss=0.0962 | test‑loss=0.0755 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0609 | test‑loss=0.0507 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0425 | test‑loss=0.0371 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0319 | test‑loss=0.0288 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.6852 | test‑loss=0.6571 | test‑acc=0.6350 | P=0.6350 | R=0.6350 | F1=0.6350\n",
        "[epoch 02] train‑loss=0.4732 | test‑loss=0.2545 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.1386 | test‑loss=0.0705 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0485 | test‑loss=0.0323 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0257 | test‑loss=0.0192 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0167 | test‑loss=0.0133 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0121 | test‑loss=0.0100 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0094 | test‑loss=0.0079 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0076 | test‑loss=0.0064 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0063 | test‑loss=0.0054 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.4575 | test‑loss=0.0568 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 02] train‑loss=0.0249 | test‑loss=0.0120 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 03] train‑loss=0.0094 | test‑loss=0.0064 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 04] train‑loss=0.0058 | test‑loss=0.0043 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0042 | test‑loss=0.0032 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0031 | test‑loss=0.0026 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0025 | test‑loss=0.0022 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0021 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0018 | test‑loss=0.0015 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0015 | test‑loss=0.0013 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.4828 | test‑loss=0.0886 | test‑acc=0.9970 | P=0.9970 | R=0.9970 | F1=0.9970\n",
        "[epoch 02] train‑loss=0.1210 | test‑loss=0.0361 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 03] train‑loss=0.0842 | test‑loss=0.0165 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0656 | test‑loss=0.0257 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 05] train‑loss=0.0494 | test‑loss=0.0129 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 06] train‑loss=0.0432 | test‑loss=0.0124 | test‑acc=0.9980 | P=0.9980 | R=0.9980 | F1=0.9980\n",
        "[epoch 07] train‑loss=0.0348 | test‑loss=0.0103 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 08] train‑loss=0.0364 | test‑loss=0.0073 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 09] train‑loss=0.0303 | test‑loss=0.0073 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 10] train‑loss=0.0277 | test‑loss=0.0052 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.3771 | test‑loss=0.0356 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 02] train‑loss=0.0809 | test‑loss=0.0090 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0433 | test‑loss=0.0102 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 04] train‑loss=0.0257 | test‑loss=0.0057 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0161 | test‑loss=0.0041 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0155 | test‑loss=0.0025 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0104 | test‑loss=0.0019 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0120 | test‑loss=0.0037 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0116 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0066 | test‑loss=0.0023 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.1972 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0124 | test‑loss=0.0133 | test‑acc=0.9970 | P=0.9970 | R=0.9970 | F1=0.9970\n",
        "[epoch 03] train‑loss=0.0119 | test‑loss=0.0003 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0123 | test‑loss=0.0013 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0066 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0059 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0035 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0030 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0022 | test‑loss=0.0014 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0030 | test‑loss=0.0003 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.7325 | test‑loss=0.6976 | test‑acc=0.4880 | P=0.4880 | R=0.4880 | F1=0.4880\n",
        "[epoch 02] train‑loss=0.7319 | test‑loss=0.6953 | test‑acc=0.4900 | P=0.4900 | R=0.4900 | F1=0.4900\n",
        "[epoch 03] train‑loss=0.7086 | test‑loss=0.6913 | test‑acc=0.5280 | P=0.5280 | R=0.5280 | F1=0.5280\n",
        "[epoch 04] train‑loss=0.7002 | test‑loss=0.6867 | test‑acc=0.5390 | P=0.5390 | R=0.5390 | F1=0.5390\n",
        "[epoch 05] train‑loss=0.6927 | test‑loss=0.6684 | test‑acc=0.6040 | P=0.6040 | R=0.6040 | F1=0.6040\n",
        "[epoch 06] train‑loss=0.6579 | test‑loss=0.6082 | test‑acc=0.8850 | P=0.8850 | R=0.8850 | F1=0.8850\n",
        "[epoch 07] train‑loss=0.5988 | test‑loss=0.4994 | test‑acc=0.9950 | P=0.9950 | R=0.9950 | F1=0.9950\n",
        "[epoch 08] train‑loss=0.5019 | test‑loss=0.3739 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 09] train‑loss=0.4247 | test‑loss=0.2741 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.3350 | test‑loss=0.1913 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.7345 | test‑loss=0.6898 | test‑acc=0.5550 | P=0.5550 | R=0.5550 | F1=0.5550\n",
        "[epoch 02] train‑loss=0.6994 | test‑loss=0.6511 | test‑acc=0.7460 | P=0.7460 | R=0.7460 | F1=0.7460\n",
        "[epoch 03] train‑loss=0.5778 | test‑loss=0.3980 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.3361 | test‑loss=0.1642 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.1984 | test‑loss=0.0937 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.1398 | test‑loss=0.0594 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.1103 | test‑loss=0.0387 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0840 | test‑loss=0.0340 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0726 | test‑loss=0.0237 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0676 | test‑loss=0.0212 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.5959 | test‑loss=0.1251 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.1392 | test‑loss=0.0384 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0771 | test‑loss=0.0157 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0641 | test‑loss=0.0146 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0485 | test‑loss=0.0105 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0340 | test‑loss=0.0073 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0311 | test‑loss=0.0056 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0277 | test‑loss=0.0069 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0273 | test‑loss=0.0056 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0219 | test‑loss=0.0082 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 64, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.2720 | test‑loss=0.0191 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0099 | test‑loss=0.0059 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0041 | test‑loss=0.0033 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0026 | test‑loss=0.0022 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0018 | test‑loss=0.0017 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0014 | test‑loss=0.0014 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0011 | test‑loss=0.0011 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0010 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0008 | test‑loss=0.0008 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0007 | test‑loss=0.0007 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.1823 | test‑loss=0.0073 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0042 | test‑loss=0.0029 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0020 | test‑loss=0.0018 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0013 | test‑loss=0.0014 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0009 | test‑loss=0.0011 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0007 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0006 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0005 | test‑loss=0.0008 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0004 | test‑loss=0.0007 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0004 | test‑loss=0.0006 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.0777 | test‑loss=0.0004 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0003 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0002 | test‑loss=0.0002 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0001 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0000 | test‑loss=0.0000 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.01, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.6962 | test‑loss=0.6926 | test‑acc=0.5190 | P=0.5190 | R=0.5190 | F1=0.5190\n",
        "[epoch 02] train‑loss=0.6822 | test‑loss=0.6718 | test‑acc=0.5710 | P=0.5710 | R=0.5710 | F1=0.5710\n",
        "[epoch 03] train‑loss=0.6298 | test‑loss=0.5712 | test‑acc=0.9840 | P=0.9840 | R=0.9840 | F1=0.9840\n",
        "[epoch 04] train‑loss=0.4671 | test‑loss=0.3544 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.2563 | test‑loss=0.1787 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.1314 | test‑loss=0.0979 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0762 | test‑loss=0.0607 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0501 | test‑loss=0.0421 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0360 | test‑loss=0.0314 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0276 | test‑loss=0.0247 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.5885 | test‑loss=0.3798 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 02] train‑loss=0.1963 | test‑loss=0.0867 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0562 | test‑loss=0.0362 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0278 | test‑loss=0.0206 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0176 | test‑loss=0.0140 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0127 | test‑loss=0.0104 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0098 | test‑loss=0.0082 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0079 | test‑loss=0.0068 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0066 | test‑loss=0.0057 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0056 | test‑loss=0.0049 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.3794 | test‑loss=0.0236 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0112 | test‑loss=0.0058 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0043 | test‑loss=0.0031 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0026 | test‑loss=0.0021 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0018 | test‑loss=0.0015 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0014 | test‑loss=0.0012 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0011 | test‑loss=0.0010 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0009 | test‑loss=0.0008 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0008 | test‑loss=0.0007 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0007 | test‑loss=0.0006 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0, 'lr': 0.001, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.3985 | test‑loss=0.0512 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 02] train‑loss=0.0630 | test‑loss=0.0151 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 03] train‑loss=0.0286 | test‑loss=0.0088 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0243 | test‑loss=0.0079 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0147 | test‑loss=0.0068 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 06] train‑loss=0.0142 | test‑loss=0.0037 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0091 | test‑loss=0.0028 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0095 | test‑loss=0.0046 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0074 | test‑loss=0.0035 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0057 | test‑loss=0.0019 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.4277 | test‑loss=0.0294 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0735 | test‑loss=0.0119 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0468 | test‑loss=0.0097 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0389 | test‑loss=0.0136 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 05] train‑loss=0.0256 | test‑loss=0.0033 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0292 | test‑loss=0.0068 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 07] train‑loss=0.0252 | test‑loss=0.0052 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 08] train‑loss=0.0151 | test‑loss=0.0030 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0200 | test‑loss=0.0114 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 10] train‑loss=0.0120 | test‑loss=0.0042 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.1308 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.0027 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0031 | test‑loss=0.0004 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0029 | test‑loss=0.0007 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0015 | test‑loss=0.0009 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0021 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0018 | test‑loss=0.0004 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0003 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0003 | test‑loss=0.0003 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0002 | test‑loss=0.0001 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.01, 'momentum': 0.9}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
        "[epoch 01] train‑loss=0.7231 | test‑loss=0.6839 | test‑acc=0.5180 | P=0.5180 | R=0.5180 | F1=0.5180\n",
        "[epoch 02] train‑loss=0.6820 | test‑loss=0.6185 | test‑acc=0.8370 | P=0.8370 | R=0.8370 | F1=0.8370\n",
        "[epoch 03] train‑loss=0.5689 | test‑loss=0.4380 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.3908 | test‑loss=0.2455 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.2549 | test‑loss=0.1381 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.1779 | test‑loss=0.0833 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.1265 | test‑loss=0.0555 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0996 | test‑loss=0.0410 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0812 | test‑loss=0.0308 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0678 | test‑loss=0.0267 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
        "[epoch 01] train‑loss=0.7298 | test‑loss=0.6833 | test‑acc=0.6080 | P=0.6080 | R=0.6080 | F1=0.6080\n",
        "[epoch 02] train‑loss=0.6891 | test‑loss=0.6188 | test‑acc=0.8530 | P=0.8530 | R=0.8530 | F1=0.8530\n",
        "[epoch 03] train‑loss=0.5337 | test‑loss=0.3247 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.2705 | test‑loss=0.1130 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.1295 | test‑loss=0.0547 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0829 | test‑loss=0.0312 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 07] train‑loss=0.0566 | test‑loss=0.0212 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0472 | test‑loss=0.0175 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0367 | test‑loss=0.0158 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0360 | test‑loss=0.0138 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.5}\n",
        "\n",
        "Current hyper-parameter: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}\n",
        "[epoch 01] train‑loss=0.5881 | test‑loss=0.1344 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 02] train‑loss=0.1153 | test‑loss=0.0155 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 03] train‑loss=0.0448 | test‑loss=0.0081 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 04] train‑loss=0.0251 | test‑loss=0.0087 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 05] train‑loss=0.0208 | test‑loss=0.0072 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 06] train‑loss=0.0184 | test‑loss=0.0087 | test‑acc=0.9990 | P=0.9990 | R=0.9990 | F1=0.9990\n",
        "[epoch 07] train‑loss=0.0109 | test‑loss=0.0031 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 08] train‑loss=0.0088 | test‑loss=0.0026 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 09] train‑loss=0.0119 | test‑loss=0.0020 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "[epoch 10] train‑loss=0.0066 | test‑loss=0.0017 | test‑acc=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000\n",
        "New best accuracy 1.0000 with {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}\n",
        "\n",
        "Best hyper‑parameters found: {'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}"
      ],
      "metadata": {
        "id": "QxobYhFW4eWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keOrQ1ZhvlZV",
        "outputId": "768a0369-5221-481a-dc27-ccebd61120e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'conv_channels': 128, 'dropout_rate': 0.3, 'lr': 0.001, 'momentum': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NpXTnCJ63_6D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}